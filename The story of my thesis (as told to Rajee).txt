

Hello. 

Can you hear me? I can hear you. I can hear you. How are you? I'm. I'm actually a lot better. Yeah. Yeah. Nice. What? I think I'm getting close to being exhausted again anyway. Nothing. Okay. I tell you about my thesis. Okay. I like how you look. 

Thank you. 

Okay, so the, 

Se I need to be doodling or taking notes or something. Okay. Yeah. So. The high level story that I want to tell. Is the cock and proof assistance are important. And. Performance in them is important especially at scale and performance improve assistance has some unique challenges that turned show up in other programming languages. 

And I want to paint a picture of. Sort of what the unique challenges are. What sort of two main areas probably in the previous system that there are performance bottlenecks and propose some reasons about why there might be performance model next year and describe solutions for them. And also they'll be another section that has some miscellaney other performance bottlenecks that come up in preface this sense and incall. 

So the first bit you should also feel free to ask questions as you have them if you want to. To the first bit is about like what makes performance and proof resistance and cock challenging. And in most languages. Or in most most areas the performance story is that you do a thing and you make it fast on your toy examples and you do larger examples and hopefully it's still fast and then you do much larger examples and maybe it gets a bit slow and maybe for the largest of examples you need to like let it run overnight or something. 

The experiencing caulk frequently is that you do something and you get it to work on your toy examples and it's fast and you do slightly larger examples and it's still kind of fast. But like noticeable and then you do somewhat larger examples and now it's like slow and annoying but still okay and then you make your examples a little bit longer and. 

Maybe it won't finish for a week. Or longer okay, oh like. Like I ran into a case where I had a thing and it worked and for the larger examples it would maybe take I don't know an hour to and then there were some examples that. Did finish after about four thousand hours. 

Um, Was it wait four thousand no sorry not four thousand hours four thousand seconds okay, yeah that's more reasonable out of time yeah like four thousand seconds, oh. But. There were other larger examples that didn't finish even after like nine hundred hours, ah, yes hours, oh wow. So like four a month. 

I think that's about how long I left them running okay just out of curiosities to see which ones would finish. Maybe it was 40,000 seconds that some of the medium-sized ones finished in anyway, it was some like ridiculous amount like like you got a bunch of them that would finish reasonably quickly and then the next ones would like much much slower completely unreasonable amounts of time. 

And this is sort of common in cock where you'll get something and it'll work and if it works then you just leave it and then you try to scale your thing and now suddenly you've hit sudden you've hit one of many instances of quadratic or exponential behavior and now your thing is. 

Unclear if it'll finish in a year, okay? Oh. And. This is performance of compile time by the way, this is like performance of how long it takes to check proofs if you're writing programs and you want to prove things about them, like how your programs perform is subject to the same optimization techniques as other languages, but the issue that you have a question no go on the issue with using those techniques for how your proofs perform is that usually most languages either a library is slow. 

And you like know it's slow and it has like known performance characteristics or the code that you were as slow. Here. There are many many bits of the compiler that usually just work and most the time you don't need to care about how they work they just work until they don't. 

So why don't they work ah, so there's various reasons, um, one of them is that the cocktail team is under staffed okay like. So okay, so here's here's a performance issue that has not yet been solved. I went to the cocktail team and I was like this thing is quadratic in ah, the number of arguments to the function like what you're doing underneath the function should not be quadratic and how many arguments there are to the function. 

Okay. 

Hmm yeah the one of the cocktails looked at it there were actually two different parts and I was like both of these things are quadratic in the number of arguments the function cognitive team looked at it and was like, oh there's different sources of quadraticness in the two different things and the reason for the worse. 

Source of quadraticness was that when you refer to? Variables, they you do it by number. And so when you have a closure when you have a like. Function object that is like waiting for extra arguments, but it like refers to some of the arguments that exist and you like move it beneath more binders, you need to update all the numbers. 

So you're doing it a second time. But the way that they update all the numbers is every time they move beneath one binder they have a thing a thunk that's waiting that says when you go to look at this function bump all the numbers by one. I see and then you move it under another binder and you add another thumbs that says when you go to look at this function bump all the numbers by one so when you put it on their end binders n times, you say plus one plus on plus one plus one plus yeah and then it's quadratic yeah. 

And no one realizes this because this part of the system is pretty fast and no one was dealing with functions that had a hundred or a thousand arguments. And so this part of the system went unstressed in order to find that this is the issue you need to know how to you need to like know the slowness you need to know what it's slow in you need to know what the algorithm is doing and for like complicated software that relies on. 

Like down to your mouth, this is not always trivial. If it's in a part of the code base that needs to be trusted then if you make any changes like they need to like you need to get them correct or else you trusted so caucus split into two parts, there's the part of the system that ah is called the kernel or the trusted code base. 

And once you get a proof this part will be like yup. I believe the proof for like nope your proof is bad. And then there's the other part that is like here's magic and it will make purse for you, okay, you're like I have an arithmetic expression please prove that it's true and there's a bit in this other part that's like I know how to prove arithmetic expressions and it gives the arithmetic expression and then it generates a certificate or proof that this other trusted part tracks and if the part generating the arithmetic proof is wrong then the users come complaining to you that you have a bug. 

If the part checking the proofs is wrong. Then you don't see the bug and now suddenly your users can prove anything they want. And the system is no longer trustworthy right and so for that bit of it you need to be very careful with any changes you make. So there's this like cornucopia issues that makes like improving the performance in these sorts of systems a bit tricky. 

Ah. 

And this part of my thesis. I will like. Point to a couple of other like a sort of palette of like examples of ah, slowness issues that come in come up and talk that are sort of heard to tell where exactly they come from. Hmm. 

Okay, so that's the like introduction introduction and like. Palate of slowness. The next section is one of the two big sections on like components of the system that is important for performance and this section is geared at users of proof assistance mainly. And. This is about how to design your APIs. 

How to design the like interface of functions that you're doing so. Most a lot of languages have a type system this is things that are like if you have a function that takes a string and you pass it an integer you want to know that you made a mistake. 

And caulk cock has this on steroids because not only can you say this function takes an integer where this function takes a string you can also say things like this function takes if this. Turing machine holds an element of the one element set and if this turning machine does not halt an element of the empty cell, you can't quite say that but you can say if it holds within n steps see you can say this takes a number n and the turing machine t and if, T holds within n steps then it takes an element of the one element set and if t does not hold with an end steps that it takes an element of the empty set what is the utility is this kind of precision, oh this lets you pass around troops. 

Like just by virtue of being able to call the function you have a proof that some fact is true. Right okay, so it's like a computation like means to make things more efficient than oh it's it's a source of power. It's like. Let's you write functions about that like taken proofs that you and like let's you write functions that prove things correct it let's you do things like this is a function that takes an approved that ah, This list is not empty and it's out of proof that like if you append that list to itself the resulting list is not empty. 

This is useful why because you want to prove things. Okay, for example. Maybe you want to say. This function takes in a C program. It takes in. A function that's describes the behavior of the C program and it takes an approved that the C program matches the behavior of the function. 

And what it spits out is some assembly code and a proof that the assembly code matches the behavior of the function. I see. 

And like this is how you get verified programs, but it doesn't matter the thing where you said that well. I still understand the part of like why using it as a function is useful or something. Like making a function out of it what's the alternative if you didn't have it like as a function calling it like what are you saving when you have a function that does this oh so it's sort of a question of how you found your mathematics on or like how you how you're doing mathematics, so like one way of doing proofs is that ah programs improve through the same thing. 

So you can reuse all the machinery for writing programs to also write proofs and you can reuse all the machinery for like making sure that a program is well typed to making sure that a proof is valid. Okay, it's kind of neat a different way you could do it as you could found your math on set theory and you could be like, I'm just applying axioms. 

This is how proof assistant called Isabel. Hall works almost for higher order logic. 

What is the higher order logic h o l. 

So like there is a sort of design choice of like what? Like how you're building your prefix system tonight out have much to say about. Preface systems that are not based on type theory, okay? Oh. Other questions no okay so. Great so you can put arbitrary amounts of computation into this like thing that in other languages is used for checking that you don't try to pass an integer as a string. 

Um, and that's kind of neat it's kind of cool it also turns out to be. Useful because the part that does the checking is decently optimized in particular when you're like running fully running a program that's pretty optimized and so if you can stick all of the proof like all of the hard work into this question of how I passing an element of the empty set or of the one element set. 

Then you're like, you'll happy. Um, Also if you restrict yourself. To only asking questions like do I have a string or like asking questions like please make sure I have a string not an integer. You're also pretty happy like things are fast you need to do your proof separately but things still work nicely. 

The problem is that with all this power. That usually works it's like very tempting to use a and so you're like, okay, give me a list give me the length of the list also give me a proof that the the list has that length. And like this is fine and it works fine until you try to scale it and then it doesn't okay, ah because you're like okay, well if I like. 

Append to lists. I spit out a proof that like the so I spit out that the length should be like the sum of the two lengths I spit out of the proof that like the depending of the lists has length equal to the sum of the two lens. And then you're like okay and if I reverse a list it keeps the same length, and maybe now you want to like match like in one part of the code you were like I reversed my lists and then I appended them in reverse order. 

And another part you were like I I like first depended the lists and then I reversed the whole thing and like these are the same and I should be able to know that they're the same. 

But now here you're like length one plus length two and here you're like length two plus one. And so now your numbers are in the same and you're proofs are different. Ah, and maybe you manage to like make call accidentally try to figure out exactly what the proof is. 

Rather than trying to just like verify that your numbers line up or something. And now suddenly it's spending a lot of time trying to figure out exactly what your complicated proof is. And this is why you when you like make your example a little bit bigger and careful on this place it like takes the other path and now instead of being like, oh oops. 

I guess this path doesn't work after one second now, it's like. I'm gonna keep trying for a month hmm. And then you're real sad. 

So the the lesson today out of this is like either put all of the work into the ah into the types. We're all turnatively like either but all of the work into the computational power at the types, or make sure that you're not using the computational power of the types at all. 

What you mean not using the computational power of the types at all, you're not computing anything when you're asking like is string the same thing as string or string the same thing as integer, oh what would you do instead oh I mean there there's like nothing to compute you just compare them, okay? 

Right and then you're like, um, but like what about the identity function applied to string and you're like yeah yeah that's fine and so you can do a little bit of computation but if you're not careful then you're then you end up in this land where you're trying to compute with proofs and if you're not being careful, then you explode what's the extra stuff that you get from using the identity function versus comparing two strings, ah, Like what does it become more efficient or like what's the utility so like? 

Generally how it works is that you get to do more abstraction. Like. Like if you've ever dealt with monads in Haskell. 

There are fancy abstraction things that you can do with it, okay and like most of them don't require much computation at the type level the require a little bit of computation at the site level. Um, that's fine. And it's also fine to do all your computation at the type level but it's not fine is when you. 

When you're sort of like well do as much computation as you need. And if you're not being careful about how much computation is done at the site level, which you're usually not like it's something that's hard to track. Then and it's like the computer doesn't help you because you are going to like it it keeps working on small examples, but then you're real sad when you. 

When you end up with a little bit too much. 

Okay so that's that's this first section those the second section right oh like the first one it's the first of the like two big chunks of like things you want to do right this this thing so this part of cop that's like checking if two types do the same this is called conversion, okay, so the sections and conversions oh it's on like performance bottlenecks and conversion, okay? 

So the next section is on an sort of the other main thing that you one of the other main things maybe the other main thing that you want to do your structure because you want to do you're recording this right? I'm recording this yeah, but my dearly new structure because of structure that I have is. 

Not very structurally, what do you mean? I mean, it's helpful you ask these questions and I'm like, oh, I'll probably need to explain this bit here that bet there okay, yeah. Like I'll probably try to get Google to transcribe this and then edit it a bit and turn it into an outline. 

So thank you more words to say no. I get all the words you're saying you have so much stuff maybe um, so the other thing you might want to do in caulk is. A program transformation or rewriting so this is like sometimes you have one. Program and you want to turn it into another program typical example of this is your writing a compiler. 

Or you have some things and you know that some other some things are equal and you want to like replace things with other equal things you want to do like equational reasoning. 

Right? And all custom built-in tactics for this and they work on small examples and they don't scale. And they're sort of notorious for not scaling. And there are a number. Of ways in which they don't scale some of which are probably just artifacts of how they're designed some of which are issues with how things are set up. 

Some of which are potentially fundamental issues to doing this sort of thing. And. 

The. Solution that I will be proposing in my thesis. Is that it turns out that you can do all of this program transformation rewriting stuff by shoving it into the part shoving it all into the type level. Serving it all into the part of like this part of the system that's been heavily optimized for a particular type of computation. 

So what is it in before you shove it into the type level, right? So I talked before about two different parts of the trusted good base with the kernel and this large bit around it. And previously there in this large bit around it. And so what this looks like is that you're like I have this equation. 

Please take my thing, maybe it's an expression, maybe it's a program whatever and transform this bit to this other bet. And caucus like okay, I know that those two bits are the same. Let me generate a proof that you're like program with the first bit is equal to your program with that bit changed. 

We had it cloud generate this. Ah, there's a standard way of generating it. Okay, it has one of the built-in tactics tactics or things that generate proofs. It knows how to generate this sort of proof. And that's fine when you're doing one step. But maybe you have a program that's a couple hundred lines long. 

Or thousand lines long and maybe you wanted to like one transformation in each of the lines and so you're doing like a thousand transformations, which is like should be reasonable. I will as an aside the like main project that I've worked on uses needs code sharing and student program transformations with code sharing. 

What does that mean? So you're like let x be a plus a and then let y be x plus x then let's z by plus y and you have a bunch of these and if you inline to all of them then your program blows up in size. And so we want to do maybe you had like an extra plus zero on all of these. 

You want to get rid of the plus zeroes without inlining everything. And like caulk has ways of generating fruits like this. But their quadratic and how many are like each individual transformation is linear in the number of variables, you've allocated above it. Which makes it quadratic in the leg or like makes it a product of how many lines you have and how many transformations you're doing, right? 

Which and the like quadratic factor is you're like okay, it's quadratic, but like how bad is the quadratic? And adding up each of them, what is it like one plus two and then the next one is three or is it the next one's four oh because you're doing everything that the second one did and it's it's like one plus two plus three plus okay, oh but like the quantity like if the scaling factor is like a nanosecond yeah and you're dealing with a couple thousand you're like couple thousand nanoseconds, whatever. 

If the skeleton factor is a minute, you're like couple thousand minutes or like thousand squared minutes that's pretty terrible yeah and so the scaling factors work out so that like, 50 to 100 lines, you hit like about a minute. And the programs that we worked with went from about 90 lines up to about 900 lines see so if you hit a minute at like 90 lines, you're not gonna be able to handle 900. 

So that's that's sort of what the section is about. Oh what we see outside of the specific example of like inlining this thing where you referring it's oh well, so you need to not inline it but you're doing like arbitrary code transformations, okay this program. And the tool that I have let's you do like there's somewhere restrictions on what kind of programs you can handle and it's a research prototype so there's a bunch of restrictions there mostly engineering work. 

I think to lift. But it puts all of the work in the in the like fast part of caulk the running time is constant sorry the not to run it the proof size is constant in the number of steps. It's like linear and how many lines of code you have hmm right so before we had a quadratically sized proof because every step had its own proof that encoded the entire program right and so you chain all these together and you'd be sad. 

It's unclear whether or not this is actually the quadratic bottleneck in. The existing parts of the system like it's a real hard to diagnose. Like what exactly the issue is for musings that I will hopefully mention in the initial section where I was like palliative things that are hard like another thing that makes it hard is that caulk is written as like a big mutual recursive block which is like you keep jumping around between functions and so looking at like where am I spending my time is real hard to pin down because you're like well all the functions and like even. 

So even if you know what function you're spending time and it's not necessarily. Easy to tie to like user level things because maybe you're spending a lot of time type checking this quadratically sized proof and like making sure that things light up. Or maybe the. Like could transformation equational rewriting bit generated a proof term that used more power than it needed to like use the more type level computation and so you're spending a lot of time exploring bad roots. 

Unclear. 

Or maybe you're spending a lot of time in a completely different part of the stuff like there's some other parts of the system that are quadratic or cubic in like how many lines of yeah like how many variables you have for stupid reasons. That are nevertheless very hard to fix. 

Ah. 

And like so like here's another example that will probably go into the first section. Sometimes you want to introduce you want to like do things underneath a bunch of variables. And. 

Every time you do a thing you need to create a new goal state. And you need to relate it to the old goal state. And this has cost that's something like linear in how many variables exist in the goal state. And. So then if you want to introduce a bunch of things if you do have one out of time, you'll be creating one new goal state for each variable and each one will have cost linear and how many variables were above it and now oops it's quadratic to introduce and variables and do something underneath them that's sad there might actually be another linear factor here. 

I think it might end up being cubic. Yeah and so like being modular in a bunch of places like runs real hard against being fast. 

Yeah. So anyway back to this this part of the system of doing program transformation, so I'm going to present the like new tool that I have. I probably will have a section that's like if you're looking to implement your own purposes, then that is like incorporating this here the details of all the things that went into like building this tool. 

If your user that's looking to use this you don't the section is not for you. Another bit that will show up in this section. Is sorry I just remembered another bit for the previous section maybe I'll say that first the previous section the one about how to design your API is about conversion one thing that I will probably mention is a neat trick where you can convince caulk that two different theorems are actually the same and can have the same proof. 

What do you mean convince call? Ah, if you. Design your theorem very carefully then you can make it so that caulk the like bit where you're like conquer these two things the same are the types the same. If you design things very carefully, you can get cock to say yes for two different theorems and then one cox is yes, you can say look. 

I have the same proof for both them. So this is not true no it is true right so so this the sort of thing you do this with um, so in category theory you have objects and you have errors between them. And there's a common thing that you do in category theory where you're like if I flip all the arrows around. 

Nothing changes. And so if you're very careful about how you set things up in caulk you can flip all the arrows arrows around and say cock did anything change cock will say like nope nothing changed. 

Um, but if you're not careful then it doesn't work. 

Uh, yeah, so that was an extra bit for the previous section extra bit and the second section the program transformation one. Is that I'm hung up in a probably not useful but you can change one of the errors or like it's set up in such a way like there's like one exception or something what do you mean like there's a break it like if there's like one function that you can this is mathematics there aren't exceptions there's like one function like okay, so you're taking something that has in verses all around. 

It's not something that has inverses it's your. Your putting on it's like like when you put on upside-down classes. You're putting on arrow flippy glasses. How are you flipping the arrows okay, so here's a definition of what it means to be the empty set okay to be the empty set is to have exactly one function from you to any other set. 

Here's a okay, so now let's flip all the iris. What does it mean if there's exactly one function to you from every other set? Now you're the one element so. 

Any theorem that is a sufficiently abstract to be cast in terms of arbitrary categories. If it applies to the one element set there is another version of the theorem that applies to the empty set. 

Okay. That sounds a little bit better but I have made full sense of it but that's on me go on it's a pretty cool trick yeah and it's more cool that I can convince talk to do all the work in a that. I don't have to do any of it so back to the program transformation section. 

Sorry. I was just considering that I had told zoom to record separate audio for each of us for this call hearing to see if I'm sad about that. Why would you be sad about that if I want to transcribe it and it's missing things. I guess I can combine the audio files in audacity, it'll be fine. 

Anyway, so the section about program transformation. One of the steps that you have to do is you want to take your meaning of the program and turn it into a syntax tree. What does that mean so the meaning of the program might be something like take these two numbers and add them and here's how addition is defined the syntax tree might be? 

You have a function node called plus and it is applied to two arguments and one of them is the variable with this name and the other one is the variable with that name yeah isn't that what the whole thing is anyway what oh. So. Are you writing the first thing like are you writing the meaning of the program are you asking called to generate you you write the meaning and you ask our quote the syntax tree is? 

How does clock generate that free you have to tell clock out a generator okay, um and the default the like obvious way of doing this is slow. For disturbingly similar reasons to how Python is slow. Because if you write it in the language of proof, script automation, you end up doing lots of things that you don't actually need to be doing. 

Like you end up. Making lots of intermediate goals and you end up spending a lot of time checking that things are the same over and over and over again. It's just hard to avoid in this language. You could spend more time writing in a better language. Or. For most of these kinds of problems. 

The part of the system that lets you do proof by induction. Can be repurposed to turn meanings into syntax trees. So one key component of doing induction is you're like caulk I want to do induction on this thing and here is the theorem that I'm trying to prove and cock needs to find all the instances of that thing in the theorem and be like in all of these places the induction variable shows up. 

And this is kind of similar. You're like, please find all the places with addition and replace it with the addition node. Please find all the places with subtraction and replace it with the subtraction node. And so you can leverage this facility that was there for doing things like induction. 

To do to give you abstract syntax trees out of programs. I see. It's pretty cute and it's also blazingly fast. Me. 

Ah. So the tactic is called pattern. Okay, but the I've named the method of doing this reification by parametricity. And reification is the you turn a per you turn the meaning of a program into the abstract syntax tree. And parametricity is the. It's about how. 

When you have very little information about things there's sort of only one thing you can do with them. I'm like, I have a function and it takes two types. A and B. And it takes in a thing of type A and it's the thing of type B. They returns the thing of type A. 

And you're like well, obviously it's just returning first one. That's sort of the only thing I can do. And I'm like well. 

If. You're in Haskell. Done or so if you're in Python then you can do something sneaky like say well if they're the same type then return the second one and otherwise return the first one but if you're in a nice language like caulk that's what's called parametric then you're not allowed to do that and really the only thing you can do is return the first one. 

Why does it matter? Oh we're sort of taking advantage of the fact that what you do is it's allowed to depend on. These sorts of. Details that you're not supposed to be able to look at okay, oh that if you claim to do something for all types, you have to do it the same for all types, you're not allowed to do it differently for some types then for other ones, this is part of the. 

This is part of the mathematics of caulk. 

What's this what? Um, is it the way coffee setup versus to call custom code okay and you trust that it implements the mathematics and then you also trust or prove that you hope that the mathematics is correct? And people write papers about the mathematics, they don't write papers about the code. 

You you ideally you should prove that they could match us the math right with some people working on that. 

But yeah like like one of the bits of the the the trusted part is like, how do you check that two things are the same? And like in particular how do you do this quickly and like what how do you just if you're like checking that two things are the same and you want to know whether to do computation on the left or on the right, how do you decide which one to do first and like this is not a thing that shows up in the mathematics. 

But it is a thing that shows up in the trusted code base. Yeah. 

Okay, so I think to finish up what I was saying were. Relying on the fact that you don't get to do different things depending on different types to let us like swap all of the things out for different things. That you can notice are different. 

So those are the two main sections the thesis. And then there's another section of other small. Miscellaneous things that come up better like performance bottlenecks. Through like can or performance concerns, let's say these are things like decide design decisions that can have quadratic impacts. Um, Decisions about like what parts of cop to use for what and like why some bits might be more or less slow than others. 

Yeah, that's that's that section and then I think I'm going to have seconds last section. Be a sort of retrospective of like places where cocks performance has gotten better in the past like decade or so of like I started with a bunch of ways that solving performance issues improved systems is heard but here are some successes and things where like we've managed to improve things and you can actually like, Leverage this for faster performance. 

And then I think my current. I'm not sure if I'm gonna go with this for the conclusion but my my current thought that might be too informal for a thesis. Is something like perhaps this thesis has inspired you to write your own performance system and we remind you about the things you should look out for when implementing it. 

What are your other options? I don't have any okay, okay. I have I have two other options one of them is definitely much worse long one of the options. I just ended. Another option is I say the end and beneath that sewing category theory there's a construction called an n then a construction called the co-end and so I can put the category whole diagram for an end in either the end that's just the cutesy thing yes, okay, do you have suggestions for a better ending ah, 

Now it seems like you describe two things that people are fucking up and should fix or something and so it makes sense to be like yep just pieces should have inspired you to that make sense. Yeah. 

Doesn't make sense to go on the other direction it's like I've pointed it ways that previous systems perform or like fixing them as hard and like you couldn't look for other stuff in this domain that I've pointed at or something. 

They're like, oh the ways that I'm pointing it like solutions or something yeah, so maybe another thing to put in is like like what? Ah, like what are the next steps in criticism performance, mm-hmm and there's a paper that. Hundreds has flooded writing that I think is a good next paper to write. 

Ah, that is something like okay, so you've like, Followed all the tenants that I've laid out to like have fast APIs you're like very careful about where you're having called two things. And then you start hitting so brief historical perspective. I've described a bunch of like quadratic or exponential behaviors where like you're hitting. 

Areas of the system that aren't scaling nicely. There was a previous generation to this where pretty much everything was quadratic or exponential in like everything and so you couldn't do anything beyond a certain scale because everything would start blowing up on you I see and there was someone before me named George got there who when working on he was the one who led the team at Microsoft Research to you formalized the four color theorem. 

I think now not the four color theorem the odd order theorem. In call okay took them about ten years. I think you've mentioned this yeah oh and he went on the cocktails and they fixed these like everything is terrible and everything. So now we're heading like problems that maybe maybe are more fundamental to proof assistance. 

But like then you you design your things carefully and you're careful about which parts the system you use and you'd like count for every step. And then you start hitting the next class of problems, which is I have a couple thousand things. A couple thousand variables and I want to introduce them all oops adding a couple thousand like adding n variables is quadratic or cubic in the number of variables that I'm introducing that's unfortunate. 

Um, or you're like I want to like change my goal state oops making a new goal state is linear in how many variables there that's sad now. I'm now by running time is quadratic in the number of goal states or something mm-hmm. 

And like you hit all of these like the fundamental building blocks. Are too slow. And. That's sort of the next area to investigate of like how do you build a proof assistant so like what are the fundamental building blocks? How are they too slow? Huh the how do we know there are two slow what what are the factors that they're too slow and like can we show that there's like no way to get anything to actually scale without completely re-implementing the profanion because that's basically what I what I said for program transformation. 

I'm like look the existing thing it's quadratic it's real sad let's throw it out and write a new one and stick it in the part of the system that's fast. So like yeah, you can do that for all your proofs you can throw out the entire pure system and write a new one. 

But like, Would be nice if you didn't have to do that we say that again. So like you're like, okay, I was trying to do this thing no just the last sentence, oh it would be nice if we didn't have to do that yeah. So the alternative is to the to the alternative is that you figure out what the primitives are what they're too slow and why they're too slow and how do you design a proof assistant like a proof engine with primitives that are actually performant that if you're carefully accounting for all of the primitive steps that you're doing in your proof then you can actually get a proof with reasonable performance. 

Like all the things that I've been describing are. You slap something together and it works on small things and then you increase your you try to scale it and it's suddenly stops working because of exponential behavior. And like, Maybe there isn't a hope of fixing that if you slap something together. 

But if you're like carefully engineering your proof, you should be able to avoid that. What is the careful part like can you describe that or is it just like the thing so? Okay, so here's how here's how beginners pure things in caulk. Their teacher tells them what they're trying to prove. 

They look at what they're trying to prove they look at the list of things they can do they're like, oh I'm trying to prove for all X something. I know a tactic to use. I'm gonna use interest. Oh I'm trying I have a conjunction in my hypothesis that I know a tactic to use I'm gonna use destruct. 

I'm trying to prove something about natural numbers, how do I prove something about natural numbers by induction? Where you have this very simple pattern match that are matching program that's running in a brain that you're like how do I do this thing one step at a time? I'm just gonna try a thing and see what works we have some arithmetic, let's try simple let's see if cock knows how to make it simpler there's a tactic called simple without the, Okay, um, sometimes it makes things much nicer. 

Sometimes it makes things explode, sometimes it runs forever and gives you nothing it doesn't actually ever run forever pretty much. But running for a year is about as good as running forever. 

And so you'll try it and if it works then you're like great it worked. I can keep going yeah and if it doesn't work then you're like, oh I guess it didn't work, let me try something else instead. And like this is this is how beginners implement proofs and like the way I do proofs is I'm like, okay, let me figure out why this thing should be true. 

And let me figure out what gets me closer to my understanding of why it should be true and then I run the same kind of simple program that um that beginners run that's like, oh this should be true by induction on this variable. I'm not just doing induction randomly. 

I know why I'm doing induction on what and I'm like, oh I have this conjunction. I can split it apart. I have this disjunction I can split it apart and like I keep making steps and at each point. I'm like, am I still convinced that this theorem is true? 

And if I have ever I'm like, oh doesn't these seem like this true anymore that I'd like backup but otherwise I just keep going as long as I'm convinced that the theorem is still reasonable. Where you say something like you do things by figuring out why something should be true is that like. 

Is that like constructing approved sketching your head and then doing it versus someone being like oh I know what tactic to implement them, therefore. I will try to construct yeah it's like using a proof method to generate a proof versus knowing what you want to prove and then writing it need to or something oh where is this something different like how does it apply to the engineering case? 

I think it's something like that okay, so the thing that I'm doing is I'm like do I believe that this is true when I explain to a very intelligent five-year-old why this is true. And then I'll make steps unlike if at any point. I hit a theorem that I or like I hit a state where I'm like. 

This is doesn't seem true anymore. That I'll like back up but I and like I have a big sense of the proof in my head okay, oh but it's like I'm like, okay this this should follow by arithmetic. So then I do a bunch of arithmetic like things and eventually hopefully I get out a thing that's true, but it's like if I want to prove that something is true by arithmetic. 

I can just like look at my thing take a step that makes the thing simpler and if the thing still seems true that I'm like great I made it simpler now what and like I can keep taking steps to make it simpler until it's done and I don't have to have a like entire proof in my head. 

That's interesting. Don't yeah yeah, this is because I got lined by line feedback on my prefixes. I go along it's great. Yeah. The problem with doing things this way is that they don't scale yeah it seems hard like. It seemed like I feel like with most problems you have to kind of have a proof in your head and then use the syntax to like. 

Make it so let me let me also clarify yeah the sorts of proofs currently that you need to do in caulk or way simpler and the more tedious and the sorts of proofs that you're thinking of here's an example of a proof that you might have to do in caulk, um, this is this is like on the interesting end of proofs okay, oh if you, Have a loop that adds up all the numbers between one and m. 

It's the same thing as multiplying n times, m, plus one dividing by two, okay? This is the interesting proof here's another interesting proof, we're merged sword and bubble sort give you the same list if you give them the same list then. In both cases do just do it you you prove so the things you need to prove is you need to prove that they're included or do you just run both things and say no you can't run both things because you need to prove that it's true for every single list, right? 

So yeah so the way that you would prove this is you define what it means to be sorted better to be what it means to be a stable sorting of a particular list, maybe you don't need that. I think you can just define what it means to be sorted and what it means for like two lists to be the same up to permutation and you're like for any list there's a unique list, that is the same up to permutation and also sorted. 

Look both of these sorting methods produce that list. Okay, oh and like this is at the interesting end the like standard end or things like, um, 

If I have a binary tree that holds numbers. And I add one to all the leaves then I take the sum of all the leaves. The number that I get is the number of leaves plus the sum of all the leaves before I added one. 

You know, it's these sort of like trivial structural properties. 

A lot of time is that proving trivial structural properties. I see so so it's not like you like there's like a it's often not like you're missing a concept and understanding how to generate the proof or something but you need like an elegant way to like structure the proof or something and that's the part where you're saying that the beginner would just be like here's tactic. 

I will apply it anywhere like oh what's the good structure to do this or something? I mean, even I'm not what's the good structure to this? I'm like what's what's the structure to do this that isn't wrong? Okay, the beginner is like, Like cargo culting Margo what cargo holding that means? 

I maybe it's originated from Richard Feynman and that. There are some places where the. Ah, like livelihood of the tribes depended on like airplane deliveries of cargo. And. Like there was always a ritual associated with the cargo showing up where you like wave the lights in the air so that the airplane can land on the landing strip. 

And so you can like there there were some cults so I hear I don't know how accurate this is that developed around this where people would waive the lights in the air hoping that this would make the airplanes in the cargo show up. I see right so you can do the same sort of thing with programming you're like, oh I found the program that does the thing. 

I want maybe I can take the code and maybe it'll do the thing. I want. And like you'll also include all the other care and like you're like, why is this other code here? Well, because it was in this other program that did the thing that I want. I don't know if I need it. 

So like why are you doing this proof like this because the example proof that I saw had this structure and it worked through the system was like, okay. Yeah, right. So I am I'm at a more advanced level where I'm like, okay, I know that's a proof things about binary trees. 

I'm gonna go by induction on the binary tree and I'll do something with the number of leaves and I'll figure the rest of the details out as I go. 

And this is how most proofs get done. You do them piecewise. And you like don't account for like how much work call has to do at each step, you're like try it. So work it works then it's good doesn't work that it's bad. And like you could carefully in your head design the entire proof and like carefully account for how much work you expect cock to have to do at each step and make sure that cock shouldn't have to do any work that you don't think it should do. 

But very few people designed proofs like this. But it should be possible to get a proof that is fast if you design it like this and like the next wave of performance issues is going to be that even when you're designing proofs like this things are still not fast enough. 

And so then that's Cox problem. That's the like, how do you design a proof assistant with good enough primitives? Right, yeah, right. I'm like, look you can just. Throughout throw out the prevention. Do this other thing instead works nicely. 

But like it would be nice if you don't have to do that. To get things to scale. 

And yeah, that's that's the sort of next step. Right. Now, that's not like a nicer conclusion. Next step is all these very inspiring. 

Maybe maybe that paper will actually get written at some point. Yeah. Okay. I think this was helpful. Hopefully. Google will be successful at transcribing it. It's not you can listen to the recording with a pen. It sounds terrible. I can listen to the recording of the pen. I like transcribing. 

I would rather with a keyboard because transcribed from pen to La Tech. Now, yeah here. Well, if you're willing to do that for me and Google doesn't work. I might take you up on that. Yeah, I'm just like low and energy right now, but like presumably in my few days. 

I'll be more free I could do it. I mean, I also don't want to actually make me do it. Yeah. Yeah. I agree feels kind of like taking advantage of you or something. No, probably entertaining. It's like adult coloring books. Yeah. Yeah. 

I feel torrent between working a bit more on code and packing. How much do you have to pack? Mostly I just need to like make my laptop and stuff. Do you want to not zoom call for like five minutes because they're packing even? Yeah, this is recording. Well, let's do that. 

I'm gonna hang up. Bye. Bye.