\chapter{The unique challenges of performance in type-theoretic proof assistants} \label{ch:perf-failures}



\begin{subappendices}
    \section{transcript from Adam}
    You're like performance issues and look like this is what makes them hard and I want to like, It'll probably it's I should probably like say the things that I'm thinking of including in this section because you'll probably tell me that some of them are not good to include. So I'm thinking of including like both deep and mundane issues and one of the things that I want to point out is that it's hard to figure out like what the performance roots are. 
    
    And. One example that I want to pull that seems like a good example to give here is like a like one of the examples in the palette of performance. Troubles is the quadratic behavior of CBV on the number of finders. And. The ultimate issue here is the cock uses NDE to do to implement CVB and the way that they move closures under binders is they add a thunk that says bump all the point indices by one. 
    
    And so if you move it under and binders you add unthanks that add one to all the different indices you mentioned one of these design choices in caulk. I think you will be good to do your best to explain why it's not terrible any that you should finish ever to try. 
    
    Oh interesting. I feel like. 
    
    So. Leaning on premature premature optimization is the root of all evil it is this seems like a fairly easy way to implement bumping the brain indices. And if you expect most functions to have order 10-ish binders, then you don't run into any problems and you can see this by the fact that CPV is not usually very slow, okay, yeah, I'm not necessarily trying to pull out these explanations from you now to apply things to see that we really want to try in this paper and this document and then say the next version we submit of our rewriter paper not to just present it as usual and into us by the gods we have to deal with that we want to explain why this is. 
    
    The tool we're connected to is somewhat representative of the community's knowledge about how to build a good privilege system sure. Oh. Yeah. So like this to to finish up the CBV example, like the algorithm that they have tends to work, it's tends to be fast enough and even catch this. 
    
    Performance issue either you need to be the one who wrote the code in the first place or you need to be actually playing with hundreds of binders. To notice it. To diagnose it. You need to understand the algorithm in part because all of caulk is like a big mutual recursive lock and soon call traces turned always give you relevant data. 
    
    And also because you're implementing mathematical algorithms that are non-trivial. And because it's I think CBV is not. In the trusted code base. But. You could imagine it's possible that lazy has the same issue. I'm not sure if it does it might. And if it does then it is part of the trusted code base. 
    
    And so then you can you need to be careful when you're optimizing because you still need to trust the resulting code. And so you have this. Confluence of a bunch of different restrictions that they hit hard to catch and diagnose and fix the performance issues, yeah. Even when they're Monday and like this, that sounds okay. 
    
    Yeah. 
    
    And so another another example from this is that oh. Building proof terms step by step every time you need to create a new. Evar for the goal and. When you create the new Eve already you need to relate it to the you need to relate it's context the only verse context. 
    
    And it turns out that this is something like linear in the number of things in the context. And this is usually fine because your context are usually not more than a couple hundred things big and you're it's usually the case that the individual steps in your approved take more time than the like transition between steps in the proof. 
    
    But this means that if you want to introduce say a couple thousand variables and you do it one of the time you're now something like. Ah, like quadratic. In the republic. I can't remember if it's quadratic or cubic there might be another linear factor somewhere in there and call okay, but you have like that performance in the number of variables you're trying to introduce for this like very simple tactic and this one is sort of less obvious how to solve it. 
    
    Sure. And say like that's that's another thing that's hard. Oh and so I think in this section now probably go digging up a couple other performance issues that unlike pain this picture of like widely ranging performance issues in terms of how hard they are to solve but the commonality is that it's. 
    
    Complicated to tell ahead of time like. It's like hard to find the performance issue and know how hard it'll be to solve, okay? Oh so that's how I want to sort of end the introduction. Makes sense to me. It does sound like you've been pretty clear you would go there so I figured out remaining time that's more useful to talk about earlier parts that are fuzzier yep sounds good. 
    
    
    \section{transcript from Rajee}
The first bit is about what makes performance in proof assistants and Coq challenging. In most languages, or in most most areas, the performance story is that you do a thing and you make it fast on your toy examples and you do larger examples and hopefully it's still fast and then you do much larger examples and maybe it gets a bit slow and maybe for the largest of examples you need to like let it run overnight or something. 

The experience in Coq frequently is that you do something and you get it to work on your toy examples and it's fast and you do slightly larger examples and it's still kind of fast. But it's noticeable. And then you do somewhat larger examples and now it's slow and annoying but still okay.  And then you make your examples a little bit longer and \ldots{} maybe it won't finish for a week. Or longer.  I ran into a case where I had a thing and it worked and for the larger examples it would maybe take an hour to finish, and then there were some examples that did not finish after about 900 hours.  Not for any deep reason, though.  Just because we weren't careful enough in setting up conversion checks, and so it would take a really long time to just run \texttt{abstract reflexivity}.

And this is sort of common in Coq where you'll get something and it'll work and if it works then you just leave it and then you try to scale your thing and now suddenly you've hit one of many instances of quadratic or exponential behavior and now it's unclear if it'll finish in a year.

This is performance of compile time by the way, this is like performance of how long it takes to check proofs.  If you're writing programs and you want to prove things about them, how your programs perform is subject to the same optimization techniques as other languages, but the issue with using those techniques for how your proofs perform is that usually, for most languages either a library is slow, and you know it's slow and it has known performance characteristics; or the code that you wrote was slow. Here, there are many many bits of the compiler that usually just work and most the time you don't need to care about how they work; they just work \ldots{} until they don't.

So why don't they work?  There's various reasons.  One of them is that the Coq dev team is understaffed. Here's a performance issue that has not yet been solved. I went to the Coq dev team and I was like ``this thing is quadratic in the number of arguments to the function; what you're doing underneath the function should not be quadratic and how many arguments there are to the function.''  There were actually two different parts and I was like ``both of these things are quadratic in the number of arguments the function''.  The Coq dev team looked at it and was like, ``oh there's different sources of quadraticness in the two different things and the reason for the worse source of quadraticness was that when you refer to variables, you do it by number. And so when you have a closure, when you have a function object that is like waiting for extra arguments, but it refers to some of the arguments that exist, and you move it beneath more binders, you need to update all the numbers.  So you're doing it a second time. But the way that they update all the numbers is every time they move beneath one binder they have a thunk that says ``when you go to look at this function bump all the numbers by one.'' And then you move it under another binder and you add another thunk that says ``when you go to look at this function bump all the numbers by one'' so when you put it under binders $n$ times, you say plus one plus on plus one plus one and then it's quadratic. 

And no one realizes this because this part of the system is pretty fast and no one was dealing with functions that had a hundred or a thousand arguments. And so this part of the system went unstressed.  In order to find that this is the issue you need to know the slowness, you need to know what it's slow in, you need to know what the algorithm is doing, and for complicated software that relies on complicated math, this is not always trivial. If it's in a part of the code base that needs to be trusted then if you make any changes, you need to get them correct or else your trust story is bad. 

So there's this like cornucopia issues that makes like improving the performance in these sorts of systems a bit tricky. 

And this part of my thesis. I will like, point to a couple of others, a sort of palette of examples of slowness issues that come in come up, and talk that are sort of hard to tell where exactly they come from.

Okay, so that's the like introduction palate of slowness.

\todo{this chapter}

\begin{itemize}
\item Descriptions of the order in which things fail?
\end{itemize}
\end{subappendices}