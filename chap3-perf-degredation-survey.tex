\chapter{The unique challenges of performance in type-theoretic proof assistants} \label{ch:perf-failures}

The first bit is about what makes performance in proof assistants and Coq challenging. In most languages, or in most most areas, the performance story is that you do a thing and you make it fast on your toy examples and you do larger examples and hopefully it's still fast and then you do much larger examples and maybe it gets a bit slow and maybe for the largest of examples you need to like let it run overnight or something. 

The experience in Coq frequently is that you do something and you get it to work on your toy examples and it's fast and you do slightly larger examples and it's still kind of fast. But it's noticeable. And then you do somewhat larger examples and now it's slow and annoying but still okay.  And then you make your examples a little bit longer and \ldots{} maybe it won't finish for a week. Or longer.  I ran into a case where I had a thing and it worked and for the larger examples it would maybe take an hour to finish, and then there were some examples that did not finish after about 900 hours.  Not for any deep reason, though.  Just because we weren't careful enough in setting up conversion checks, and so it would take a really long time to just run \texttt{abstract reflexivity}.

And this is sort of common in Coq where you'll get something and it'll work and if it works then you just leave it and then you try to scale your thing and now suddenly you've hit one of many instances of quadratic or exponential behavior and now it's unclear if it'll finish in a year.

This is performance of compile time by the way, this is like performance of how long it takes to check proofs.  If you're writing programs and you want to prove things about them, how your programs perform is subject to the same optimization techniques as other languages, but the issue with using those techniques for how your proofs perform is that usually, for most languages either a library is slow, and you know it's slow and it has known performance characteristics; or the code that you wrote was slow. Here, there are many many bits of the compiler that usually just work and most the time you don't need to care about how they work; they just work \ldots{} until they don't.

So why don't they work?  There's various reasons.  One of them is that the Coq dev team is understaffed. Here's a performance issue that has not yet been solved. I went to the Coq dev team and I was like ``this thing is quadratic in the number of arguments to the function; what you're doing underneath the function should not be quadratic and how many arguments there are to the function.''  There were actually two different parts and I was like ``both of these things are quadratic in the number of arguments the function''.  The Coq dev team looked at it and was like, ``oh there's different sources of quadraticness in the two different things and the reason for the worse source of quadraticness was that when you refer to variables, you do it by number. And so when you have a closure, when you have a function object that is like waiting for extra arguments, but it refers to some of the arguments that exist, and you move it beneath more binders, you need to update all the numbers.  So you're doing it a second time. But the way that they update all the numbers is every time they move beneath one binder they have a thunk that says ``when you go to look at this function bump all the numbers by one.'' And then you move it under another binder and you add another thunk that says ``when you go to look at this function bump all the numbers by one'' so when you put it under binders $n$ times, you say plus one plus on plus one plus one and then it's quadratic. 

And no one realizes this because this part of the system is pretty fast and no one was dealing with functions that had a hundred or a thousand arguments. And so this part of the system went unstressed.  In order to find that this is the issue you need to know the slowness, you need to know what it's slow in, you need to know what the algorithm is doing, and for complicated software that relies on complicated math, this is not always trivial. If it's in a part of the code base that needs to be trusted then if you make any changes, you need to get them correct or else your trust story is bad. 

So there's this like cornucopia issues that makes like improving the performance in these sorts of systems a bit tricky. 

And this part of my thesis. I will like, point to a couple of others, a sort of palette of examples of slowness issues that come in come up, and talk that are sort of hard to tell where exactly they come from.

Okay, so that's the like introduction palate of slowness.

\todo{this chapter}

\begin{itemize}
\item Descriptions of the order in which things fail?
\end{itemize}
