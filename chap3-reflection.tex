\chapter{\readyforreading{Reflective Program Transformation}}\label{ch:reflection}

\section{Introduction}\label{sec:reflection:intro}\label{sec:reification-by-parametricity:intro:old}

\minortodo{reformat this for flow, right now it's from reification-by-parametricity}

Proof by reflection~\cite{ReflectionTACS97} is an established method for employing verified proof procedures, within larger proofs~\cite{MirrorShardITP14,malecha2013mirror-shard,Speeding2017Malecha,gonthier2016small}.
\minortodo{should we cite this many things here, or remove some of them?}
There are a number of benefits to using verified functional programs written in the proof assistant's logic, instead of tactic scripts.
We can often prove that procedures always terminate without attempting fallacious proof steps, and perhaps we can even prove that a procedure gives logically complete answers, for instance telling us definitively whether a proposition is true or false.
In contrast, tactic-based procedures may encounter runtime errors or loop forever.
As a consequence, if we want to keep the trusted codebase small, as discussed in \autoref{sec:debruijn-criterion}, these tactic procedures must output proof terms, justifying their decisions, and these terms can grow large, making for slower proving and requiring transmission of large proof terms to be checked slowly by others.
A verified procedure need not generate a certificate for each invocation.

The starting point for proof by reflection is \emph{reification}: translating a ``native'' term of the logic into an explicit abstract syntax tree.
We may then feed that tree to verified procedures or any other functional programs in the logic.
The benefits listed above are particularly appealing in domains where goals are very large.
For instance, consider verification of large software systems, where we might want to reify thousands of lines of source code.
Popular methods turn out to be surprisingly slow, often to the point where, counter-intuitively, the majority of proof-execution time is spent in reification -- unless the proof engineer invests in writing a plugin directly in the proof assistant's metalanguage (e.g., OCaml for Coq).

\subsection{Proof-Script Primer}
\minortodo{rename this subsection}
Basic Coq proofs are often written as lists of steps such as \mintinline{coq}{induction} on some structure, \mintinline{coq}{rewrite} using a known equivalence, or \mintinline{coq}{unfold} of a definition.
As mentioned in \autoref{sec:intro:intro}, proofs can very quickly become long and tedious, both to write and to read, and hence Coq provides \Ltac, a scripting language for proofs, which we first mentioned in \autoref{sec:ltac-first-mention}.
As theorems and proofs grow in complexity, users frequently run into performance and maintainability issues with \Ltac, some of which we've seen in \autoref{ch:perf-failures}.
%\todonz{[re this paragraph, especially ``and hence Coq provides \Ltac, a scripting language for proofs''] seems repetitive and out of place. already introduced Ltac earlier}
Consider the case where we want to prove that a large algebraic expression, involving many \letindots\space expressions, is even:
\begin{minted}{coq}
Inductive is_even : nat → Prop :=
| even_O : is_even O
| even_SS : forall x, is_even x → is_even (S (S x)).

Goal is_even (let x := 100 * 100 * 100 * 100 in
              let y := x * x * x * x in
              y * y * y * y).
\end{minted}
Coq stack-overflows if we try to reduce this goal.
As a workaround, we might write a lemma that talks about evenness of \letindots, plus one about evenness of multiplication, and we might then write a tactic that composes such lemmas.

\minortodo{factor some of this with chapter 2}
Even on smaller terms, though, proof size can quickly become an issue.
If we give a naïve proof that 7000 is even, the proof term will contain all of the even numbers between 0 and 7000, giving a proof-term-size blow-up at least quadratic in size (recalling that natural numbers are represented in unary; the challenges remain for more efficient base encodings).
Clever readers will notice that Coq could share subterms in the proof tree, recovering a term that is linear in the size of the goal.
However, such sharing would have to be preserved very carefully, to prevent size blow-up from unexpected loss of sharing, and today's Coq version does not do that sharing.
Even if it did, tactics that rely on assumptions about Coq's sharing strategy become harder to debug, rather than easier.

\subsection{Reflective-Automation Primer}\label{sec:evenness}
Enter reflective automation, which simultaneously solves both the problem of performance and the problem of debuggability.
Proof terms, in a sense, are traces of a proof script.
They provide Coq's kernel with a term that it can check to verify that no illegal steps were taken.
Listing every step results in large traces.

\begin{wrapfigure}[8]{r}{\widthof{\texttt{Fixpoint check\_is\_even (n : nat) : bool}}}
\begin{minted}{coq}
Fixpoint check_is_even (n : nat) : bool
  := match n with
     | 0 => true
     | 1 => false
     | S (S n) => check_is_even n
     end.
\end{minted}
%\vspace{-18pt}
\caption{Evenness Checking}\label{fig:check-is-even}
\end{wrapfigure}
The idea of reflective automation is that, if we can get a formal encoding of our goal, plus an algorithm to \emph{check} the property we care about, then we can do much better than storing the entire trace of the program.
We can prove that our checker is correct once and for all, removing the need to trace its steps.

A simple evenness checker can just operate on the unary encoding of natural numbers (\autoref{fig:check-is-even}).
We can use its correctness theorem to prove goals much more quickly:
\begin{minted}{coq}
Theorem soundness : forall n, check_is_even n = true → is_even n.

Goal is_even 2000.
  Time repeat (apply even_SS || apply even_O). (* 1.8 s *)
  Undo.
  Time apply soundness; vm_compute; reflexivity. (* 0.004 s *)
\end{minted}
The tactic \mintinline{coq}{vm_compute} tells Coq to use its virtual machine for reduction, to compute the value of \mintinline{coq}{check_is_even 2000}, after which \mintinline{coq}{reflexivity} proves that \mintinline{coq}{true = true}.
Note how much faster this method is.
In fact, even the asymptotic complexity is better; this new algorithm is linear rather than quadratic in \mintinline{coq}{n}.

However, even this procedure takes a bit over three minutes to prove the goal \mintinline{coq}{is_even (10 * 10 * 10 * 10 * 10 * 10 * 10 * 10 * 10)}.
To do better, we need a formal representation of terms or expressions.

\subsection{Reflective-Syntax Primer}
Sometimes, to achieve faster proofs, we must be able to tell, for example, whether we got a term by multiplication or by addition, and not merely whether its normal form is 0 or a successor.%
\footnote{%
  Sometimes this distinction is necessary for generating a proof at all, as is the case in \mintinline{coq}{nsatz} and \mintinline{coq}{romega}; there is no way to prove that addition is commutative if you cannot identify what things you were adding in the first place.%
}

A reflective automation procedure generally has two steps.
The first step is to \emph{reify} the goal into some abstract syntactic representation, which we call the \emph{term language} or an \emph{expression language}.
The second step is to run the algorithm on the reified syntax.

\begin{wrapfigure}[6]{r}{\widthof{\texttt{| NatMul (x y : expr) : expr.}}}
%\vspace{-45pt}
\begin{minted}{coq}
Inductive expr :=
| NatO : expr
| NatS (x : expr) : expr
| NatMul (x y : expr) : expr.
\end{minted}
%\vspace{-15pt}
\caption{Simple Expressions}\label{fig:inductive-expr-no-letin}
\end{wrapfigure}
What should our expression language include?
At a bare minimum, we must have multiplication nodes, and we must have \mintinline{coq}{nat} literals.
If we encode \mintinline{coq}{S} and \mintinline{coq}{O} separately, a decision that will become important later in~\autoref{sec:reification-by-parametricity}, we get the inductive type of \autoref{fig:inductive-expr-no-letin}.

Before diving into methods of reification, let us write the evenness checker.
\begin{minted}{coq}
Fixpoint check_is_even_expr (t : expr) : bool
  := match t with
     | NatO => true
     | NatS x => negb (check_is_even_expr x)
     | NatMul x y => orb (check_is_even_expr x) (check_is_even_expr y)
     end.
\end{minted}
%We have used \mintinline{coq}{negb} and \mintinline{coq}{orb} from the standard library for boolean negation and disjunction respectively.

Before we can state the soundness theorem (whenever this checker returns \mintinline{coq}{true}, the represented number is even), we must write the function that tells us what number our expression represents, called \emph{denotation} or \emph{interpretation}:
\begin{minted}{coq}
Fixpoint denote (t : expr) : nat
  := match t with
     | NatO => O
     | NatS x => S (denote x)
     | NatMul x y => denote x * denote y
     end.

Theorem check_is_even_expr_sound (e : expr)
  : check_is_even_expr e = true → is_even (denote e).
\end{minted}

Given a tactic \mintinline{coq}{Reify} to produce a reified term from a \mintinline{coq}{nat}, we can time the execution of \mintinline{coq}{check_is_even_expr} in Coq's VM.
It is instant on the last example.%, \mintinline{coq}{10 * 10 * 10 * 10 * 10 * 10 * 10 * 10 * 10}.

Before we proceed to reification, we will introduce one more complexity.
If we want to support our initial example with \letindots\space efficiently, we must also have \mintinline{coq}{let}-expressions.
Our current procedure that inlines \mintinline{coq}{let}-expressions takes 19 seconds, for example, on \mintinline{coq}{let x0 := 10 * 10 in let x1 := x0 * x0 in … let x24 := x23 * x23 in x24}.
The choices of representation of binders, which are essential to encoding \mintinline{coq}{let}-expressions, include higher-order abstract syntax (HOAS)~\cite{HOAS}, parametric higher-order abstract syntax (PHOAS)~\cite{PhoasICFP08} which is also known as weak HOAS~\cite{weak2013Ciaffaglione}, de Bruijn indices~\cite{debruijn1972}, nominal representations~\cite{Nominal2003Pitts}, locally nameless representations~\cite{Locally2012Chargueraud,locally2007Leroy}, named representations, and nested abstract syntax~\cite{Nested2012Hirschowitz,deBruijn1999Bird}.
\minortodo{compare citations with those of \cite[p.~122]{ringer2020qed}}
A survey of a number of options for binding can be found in \autocite{Engineering2008Aydemir}.
\minortodoask{is this a place to cite POPLMark?  What should be said about it?  Should I mention more sorts of representations?}

Although we will eventually choose the PHOAS representation for the tools presented in \Autoref{ch:rewriting,ch:reification-by-parametricity}, we will also briefly survey some of the options for encoding binders, with an eye towards performance implications.

\subsubsection{PHOAS} \label{sec:binders:PHOAS}

The PHOAS representation~\cite{PhoasICFP08,weak2013Ciaffaglione} is particularly convenient.
In PHOAS, expression binders are represented by binders in Gallina, the functional language of Coq, and the expression language is parameterized over the type of the binder.
%We make this binder type implicit so that we can often omit writing it.
Let us define a constant and notation for \mintinline{coq}{let} expressions as definitions (a common choice in real Coq developments, to block Coq's default behavior of inlining \mintinline{coq}{let} binders silently; the same choice will also turn out to be useful for reification later).
We thus have: \label{sec:phoas-expr-def}
\begin{minted}{coq}
Inductive expr {var : Type} :=
| NatO : expr
| NatS : expr → expr
| NatMul : expr → expr → expr
| Var : var → expr
| LetIn : expr → (var → expr) → expr.
Notation "'elet' x := v 'in' f" := (LetIn v (fun x => f))
    (x ident, at level 200).

Definition Let_In {A B} (v : A) (f : A → B) := let x := v in f x.
Notation "'dlet' x := v 'in' f" := (Let_In v (fun x => f))
    (x ident, at level 200).

Fixpoint denote (t : @expr nat) : nat
  := match t with
     | NatO => O
     | NatS x => S (denote x)
     | NatMul x y => denote x * denote y
     | Var v => v
     | LetIn v f => dlet x := denote v in denote (f x)
     end.

Fixpoint check_is_even_expr (t : @expr bool) : bool
  := match t with
     | NatO => true
     | NatS x => negb (check_is_even_expr x)
     | NatMul x y => orb (check_is_even_expr x) (check_is_even_expr y)
     | Var v_even => v_even
     | LetIn v f => let v_even := check_is_even_expr v in
                    check_is_even_expr (f v_even)
     end.
\end{minted}

Note, importantly, that \mintinline{coq}{check_is_even_expr} and \mintinline{coq}{denote} take \mintinline{coq}{expr}s with \emph{different} instantiations of the \mintinline{coq}{var} parameter.
This is necessary so that we can store the information about whether or not a particular \mintinline{coq}{let}-bound expression is even (or what its denotation is) in the variable node itself.
However, this means that we cannot reuse the same expression as arguments to both functions to formulate the soundness condition.
Instead, we must introduce a notion of \emph{relatedness} of expressions with different instantiations of the \mintinline{coq}{var} parameter.

Such a relatedness predicate has one constructor for each constructor of \mintinline{coq}{expr}, essentially encoding that the two expressions have the same structure.
For the \mintinline{coq}{Var} case, we defer to membership in a list of ``related'' variables, which we extend each time we go underneath a binder.
\begin{minted}{coq}
Inductive related {var1 var2 : Type}
  : list (var1 * var2) → @expr var1 → @expr var2 → Prop :=
| RelatedNatO {Γ}
 : related Γ NatO NatO
| RelatedNatS {Γ e1 e2}
 : related Γ e1 e2 → related Γ (NatS e1) (NatS e2)
| RelatedNatMul {Γ x1 x2 y1 y2}
 : related Γ x1 x2 → related Γ y1 y2
   → related Γ (NatMul x1 y1) (NatMul x2 y2)
| RelatedVar {Γ v1 v2}
 : (v1, v2) ∈ Γ → related Γ (Var v1) (Var v2)
| RelatedLetIn {Γ e1 e2 f1 f2}
 : related Γ e1 e2 → (∀ v1 v2, related ((v1, v2) :: Γ) (f1 v1) (f2 v2))
   → related Γ (LetIn e1 f1) (LetIn e2 f2).
\end{minted}

Conventionally, syntax trees are parametric over the value of the \mintinline{coq}{var} parameter, and we require that all instantiations give related ASTs (in the empty context), whence we call the parametric AST \emph{well-formed}:
\begin{minted}{coq}
Definition Expr := ∀ var, @expr var.
Definition Wf (e : Expr) := ∀ var1 var2, related [] (e var1) (e var2)
\end{minted}
\label{sec:PHOAS:Wf-def}

We could then prove a modified form of our soundness theorem:
\begin{minted}{coq}
Theorem check_is_even_expr_sound (e : Expr) (H : Wf e)
: check_is_even_expr (e bool) = true → is_even (denote (e nat)).
\end{minted}

To complete the picture, we would need a tactic \mintinline{coq}{Reify} which took in a term of type \mintinline{coq}{nat} and gave back a term of type \mintinline{coq}{forall var, @expr var}, plus a tactic \mintinline{coq}{prove_wf} which solved a goal of the form \mintinline{coq}{Wf e} by repeated application of constructors.
Given these, we could solve an evenness goal by writing%
\footnote{%
  Note that for the \mintinline{coq}{refine} to be fast, we must issue something like \mintinline{coq}{Strategy -10 [denote]} to tell Coq to unfold \mintinline{coq}{denote} before \mintinline{coq}{Let_In}.
  Alternatively, we may issue something like \mintinline{coq}{Strategy 10 [Let_In]} to tell Coq to unfold \mintinline{coq}{Let_In} only after unfolding any constant with no \mintinline{coq}{Strategy} declaration.
  This invocation may look familiar to those readers who read the footnotes in \fullnameref{sec:fiat-crypto-codegen-numbers}, as in fact this is the issue at the root cause of the exponential performance blowup which resulted in numbers like ``over 4\,000 millennia'' in an earlier version of Fiat Cryptography.
}
\begin{minted}{coq}
match goal with
| [ |- is_even ?v ]
  => let e := Reify v in
     refine (check_is_even_expr_sound e _ _);
     [ prove_wf | vm_compute; reflexivity ]
end.
\end{minted}
%\todo{Should we mention that for the \mintinline{coq}{refine} to be fast, we need a \mintinline{coq}{Strategy} command to tell Coq to unfold \mintinline{coq}{denote} before \mintinline{coq}{Let_In}?}

\subsubsection{Multiple Types} \label{sec:multiple-types-ASTs}
One important point, not yet mentioned, is that sometimes we want our reflective language to handle multiple types of terms.
For example, we might want to enrich our language of expressions with lists.
Since expressions like ``take the successor of this list'' don't make sense, the natural choice is to index the inductive over codes for types.

We might write:
\begin{minted}{coq}
Inductive type := Nat | List (_ : type).
Inductive expr {var : type → Type} : type → Type :=
| NatO : expr Nat
| NatS : expr Nat → expr Nat
| NatMul : expr Nat → expr Nat → expr Nat
| Var {t} : var t → expr t
| LetIn {t1 t2} : expr t1 → (var t1 → expr t2) → expr t2
| Nil {t} : expr (List t)
| Cons {t} : expr t → expr (List t) → expr (List t)
| Length {t} : expr (List t) → expr Nat.
\end{minted}
We would then have to adjust the definitions of the other functions accordingly.
The type signatures of the might functions become

\begin{minted}{coq}
Fixpoint denote_type (t : type) : Type
  := match t with
     | Nat => nat
     | List t => list (denote_type t)
     end.

Fixpoint even_data_of_type (t : type) : Type
  := match t with
     | Nat => bool (* is the nat even or not? *)
     | List t => list (even_data_of_type t)
     end.

Fixpoint denote {t} (e : @expr denote_type t) : denote_type t.

Fixpoint check_is_even_expr {t} (e : @expr even_data_of_type t)
  : even_data_of_type t.

Inductive related {var1 var2 : type → Type}
  : list { t : type & var1 t * var2 t}
    → ∀ {t}, @expr var1 t → @expr var2 t → Prop.

Definition Expr (t : type) := ∀ var, @expr var t.

Definition Wf {t} (e : Expr t)
  := ∀ var1 var2, related [] (e var1) (e var2).
\end{minted}

See \textcite{PhoasICFP08} for a fuller treatment.

\subsubsection{de Bruijn Indices} \label{sec:binders:de-bruijn}
The idea behind \emph{de Bruijn indices} is that variables are encoded by numbers which count up starting from the nearest enclosing binder.
We might write
\begin{minted}{coq}
Inductive expr :=
| NatO : expr
| NatS : expr → expr
| NatMul : expr → expr → expr
| Var : nat → expr
| LetIn : expr → expr → expr.

Fixpoint denote (default : nat) (Γ : list nat) (t : @expr nat) : nat
  := match t with
     | NatO => O
     | NatS x => S (denote default Γ x)
     | NatMul x y => denote default Γ x * denote default Γ y
     | Var idx => nth_default default Γ idx
     | LetIn v f => dlet x := denote default Γ v in
                    denote default (x :: Γ) f
     end.
\end{minted}
If we wanted a more efficient representation, we could choose better data-structures for the context $\Gamma$ and variable indices than linked lists and unary-encoded natural numbers.
One particularly convenient choice, in Coq, would be using the efficient \mintinline{coq}{PositiveMap.t} data-structure which encodes a finite map of binary-encoded \mintinline{coq}{positive}s to any type.

One unfortunate result is that the natural denotation function is no longer total.
Here we have chosen to give a denotation function which returns a default element when a variable reference is too large, but we could instead choose to return an \mintinline{coq}{option nat}.
In general, however, returning an optional result significantly complicates the denotation function when binders are involved, because the types \mintinline{coq}{A → option B} and \mintinline{coq}{option (A → B)} are not isomorphic.
On the other hand, requiring a default denotation prevents syntax trees from being able to represent possibly empty types.
\minortodoask{Is there a good reference for these sorts of issues?  Are they well-known?  Well-studied?}

This causes further problems when dealing with an AST type which can represent terms of multiple types.
In that case, we might annotate each variable node with a type code, mandate decidable equality of type codes, and then during denotation, we'd check the type of the variable node with the type of the corresponding variable in the context.

\subsubsection{Nested Abstract Syntax} \label{sec:binders:nested-abstract-syntax}
If we want a variant of de Bruijn indices which guarantees well-typed syntax trees, we can use nested abstract syntax~\cite{Nested2012Hirschowitz,deBruijn1999Bird}.
On mono-typed ASTs, this looks like encoding the size of the context in the type of the expressions.
For example, we could use \mintinline{coq}{option} types~\cite{Nested2012Hirschowitz}:
\begin{minted}{coq}
Notation "^ V" := (option V).
Inductive expr : Type → Type :=
| NatO {V} : expr V
| NatS {V} : expr V → expr V
| NatMul {V} : expr V → expr V → expr V
| Var {V} : V → expr V
| LetIn {V} : expr V → expr (^V) → expr V.
\end{minted}

This may seem a bit strange to those accustomed to encodings of terms in proof assistants, but it generalizes to a quite familiar intrinsic encoding of dependent type theory using types, contexts, and terms~\cite{Strongly2012Benton}.
Namely, when the expressions are multi-typed, we end up with something like
\begin{minted}{coq}
Inductive context :=
| emp : context
| push : type → context → context.

Inductive var : context → type → Type :=
| Var0 {t Γ} : var (push t Γ) t
| VarS {t t' Γ} : var Γ t → var (push t' Γ) t.

Inductive expr : context → type → Type :=
| NatO {Γ} : expr Γ Nat
| NatS {Γ} : expr Γ Nat → expr Γ Nat
| NatMul {Γ} : expr Γ Nat → expr Γ Nat → expr Γ Nat
| Var {t Γ} : var Γ t → expr Γ t
| LetIn {Γ t1 t2} : expr Γ t1 → expr (push t1 Γ) t2 → expr Γ t2.
\end{minted}

Note that this generalizes nicely to codes for dependent types if the proof assistant supports induction-induction.

Although this representation enjoys both decidable equality of binders (like de Bruijn indices), as well as being well-typed-by-construction (like PHOAS), it's unfortunately unfit for coding algorithms that need to scale without massive assistance from the proof assistant.
In particular, the naïve encoding of this inductive datatype incurs a quadratic overhead in representing terms involving binders, because each node stores the entire context.
It is possible in theory to avoid this blowup by dropping the indices of the inductive type from the runtime representation~\cite{Inductive2003Brady}.
One way to simulate this in Coq would be to put \mintinline{coq}{context} in \mintinline{coq}{Prop} and then extract the code to OCaml, which erases the \mintinline{coq}{Prop}s.
Alternatively, if Coq is extended with support for dropping irrelevant subterms~\cite{sprop} from the term representation, then this speedup could be accomplished even inside Coq.

\subsubsection{Nominal} \label{sec:binders:nominal}
Nominal representations~\cite{Nominal2003Pitts} use names rather than indices for binders.
These representations have the benefit of being more human-readable, but require reasoning about freshness of names and capture-avoiding substitution.
Additionally, if the representation of names is not sufficiently compact, the overhead of storing names at every binder node can become significant.

\subsubsection{Locally Nameless} \label{sec:binders:locally-nameless}
We mention the locally nameless representation~\cite{Locally2012Chargueraud,locally2007Leroy} because it is the term representation used by Coq itself.
This representation uses de Bruijn indices for closed terms, and names for variables which are not bound in the current term.

Much like nominal representations, locally nameless representations also incur the overhead of generating and storing names.
Naïve algorithms for generating fresh names, such as the algorithm used in Coq, can easily incur overhead that's linear in the size of the context.
Generating $n$ fresh names then incurs $\mathcal \Theta(n^2)$ overhead.
\minortodo{explain what evar substitutions are somewhere?  reference it here?}
Additionally, using a locally nameless representation requires that evar substitutions be named.
\minortodo{elaborate more on the performance bottlenecks of named evar substitutions}
See also \autoref{sec:setoid-rewrite-bottlenecks}.

\subsection{Performance of Proving Reflective Well-Formedness of PHOAS} \label{sec:wf:perf}

We saw in \autoref{sec:binders:PHOAS} that in order to prove the soundness theorem, we needed a way to relate two PHOASTs (parametric higher-order abstract syntax trees), which generalized to a notion of well-formedness for the \mintinline{coq}{Expr} type.

Unfortunately, the proof that two \mintinline{coq}{expr}s are \mintinline{coq}{related} is quadratic in the size of the expression, for much the same reason that proving conjunctions in \autoref{sec:quadratic-conj-certificate} resulted in a proof term which was quadratic in the number of conjuncts.
We present two ways to encode linearly-sized proofs of well-formedness in PHOAS.

\subsubsection{Iterating Reflection} \label{sec:wf:perf:reflective}

The first method of encoding linearly-sized proofs of \mintinline{coq}{related} is itself a good study in how using proof by reflection can compress proof terms.
Rather than constructing the inductive \mintinline{coq}{related} proof, we can instead write a fixed point:
\begin{minted}{coq}
Fixpoint is_related {var1 var2 : Type} (Γ : list (var1 * var2))
    (e1 : @expr var1) (e2 : @expr var2) : Prop :=
  match e1, e2 with
  | NatO, NatO => True
  | NatS e1, NatS e2 => is_related Γ e1 e2
  | NatMul x1 y1, NatMul x2 y2
    => is_related Γ x1 x2 /\ is_related Γ y1 y2
  | Var v1, Var v2 => List.In (v1, v2) Γ
  | LetIn e1 f1, LetIn e2 f2
    => is_related Γ e1 e2
       /\ ∀ v1 v2, is_related ((v1, v2) :: Γ) (f1 v1) (f2 v2)
  | _, _ => False
  end.
\end{minted}
This unfortunately isn't quite linear in the size of the syntax tree, though it is significantly smaller.
One way to achieve even more compact proof terms is to pick a more optimized representation for list membership and to convert the proposition to be an eliminator.%
\footnote{%
  The size of the proof term will still have an extra logarithmic factor in the size of the syntax tree due to representing variable indices in binary.
  Moreover, the size of the proof term will sill be quadratic due to the fact that functions store the type of their binders.
  However, this representation allows proof terms that are significantly faster to construct in Coq's proof engine for reasons that are not entirely clear to us.
}
This consists of replacing $A \wedge B$ with $\forall P, A \to B \to P$, and similar.
\begin{minted}{coq}
Fixpoint is_related_elim {var1 var2 : Type} (Γ : list (var1 * var2))
   (e1 : @expr var1) (e2 : @expr var2) : Prop :=
  match e1, e2 with
  | NatO, NatO => True
  | NatS e1, NatS e2 => is_related_elim Γ e1 e2
  | NatMul x1 y1, NatMul x2 y2 => forall P : Prop,
      (is_related_elim Γ x1 x2 → is_related_elim Γ y1 y2 → P) → P
  | Var v1, Var v2 => forall (P : Prop),
      (forall n, List.nth_error Γ (N.to_nat n) = Some (v1, v2) → P) → P
  | LetIn e1 f1, LetIn e2 f2 => forall P : Prop,
      (is_related_elim Γ e1 e2
       → (forall v1 v2, is_related_elim ((v1, v2) :: Γ) (f1 v1) (f2 v2))
       → P)
      → P
  | _, _ => False
  end.
\end{minted}
We can now prove that \mintinline{coq}{is_related_elim Γ e1 e2 → is_related Γ e1 e2}.

Note that making use of the fixpoint is significantly more inconvenient than making use of the inductive; the proof of \mintinline{coq}{check_is_even_expr_sound}, for example, proceeds most naturally by induction on the relatedness hypothesis.
We could instead induct on one of the ASTs and destruct the other one, but this becomes quite hairy when the ASTs are indexed over their types.

\minortodo{Time permitting, benchmark wf proof methods and insert plots}

\subsubsection{Via de Bruijn} \label{sec:wf:perf:de-bruijn}

An alternative, ultimately superior, method of constructing compact proofs of relatedness involves a translation to a de Bruijn representation.
We can define a boolean predicate on de Bruijn syntax representing well-formedness.
\begin{minted}{coq}
Fixpoint is_closed_under (max_idx : nat) (e : expr) : bool :=
  match expr with
  | NatO => true
  | NatS e => is_closed_under max_idx e
  | NatMul x y
     => is_closed_under max_idx x && is_closed_under max_idx y
  | Var n => n <? max_idx
  | LetIn v f
     => is_closed_under max_idx v && is_closed_under (S max_idx) f
  end.
Definition is_closed := is_closed_under 0.
\end{minted}
Note that this check generalizes quite nicely to expressions indexed over their types---so long as type codes have decidable equality---where we can pass around a list (or more efficient map structure) of types for each variable, and just check that the types are equal.

Now we can prove that whenever a de Bruijn \mintinline{coq}{expr} is closed, any two PHOAS \mintinline{coq}{expr}s created from that AST will be related in the empty context.
Therefore, if the PHOAS \mintinline{coq}{expr} we start off with is the result of converting some de Bruijn \mintinline{coq}{expr} to PHOAS, we can easily prove that it's well-formed simply by running \mintinline{coq}{vm_compute} on the \mintinline{coq}{is_closed} procedure.
How might we get such a de Bruijn \mintinline{coq}{expr}?
The easiest way is to write a converter from PHOAS to de Bruijn.

Hence we can prove the theorem \texttt{∀ e, is\_closed (PHOAS\_to\_deBruijn e) = true ∧ e = deBruijn\_to\_PHOAS (PHOAS\_to\_deBruijn e) → Wf e}.
The hypothesis of this theorem is quite easy to check; we simply run \mintinline{coq}{vm_compute} and then instantiate it with the proof term \mintinline{coq}{conj (eq_refl true) (eq_refl e)}, which is linear in the size of \mintinline{coq}{e}.

\section{Reification}\label{sec:reif-survey}\label{sec:reif-intro}

\todo{check spacing on this figure once the introduction of this chapter is figured out}

\begin{wrapfigure}[12]{r}{\widthof{\texttt{~~~~~~~~~~~~~constr:(@NatMul v X Y)}}}
\begin{minted}{coq}
Ltac f v x := (* reify var term *)
  lazymatch x with
  | O => constr:(@NatO v)
  | S ?x => let X := f v x in
            constr:(@NatS v X)
  | ?x*?y => let X := f v x in
             let Y := f v y in
             constr:(@NatMul v X Y)
  end.
\end{minted}
%\vspace{-20pt}
\caption{Reification Without Binders in~\Ltac}\label{fig:ltac-reify-nobinders}
\end{wrapfigure}

The one part of proof by reflection that we've neglected up to this point is reification.
There are many ways of performing reification; in \autoref{ch:reification-by-parametricity}, we discuss 19 different ways of implementing reification, using 6 different metaprogramming facilities in the Coq ecosystem: \Ltac, \LtacTwo, \MtacTwo~\cite{lessadhoc,Mtac2}, type classes~\cite{sozeau2008first}, canonical structures~\cite{gonthier2016small}, and reification-specific OCaml plugins (quote~\cite{quote-plugin}\footnote{Note that this plugin was removed in Coq 8.10~\cite{coq-pr-remove-quote-plugin}, and so our plots no longer include this plugin.}, template-coq~\cite{TemplateCoq}, ours).
\autoref{fig:ltac-reify-nobinders} displays the simplest case: an Ltac script to reify a tree of function applications and constants.
Unfortunately, all methods we surveyed become drastically more complicated or slower (and usually both) when adapted to reify terms with variable bindings such as \texttt{let}-\texttt{in} or \texttt{$\lambda$} nodes.

We have made detailed walkthroughs and source code of these implementations available\footnote{\url{https://github.com/mit-plv/reification-by-parametricity}} in hope that they will be useful for others considering implementing reification using one of these metaprogramming mechanisms, instructive as nontrivial examples of multiple metaprogramming facilities, or helpful as a case study in Coq performance engineering.
\minortodo{Maybe include detailed walkthroughs in the appendix?}
However, we do \emph{not} recommend reading these out of general interest:
most of the complexity in the described implementations strikes us as needless,
with significant aspects of the design being driven by surprising behaviors, misfeatures, bugs, and performance bottlenecks of the underlying machinery as opposed to the task of reification.

\minortodo{should this paragraph be here, or above the last one?}
There are a couple of complications that arise when reifying binders, which broadly fall into two categories.
One category is the metaprogramming language's treatment of binders.
In \Ltac, for example, the body of a function is not a well-typed term, because the variable binder refers to a non-existent name; getting the name to actually refer to something, so that we can inspect the term, is responsible for a great deal of the complexity in reification code in \Ltac.
The other category is any mismatch between the representation of binders in the metaprogramming language, and the representation of binders in the reified syntax.
If the metaprogramming language represents variables as de Bruijn indices, and we are reifying to a de Bruijn representation, then we can reuse the indices.
If the metaprogramming language represents variables as names, and we are reifying to a named representation, then we can reuse the names.
If the representations mismatch, then we need to do extra work to align the representations, such as keeping some sort of finite map structure from binders in the metalanguage to binders in the AST.

\section{What's Next?}

Having introduced and explained proof by reflection and reflective automation, we can now introduce the main contribution of this thesis.
In the next chapter we'll present the reflective framework we developed for achieving adequate performance in the Fiat Cryptography project.


%\section{Related Work}
%\todo{this section}
%\todo{mention RTac, etc}

%\section{Reflective Syntax Tranformation}
%\todo{prep the reader for the upcoming chapter on the rewriter}
%\todo{Maybe call this Reflective Syntax Transformation}
%\todo{should the content on slowness in non-reflective rewriting go here?}

%\section{related work (incl. RTac)}
%\todo{talk about related work}
%\todo{figure out where this section belongs}

\begin{comment}
\todo{list:}
\begin{itemize}
\item Maybe expand on the trust story of reflective programming at the beginning
\item Expand section on PHOAS, treat HOAS, de Bruijn, named, etc
\item Talk about well-formedness, reflective well-formedness
\item Explain various ways of doing reification, explain where the trust comes from, what's proven and what's not
\item Performance measurements of the various ways of doing reification, forward reference reification by parametricity chapter
\item Related work section on reflective syntax transformation / uses of proof by reflection in general, brief intro to rewriting chapter
\end{itemize}
\end{comment}

\begin{subappendices}
\begin{minorcomment}
  \section{Reflective Evenness Checking in Coq} \label{sec:evenness-in-coq}
\end{minorcomment}
\minortodo{put reflective evenness checking in Coq somewhere, fix input of file}
%\input{coq-fragments/evenness.raw.tex}

\end{subappendices}
