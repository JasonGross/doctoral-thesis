\chapter{Concluding Remarks}\label{ch:conclusion}
%We come, at last, to the closing remarks of this dissertation.
%\todoac{This sentence seems hokey and at risk of conveying too little info, given the chapter title.}

We spent \autoref{part:introduction} mapping out the landscape of the problems of performance we encountered in dependently typed proof assistants.
In \autoref{part:rewriting} and \autoref{part:design}, we laid out more-or-less systematic principles and tools for avoiding these performance bottlenecks.
In the last chapter, \autoref{ch:retrospective}, we looked back on the concrete performance improvements in Coq over time.

We look now to the future.

The clever reader might have noticed something that we swept under the rug in \Autoref{part:rewriting,part:design}.
In \autoref{sec:intro:proof-assistant-design-choices} we laid out two basic design choices---dependent types and the de Bruijn criterion---which are responsible for much of the power and much of the trust we can have in a proof assistant like Coq.
We then spent the next chapters of this dissertation investigating the performance bottlenecks that can perhaps be said to result from these choices and how to ameliorate these performance issues.

If the strategies we laid out in \Autoref{part:rewriting,part:design} for how to use dependent types and untrusted tactics in a performant way are to be summed up in one word, that word is: ``don't!''
To avoid the performance issues resulting from tactics being untrusted, the source of much of the trust in proof assistants like Coq, we suggest in \autoref{part:rewriting} that users effectively \emph{throw away the entire tactic engine} and instead code tactics reflectively.
To avoid the performance issues incurred by unpredictable computation at the type level, the source of much of the power of dependent type theory, we broadly suggest in \autoref{part:design} to \emph{avoid using the computation at all} (except in the rare cases where the entire proof can be moved into computation at the type level, such as proof by duality (\autoref{sec:duality-conversion}) and proof by reflection (\autoref{ch:reflection})).

This is a sorry state of affairs:
we are effectively advising users to basically avoid using most of the power and infrastructure of the proof assistant.

We admit that we are not sure what an effective resolution to the performance issue of computation at the type level would look like.
While \autoref{ch:design} lays out in \fullnameref{sec:when-how-dependent-types} principles for how and when to use dependent types that allow us to recover much of the power of dependent types without running into issues of slow conversion, even at scale, this is nowhere near a complete roadmap for actually using partial computation at the type level.

On the question of using tactics, however, we do know what a resolution would look like, and hence we conclude this dissertation with such a call for future research.

As far as we can tell, no one has yet laid out a theory of what are the necessary basic building blocks of a usable tactic engine for proofs.
Such a theory should include:
\begin{itemize}
\item
  a list of basic operations
\item
  with necessary asymptotic performance,
\item
  justification that these building blocks are sufficient for constructing all the proof automation users might want to construct, and
\item
  justification that the asymptotic performance does not incur needless overhead above and beyond the underlying algorithm of proof construction.
\end{itemize}

What is \emph{needless} overhead, though?
How can we say what the performance of the ``underlying algorithm'' is?

A first stab might be thus: we want a proof engine which, for any heuristic algorithm $A$ that can sometimes determine the truth of a theorem statement (and will otherwise answer ``I don't know'') in time $\mathcal O(f(n))$, where $n$ is some parameter controlling the size of the problem, we can construct a proof script which generates proofs of these theorem statements in time not worse than $\mathcal O(f(n))$, or perhaps in time that is not much worse than $\mathcal O(f(n))$.

This criterion, however, is both useless and impossible to meet.

\minortodoaskreaders{Adam found this following paragraph hard to follow; what do other readers think?}
Useless:
In a dependently typed proof assistant, if we can prove that $A$ is sound, i.e., that when it says ``yes'' the theorem is in fact true, then we can simply use reflection to create a proof by appeal to computation.
This is not useful when what we are trying to do is describe how to identify a proof engine which gives adequate building blocks \emph{aside} from appeal to computation.

Impossible to meet:
Moreover, even if we could modify this criterion into a useful one, perhaps by requiring that it be possible to construct such a proof script without any appeal to computation, meeting the criterion would still be impossible.
Taking inspiration from \textcite[pp.~24--25]{Logical2016Garrabrant}, we ask the reader to consider a program $\texttt{prg}(x)$ which searches for proofs of absurdity (i.e., \mintinline{coq}{False}) in Coq which have length less than $2^x$ characters and which can be checked by Coq's kernel in less than $2^x$ CPU cycles.
If such a proof of absurdity is found, the program outputs \texttt{true}.
If no such proof is found under the given computational limits, the program outputs \texttt{false}.
Assuming that Coq is, in fact, consistent, then we can recognize true theorems of the form $\texttt{prg}(x) = \texttt{false}$ for all $x$ in time $\mathcal O(\log x)$.
(The running time is logarithmic, rather than linear or constant, because representing the number $x$ in any place-value system, such as decimal or binary, requires $\log n$ space.)
At the same time, by Gödel's incompleteness theorem, there is no hope of proving $\forall x, \texttt{prg}(x) = \texttt{false}$, and hence we cannot prove this simple $\mathcal O(\log x)$-time theorem recognizer correct.
We almost certainly will be stuck running the program, which will take time $\Omega(2^x)$, which is certainly not an acceptable overhead over $\mathcal O(\log x)$.

\minortodo{should I be using ``we'', still, or should I switch to ``I''?}
We do not believe that all hope is lost, though!
Gödelian incompleteness did not prove to be a fatal obstacle to verification and automation of proofs, as we saw in \autoref{sec:intro:intro}, and we hope that it proves to be surmountable here as well.

We can take a second stab at specifying what it might mean to avoid needless overhead:
Suppose we are given some algorithm $A$ which can sometimes determine the truth of a theorem statement (and will otherwise answer ``I don't know'') in time $\mathcal O(f(n))$, and suppose we are given a proof that $A$ is sound, i.e., a proof that whenever $A$ claims a theorem statement is true, that statement is in fact true.
Then we would like a proof engine which permits the construction of proofs, without any appeal to computation, of theorems that $A$ claims are true in time $\mathcal O(f(n))$, or perhaps time that is not much worse than $\mathcal O(f(n))$.
Said another way, we want a proof engine for which reflective proof scripts can be turned into nonreflective proof scripts without incurring overhead, or at least without incurring too much overhead.

Is such a proof engine possible?
Is such a proof engine sufficient?
Is this criterion necessary?
Or is there perhaps a better criterion?
We leave all of these questions for future work in this field, noting that there may be some inspiration to be drawn from the extant research on the overhead of using a functional language over an imperative one~\cite{Efficiency2010Campbell,Ben-AmramG92,Ben-amram96noteson,More1997Bird,okasaki1996purely,okasaki1998purely,Pure1997Pippenger}.
This body of work shows that we can always turn an imperative program into a strict functional program with at most $\mathcal O(\log n)$ overhead, and often we get no overhead at all.\footnote{%
  Note that if we are targeting a lazy functional language rather than a strict one, it may in fact always be possible to achieve a transformation without any overhead~\cite{Efficiency2010Campbell}.%
}

\minortodo{is there a better concluding sentence?}
We hope the reader leaves this dissertation with an improved understanding of the performance landscape of engineering of proof-based software systems and perhaps goes on to contribute new insight to this nascent field themselves.
