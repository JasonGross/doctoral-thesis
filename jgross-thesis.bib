% Encoding: UTF-8

@InProceedings{ReflectionTACS97,
  author    = {Boutin, Samuel},
  booktitle = {Theoretical Aspects of Computer Software},
  date      = {1997},
  title     = {Using reflection to build efficient and certified decision procedures},
  doi       = {10.1007/bfb0014565},
  editor    = {Abadi, Mart{\'i}n and Ito, Takayasu},
  isbn      = {978-3-540-69530-1},
  location  = {Berlin, Heidelberg},
  pages     = {515--529},
  publisher = {Springer Berlin Heidelberg},
}

@InProceedings{reification-by-parametricity,
  author          = {Jason Gross and Andres Erbsen and Adam Chlipala},
  booktitle       = {Proceedings of the \href{https://itp2018.inria.fr/}{9th International Conference on Interactive Theorem Proving (ITP'18)}},
  date            = {2018-07},
  title           = {Reification by Parametricity: Fast Setup for Proof by Reflection, in Two Lines of {L}tac},
  doi             = {10.1007/978-3-319-94821-8_17},
  url             = {https://people.csail.mit.edu/jgross/personal-website/papers/2018-reification-by-parametricity-itp-camera-ready.pdf},
  abstract        = {We present a new strategy for performing reification in Coq.
That is, we show how to generate first-class abstract syntax trees from ``native'' terms of Coq's logic, suitable as inputs to verified compilers or procedures in the \emph{proof-by-reflection} style.
Our new strategy, based on simple generalization of subterms as variables, is straightforward, short, and fast.
In its pure form, it is only complete for constants and function applications, but ``let'' binders, eliminators, lambdas, and quantifiers can be accommodated through lightweight coding conventions or preprocessing.

We survey the existing methods of reification across multiple Coq metaprogramming facilities, describing various design choices and tricks that can be used to speed them up, as well as various limitations.
We report benchmarking results for 18 variants, in addition to our own, finding that our own reification outperforms 16 of these methods in all cases, and one additional method in some cases; writing an OCaml plugin is the only method tested to be faster.
Our method is the most concise of the strategies we considered, reifying terms using only two to four lines of \texttt{Ltac}---beyond lists of the identifiers to reify and their reified variants.
Additionally, our strategy automatically provides error messages that are no less helpful than Coq's own error messages.},
  artifact-github = {https://github.com/mit-plv/reification-by-parametricity},
  artifact-tar-gz = {https://people.csail.mit.edu/jgross/personal-website/papers/2018-reification-by-parametricity-itp-camera-ready-supplementary.tar.gz},
  original-url    = {https://people.csail.mit.edu/jgross/personal-website/papers/2018-reification-by-parametricity-itp-draft.pdf},
  owner           = {Jason},
}

@Online{coq-pr-fast-rel-lookup,
  author = {Pierre-Marie Pédrot},
  date   = {2017-12},
  title  = {Fast rel lookup by ppedrot · Pull Request \#6506 · coq/coq},
  url    = {https://github.com/coq/coq/pull/6506},
}

@Book{cpdt,
  author    = {Adam Chlipala},
  date      = {2013-12},
  title     = {Certified Programming with Dependent Types: A Pragmatic Introduction to the {C}oq Proof Assistant},
  doi       = {10.7551/mitpress/9153.001.0001},
  isbn      = {9780262026659},
  publisher = {MIT Press},
  url       = {http://adam.chlipala.net/cpdt/},
}

@TechReport{gonthier2016small,
  author      = {Gonthier, Georges and Mahboubi, Assia and Tassi, Enrico},
  date        = {2016-11},
  institution = {Inria Saclay Ile de France},
  title       = {A Small Scale Reflection Extension for the {C}oq system},
  url         = {https://hal.inria.fr/inria-00258384/},
  school      = {Inria Saclay Ile de France},
}

@InProceedings{HOAS,
  author    = {Frank Pfenning and Conal Elliot},
  booktitle = {Proc. PLDI},
  date      = {1988},
  title     = {Higher-order abstract syntax},
  doi       = {10.1145/53990.54010},
  location  = {Atlanta, Georgia, United States},
  pages     = {199--208},
  url       = {https://www.cs.cmu.edu/~fp/papers/pldi88.pdf},
}

@Article{lessadhoc,
  author       = {Gonthier, Georges and Ziliani, Beta and Nanevski, Aleksandar and Dreyer, Derek},
  date         = {2013},
  journaltitle = {Journal of Functional Programming},
  title        = {How to Make Ad Hoc Proof Automation Less Ad Hoc},
  doi          = {10.1017/S0956796813000051},
  number       = {4},
  pages        = {357--401},
  url          = {https://people.mpi-sws.org/~beta/lessadhoc/lessadhoc-extended.pdf},
  volume       = {23},
  publisher    = {Cambridge University Press},
}

@InProceedings{MirrorShardITP14,
  author    = {Gregory Malecha and Adam Chlipala and Thomas Braibant},
  booktitle = {ITP'14: Proceedings of the 5th International Conference on Interactive Theorem Proving},
  date      = {2014},
  title     = {Compositional Computational Reflection},
  doi       = {10.1007/978-3-319-08970-6_24},
  url       = {http://adam.chlipala.net/papers/MirrorShardITP14/},
}

@InProceedings{PhoasICFP08,
  author    = {Adam Chlipala},
  booktitle = {ICFP'08: Proceedings of the 13th ACM SIGPLAN International Conference on Functional Programming},
  date      = {2008-09},
  title     = {Parametric Higher-Order Abstract Syntax for Mechanized Semantics},
  doi       = {10.1145/1411204.1411226},
  location  = {Victoria, British Columbia, Canada},
  url       = {http://adam.chlipala.net/papers/PhoasICFP08/},
}

@InBook{primitive-projections,
  author    = {{Coq Development Team}},
  date      = {2017},
  title     = {The {C}oq Proof Assistant Reference Manual},
  chapter   = {2.1.1 Extensions of \texorpdfstring{\textsc{Gallina}}{Gallina}, Record Types (Primitive Projections)},
  edition   = {{8.7.1}},
  publisher = {INRIA},
  url       = {https://coq.inria.fr/distrib/V8.7.1/refman/gallina-ext.html#sec65},
}

@InBook{quote-plugin,
  author    = {{Coq Development Team}},
  date      = {2017},
  title     = {The {C}oq Proof Assistant Reference Manual},
  chapter   = {10.3 Detailed examples of tactics (quote)},
  edition   = {{8.7.1}},
  publisher = {INRIA},
  url       = {https://coq.inria.fr/distrib/V8.7.1/refman/tactic-examples.html#quote-examples},
}

@Article{sozeau2008first,
  author       = {Sozeau, Matthieu and Oury, Nicolas},
  date         = {2008},
  journaltitle = {Lecture Notes in Computer Science},
  title        = {First-class type classes},
  doi          = {10.1007/978-3-540-71067-7_23},
  pages        = {278--293},
  url          = {https://www.irif.fr/~sozeau/research/publications/First-Class_Type_Classes.pdf},
  volume       = {5170},
  publisher    = {Springer},
}

@Article{ziliani2015mtac,
  author       = {Beta Ziliani and Derek Dreyer and Neelakantan R. Krishnaswami and Aleksandar Nanevski and Viktor Vafeiadis},
  date         = {2015},
  journaltitle = {Journal of Functional Programming},
  title        = {Mtac: A Monad for Typed Tactic Programming in {C}oq},
  url          = {http://plv.mpi-sws.org/mtac/journal-draft.pdf},
  volume       = {25},
  publisher    = {Cambridge University Press},
}

@Article{ziliani2017comprehensible,
  author       = {Ziliani, Beta and Sozeau, Matthieu},
  date         = {2017},
  journaltitle = {Journal of Functional Programming},
  title        = {A Comprehensible Guide to a New Unifier for {CIC} Including Universe Polymorphism and Overloading},
  url          = {https://people.mpi-sws.org/~beta/papers/unicoq-journal.pdf},
  volume       = {27},
  publisher    = {Cambridge University Press},
}

@InProceedings{maranget2008compiling,
  author       = {Maranget, Luc},
  booktitle    = {Proceedings of the 2008 ACM SIGPLAN workshop on ML},
  date         = {2008},
  title        = {Compiling Pattern Matching to Good Decision Trees},
  doi          = {10.1145/1411304.1411311},
  organization = {ACM},
  pages        = {35--46},
  url          = {http://moscova.inria.fr/~maranget/papers/ml05e-maranget.pdf},
  owner        = {jgross},
  timestamp    = {2019.04.15},
}

@Online{coq-issue-floats,
  author    = {Erik Martin-Dorel},
  date      = {2018-08},
  title     = {Implementing primitive floats (binary64 floating-point numbers) - Issue \#8276 - coq/coq},
  url       = {https://github.com/coq/coq/issues/8276},
  owner     = {jgross},
  timestamp = {2019.04.22},
}

@Article{Compcert,
  author       = {Leroy, Xavier},
  date         = {2009-12},
  journaltitle = {Journal of Automated Reasoning},
  title        = {A Formally Verified Compiler Back-end},
  doi          = {10.1007/s10817-009-9155-4},
  issn         = {0168-7433},
  number       = {4},
  pages        = {363--446},
  url          = {http://gallium.inria.fr/~xleroy/publi/compcert-backend.pdf},
  volume       = {43},
  acmid        = {1666216},
  issue_date   = {December 2009},
  keywords     = {Compiler transformations and optimizations, Compiler verification, Formal methods, Program proof, Semantic preservation, The Coq theorem prover},
  location     = {Secaucus, NJ, USA},
  numpages     = {84},
  publisher    = {Springer-Verlag New York, Inc.},
}

@InProceedings{seL4SOSP09,
  author    = {Gerwin Klein and Kevin Elphinstone and Gernot Heiser and June Andronick and David Cock and Philip Derrin and Dhammika Elkaduwe and Kai Engelhardt and Rafal Kolanski and Michael Norrish and Thomas Sewell and Harvey Tuch and Simon Winwood},
  booktitle = {Proc. SOSP},
  date      = {2009},
  title     = {{seL4}: Formal Verification of an {OS} Kernel},
  doi       = {10.1145/1629575.1629596},
  isbn      = {9781605587523},
  location  = {Big Sky, Montana, USA},
  pages     = {207--220},
  publisher = {ACM},
  series    = {SOSP ’09},
  address   = {New York, NY, USA},
  keywords  = {microkernel, l4, sel4, isabelle/hol},
  numpages  = {14},
}

@Book{PartialEvaluation,
  author    = {N. D. Jones and C. K. Gomard and P. Sestoft},
  date      = {1993-06},
  title     = {Partial Evaluation and Automatic Program Generation},
  isbn      = {0-13-020249-5},
  publisher = {Prentice Hall International},
}

@Article{LMS,
  author       = {Tiark Rompf and Martin Odersky},
  date         = {2010},
  journaltitle = {Proceedings of the Ninth International Conference on Generative Programming and Component Engineering, GPCE 2010},
  title        = {Lightweight modular staging: {A} pragmatic approach to runtime code generation and compiled {DSL}s},
  doi          = {10.1145/2184319.2184345},
  url          = {https://infoscience.epfl.ch/record/150347/files/gpce63-rompf.pdf},
}

@InProceedings{NbE,
  author    = {U. Berger and H. Schwichtenberg},
  booktitle = {[1991] Proceedings Sixth Annual IEEE Symposium on Logic in Computer Science},
  date      = {1991-07},
  title     = {An inverse of the evaluation functional for typed $\lambda$--calculus},
  doi       = {10.1109/LICS.1991.151645},
  pages     = {203--211},
  url       = {http://www.mathematik.uni-muenchen.de/~schwicht/papers/lics91/paper.pdf},
  keywords  = {formal logic;inverse;evaluation functional;typed lambda -calculus;typed lambda -terms;normalization algorithm;lambda -calculi;constants;natural deduction proofs;completeness theorem;recursive functions;Calculus;Arithmetic;Computer languages},
}

@InProceedings{Aehlig,
  author    = {Klaus Aehlig and Florian Haftmann and Tobias Nipkow},
  booktitle = {Proc. TPHOLs},
  date      = {2008},
  title     = {A Compiled Implementation of Normalization by Evaluation},
  doi       = {10.1007/978-3-540-71067-7_8},
}

@InProceedings{CodeGen,
  author    = {Florian Haftmann and Tobias Nipkow},
  booktitle = {Proc. TPHOLs},
  date      = {2007},
  title     = {A Code Generator Framework for {I}sabelle/{HOL}},
}

@InProceedings{vale,
  author    = {Barry Bond and Chris Hawblitzel and Manos Kapritsos and Rustan Leino and Jay Lorch and Bryan Parno and Ashay Rane and Srinath Setty and Laure Thompson},
  booktitle = {Proc. USENIX Security},
  date      = {2017},
  title     = {Vale: Verifying High-Performance Cryptographic Assembly Code},
  url       = {http://www.cs.cornell.edu/~laurejt/papers/vale-2017.pdf},
}

@InProceedings{nativecompute,
  author    = {Mathieu Boespflug and Maxime Dénès and Benjamin Grégoire},
  booktitle = {Proc. CPP},
  date      = {2011},
  title     = {Full Reduction at Full Throttle},
  doi       = {10.1007/978-3-642-25379-9_26},
}

@InProceedings{LMSVerify,
  author    = {Nada Amin and Tiark Rompf},
  booktitle = {Proc. POPL},
  date      = {2017},
  title     = {{LMS-Verify}: Abstraction without Regret for Verified Systems Programming},
  doi       = {10.1145/3093333.3009867},
}

@InProceedings{TemplateCoq,
  author    = {Abhishek Anand and Simon Boulier and Cyril Cohen and Matthieu Sozeau and Nicolas Tabareau},
  booktitle = {Proc. ITP},
  date      = {2018},
  title     = {Towards Certified Meta-Programming with Typed {Template-Coq}},
  doi       = {10.1007/978-3-319-94821-8_2},
}

@InBook{rtac,
  author    = {Malecha, Gregory and Bengtson, Jesper},
  date      = {2016},
  title     = {Programming Languages and Systems: 25th European Symposium on Programming, ESOP 2016, Held as Part of the European Joint Conferences on Theory and Practice of Software, ETAPS 2016, Eindhoven, The Netherlands, April 2-8, 2016, Proceedings},
  chapter   = {Extensible and Efficient Automation Through Reflective Tactics},
  doi       = {10.1007/978-3-662-49498-1_21},
  editor    = {Thiemann, Peter},
  isbn      = {978-3-662-49498-1},
  location  = {Berlin, Heidelberg},
  pages     = {532--559},
  publisher = {Springer Berlin Heidelberg},
}

@Conference{denes2013prim-ints-arrays,
  author    = {Maxime D\'en\`es},
  booktitle = {The {C}oq Workshop 2013},
  date      = {2013-04-06},
  title     = {Towards primitive data types for {C}OQ},
  subtitle  = {63-bits integers and persistent arrays},
  url       = {https://coq.inria.fr/files/coq5_submission_2.pdf},
  year      = {2013},
}

@PhdThesis{malecha2015thesis,
  author      = {Gregory Michael Malecha},
  date        = {2014-11},
  institution = {Harvard University},
  title       = {Extensible Proof Engineering in Intensional Type Theory},
  url         = {http://gmalecha.github.io/publication/2015/02/01/extensible-proof-engineering-in-intensional-type-theory.html},
}

@InProceedings{debruijn1972,
  author       = {de Bruijn, Nicolaas Govert},
  booktitle    = {Indagationes Mathematicae (Proceedings)},
  date         = {1972},
  title        = {Lambda calculus notation with nameless dummies, a tool for automatic formula manipulation, with application to the {C}hurch-{R}osser theorem},
  doi          = {10.1016/1385-7258(72)90034-0},
  number       = {5},
  organization = {Elsevier},
  pages        = {381--392},
  url          = {http://www.sciencedirect.com/science/article/pii/1385725872900340},
  volume       = {75},
}

@Article{aczel1993galois,
  author      = {Aczel, Peter},
  date        = {1993},
  title       = {Galois: a theory development project},
  url         = {http://www.cs.man.ac.uk/~petera/galois.ps.gz},
  booktitle   = {A report on work in progress for the Turin meeting on the Representation of Logical Frameworks},
  journal-old = {A report on work in progress for the Turin meeting on the Representation of Logical Frameworks},
  local-url   = {http://people.csail.mit.edu/jgross/personal-website/papers/academic-papers-local/galois.pdf},
  owner       = {Jason},
  pdf         = {http://people.csail.mit.edu/jgross/personal-website/papers/academic-papers-local/galois.pdf},
  timestamp   = {2013.12.12},
}

@Article{agerholm1995experiments,
  author       = {Agerholm, Sten},
  date         = {1995-12},
  journaltitle = {Draft manuscript},
  title        = {Experiments in Formalizing Basic Category Theory in Higher Order Logic and Set Theory},
  url          = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.22.8437&rep=rep1&type=pdf},
  local-url    = {http://people.csail.mit.edu/jgross/personal-website/papers/academic-papers-local/download-doi=10.1.1.22.8437.pdf},
  owner        = {Jason},
  publisher    = {Citeseer},
  timestamp    = {2014.03.28},
}

@Electronic{benediktahrens/coinductives,
  author    = {Benedikt Ahrens},
  title     = {Coinductives},
  url       = {https://github.com/benediktahrens/coinductives},
  owner     = {Jason},
  timestamp = {2013.12.31},
}

@Electronic{benediktahrens-Foundations-typesystems,
  author    = {Benedikt Ahrens},
  title     = {{benediktahrens/Foundations typesystems}},
  url       = {https://github.com/benediktahrens/Foundations/tree/typesystems},
  owner     = {Jason},
  timestamp = {2013.12.12},
}

@Misc{ahrens2010categorical,
  author    = {Ahrens, Benedikt},
  date      = {2010},
  title     = {Categorical semantics of programming languages (in {C}OQ)},
  url       = {http://math.unice.fr/~ahrens/edsfa/ahrens_edsfa.pdf},
  local-url = {http://people.csail.mit.edu/jgross/personal-website/papers/academic-papers-local/ahrens_edsfa.pdf},
  owner     = {Jason},
  publisher = {Citeseer},
  timestamp = {2013.12.24},
}

@Electronic{benediktahrens/rezk-completion,
  author    = {Benedikt Ahrens and Chris Kapulkin and Michael Shulman},
  title     = {{benediktahrens/rezk\_completion}},
  url       = {https://github.com/benediktahrens/rezk_completion},
  owner     = {Jason},
  timestamp = {2013.12.12},
}

@Article{Ahrens2013,
  author         = {Benedikt Ahrens and Chris Kapulkin and Michael Shulman},
  date           = {2013-03},
  journaltitle   = {Ar{X}iv e-prints},
  title          = {Univalent categories and the {R}ezk completion},
  doi            = {10.1017/s0960129514000486},
  eprint         = {1303.0584},
  eprintclass    = {math.CT},
  eprinttype     = {arxiv},
  abstract       = {We develop category theory within Univalent Foundations, which is
	a foundational system for mathematics based on a homotopical interpretation
	of dependent type theory. In this system, we propose a definition
	of "category" for which equality and equivalence of categories agree.
	Such categories satisfy a version of the Univalence Axiom, saying
	that the type of isomorphisms between any two objects is equivalent
	to the identity type between these objects; we call them "saturated"
	or "univalent" categories. Moreover, we show that any category is
	weakly equivalent to a univalent one in a universal way. In homotopical
	and higher-categorical semantics, this construction corresponds to
	a truncated version of the Rezk completion for Segal spaces, and
	also to the stack completion of a prestack.},
  adsnote        = {Provided by the SAO/NASA Astrophysics Data System},
  adsurl         = {http://adsabs.harvard.edu/abs/2013arXiv1303.0584A},
  archiveprefix  = {ar{X}iv},
  comments       = {27 pages, ancillary files contain formalized proofs in the proof assistant Coq},
  keywords       = {Mathematics - Category Theory, Mathematics - Logic, 18A15},
  oai2identifier = {1303.0584},
  owner          = {Jason},
  timestamp      = {2013.12.12},
}

@Article{altenkirch2006towards,
  author       = {Altenkirch, Thorsten and McBride, Conor},
  date         = {2006},
  journaltitle = {Manuscript, available online},
  title        = {Towards observational type theory},
  url          = {http://www.strictlypositive.org/ott.pdf},
  local-url    = {http://people.csail.mit.edu/jgross/personal-website/papers/academic-papers-local/ott.pdf},
  owner        = {Jason},
  timestamp    = {2014.04.10},
}

@InProceedings{altenkirch2007observational,
  author       = {Altenkirch, Thorsten and McBride, Conor and Swierstra, Wouter},
  booktitle    = {Proceedings of the 2007 workshop on Programming languages meets program verification},
  date         = {2007},
  title        = {Observational equality, now!},
  doi          = {10.1145/1292597.1292608},
  organization = {ACM},
  pages        = {57--68},
  url          = {http://www.strictlypositive.org/obseqnow.pdf},
  local-url    = {http://people.csail.mit.edu/jgross/personal-website/papers/academic-papers-local/obseqnow.pdf},
  owner        = {Jason},
  timestamp    = {2014.04.10},
}

@InProceedings{altucher1990mechanically,
  author       = {Altucher, James A. and Panangaden, Prakash},
  booktitle    = {10th International Conference on Automated Deduction},
  date         = {1990},
  title        = {A mechanically assisted constructive proof in category theory},
  doi          = {10.1007/3-540-52885-7_110},
  organization = {Springer},
  pages        = {500--513},
  owner        = {Jason},
  timestamp    = {2013.12.12},
}

@Book{awodey2010category,
  author    = {Awodey, Steve},
  title     = {Category theory},
  doi       = {10.1093/acprof:oso/9780198568612.001.0001},
  edition   = {Second Edition},
  publisher = {Oxford University Press},
  owner     = {Jason},
  timestamp = {2013.12.22},
  year-old  = {2010},
}

@InProceedings{barras2008implicit,
  author    = {Barras, Bruno and Bernardo, Bruno},
  booktitle = {FoSSaCS},
  date      = {2008},
  title     = {The implicit calculus of constructions as a programming language with dependent types},
  doi       = {10.1007/978-3-540-78499-9_26},
  url       = {http://hal.archives-ouvertes.fr/docs/00/43/26/58/PDF/icc_barras_bernardo-tpr07.pdf},
  local-url = {http://people.csail.mit.edu/jgross/personal-website/papers/academic-papers-local/icc_barras_bernardo-tpr07.pdf},
  owner     = {Jason},
  pages-old = {365--379},
  timestamp = {2014.01.08},
}

@Electronic{Bertot2013,
  author    = {Yves Bertot},
  date      = {2013-04},
  title     = {Private Inductive Types: Proposing a language extension},
  url       = {http://coq.inria.fr/files/coq5_submission_3.pdf},
  abstract  = {For the Coq system, we propose to add the possibility to declare an
	inductive type as private to the module where it is defined. The
	effect is to preserve the possibility to compute with a restricted
	set of functions, but to disallow uses of the more powerful pattern-matching
	constructs. Such a private type has fruitful applications in homotopy
	type theory.},
  local-url = {http://people.csail.mit.edu/jgross/personal-website/papers/academic-papers-local/coq5_submission_3.pdf},
  owner     = {Jason},
  timestamp = {2014.03.28},
}

@Book{bishop1967foundations,
  author    = {Errett Bishop},
  date      = {1967},
  title     = {Foundations of Constructive Analysis},
  doi       = {10.2307/2314383},
  publisher = {McGraw-Hill},
  series    = {McGraw-Hill series in higher mathematics},
  url       = {http://books.google.com/books?id=o2mmAAAAIAAJ},
  lccn      = {lc67022952},
  owner     = {Jason},
  timestamp = {2014.01.15},
}

@InCollection{caccamo2001higher,
  author    = {C{\'a}ccamo, Mario Jose and Winskel, Glynn},
  booktitle = {Theorem Proving in Higher Order Logics},
  date      = {2001-06},
  title     = {A Higher-Order Calculus for Categories},
  doi       = {10.1007/3-540-44755-5_11},
  editor    = {Boulton, Richard J. and Jackson, Paul B.},
  isbn      = {978-3-540-42525-0},
  language  = {English},
  pages     = {136--153},
  publisher = {Springer Berlin Heidelberg},
  series    = {Lecture Notes in Computer Science},
  url       = {ftp://ftp.daimi.au.dk/BRICS/Reports/RS/01/27/BRICS-RS-01-27.pdf},
  volume    = {2152},
  abstract  = {A calculus for a fragment of category theory is presented. The types
	in the language denote categories and the expressions functors. The
	judgements of the calculus systematise categorical arguments such
	as: an expression is functorial in its free variables; two expressions
	are naturally isomorphic in their free variables. There are special
	binders for limits and more general ends. The rules for limits and
	ends support an algebraic manipulation of universal constructions
	as opposed to a more traditional diagrammatic approach. Duality within
	the calculus and applications in proving continuity are discussed
	with examples. The calculus gives a basis for mechanising a theory
	of categories in a generic theorem prover like Isabelle.},
  local-url = {http://people.csail.mit.edu/jgross/personal-website/papers/academic-papers-local/BRICS-RS-01-27.pdf},
  owner     = {Jason},
  timestamp = {2014.01.12},
}

@Electronic{pcapriotti/agda-categories,
  author    = {Paolo Capriotti},
  title     = {{pcapriotti/agda-categories}},
  url       = {https://github.com/pcapriotti/agda-categories/},
  owner     = {Jason},
  timestamp = {2013.12.12},
}

@TechReport{Carvalho1998,
  author               = {Carvalho, Alexandra and Mateus, Paulo},
  date                 = {1998},
  title                = {Category Theory in {C}oq},
  location             = {1049-001 Lisboa, Portugal},
  url                  = {http://sqig.math.ist.utl.pt/pub/CarvalhoA/98-C-DiplomaThesis/maintext.ps},
  abstract             = {{Herein we formalize a segment of category theory using the implementation
	of Calculus of Inductive Construction in Coq. Adopting the axiomatization
	proposed by Huet and Saibi we start by presenting basic concepts,
	examples and results of category theory in Coq. Next we define adjunction
	and cocartesian lifting and establish some results using the Coq
	proof assistant. Finally we remark that the axiomatization proposed
	by Huet and Saibi is not good when dealing with the equality for
	objects. 1...}},
  citeulike-article-id = {1286396},
  citeulike-linkout-0  = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.29.9846},
  institution-old      = {Instituto Superior Técnico},
  keywords             = {category-theory, formalization},
  local-url            = {http://people.csail.mit.edu/jgross/personal-website/papers/academic-papers-local/maintext.pdf},
  owner                = {Jason Gross},
  pdf                  = {http://people.csail.mit.edu/jgross/personal-website/papers/academic-papers-local/maintext.pdf},
  posted-at            = {2007-05-09 22:07:25},
  timestamp            = {2013.06.19},
}

@Electronic{jmchapman/restriction-categories,
  author    = {James Chapman},
  title     = {jmchapman/restriction-categories},
  url       = {https://github.com/jmchapman/restriction-categories},
  owner     = {Jason},
  timestamp = {2013.12.12},
}

@TechReport{dyckhoff1985category,
  author          = {Dyckhoff, Roy},
  date            = {1985},
  title           = {Category Theory as an Extension of Martin-L\"{o}f Type Theory},
  url             = {http://rd.host.cs.st-andrews.ac.uk/publications/CTMLTT.pdf},
  institution-old = {University of St. Andrews},
  local-url       = {http://people.csail.mit.edu/jgross/personal-website/papers/academic-papers-local/CTMLTT.pdf},
  owner           = {Jason Gross},
  timestamp       = {2013.06.19},
}

@InCollection{Garillot2009,
  author     = {Garillot, Fran\c{c}ois and Gonthier, Georges and Mahboubi, Assia and Rideau, Laurence},
  booktitle  = {Theorem Proving in Higher Order Logics},
  date       = {2009},
  title      = {Packaging Mathematical Structures},
  doi        = {10.1007/978-3-642-03359-9_23},
  publisher  = {Springer Berlin Heidelberg},
  url        = {http://hal.inria.fr/docs/00/36/84/03/PDF/main.pdf},
  abstract   = {This paper proposes generic design patterns to define and combine
	algebraic structures, using dependent records, coercions and type
	inference, inside the Coq system. This alternative to telescopes
	in particular supports multiple inheritance, maximal sharing of notations
	and theories, and automated structure inference. Our methodology
	is robust enough to handle a hierarchy comprising a broad variety
	of algebraic structures, from types with a choice operator to algebraically
	closed fields. Interfaces for the structures enjoy the convenience
	of a classical setting, without requiring any axiom. Finally, we
	present two applications of our proof techniques: a key lemma for
	characterising the discrete logarithm, and a matrix decomposition
	problem.},
  editor-old = {Berghofer, Stefan and Nipkow, Tobias and Urban, Christian and Wenzel, Makarius},
  isbn-old   = {978-3-642-03358-2},
  keywords   = {Formalization of Algebra; Coercive subtyping; Type inference; Coq; SSReflect},
  local-url  = {http://people.csail.mit.edu/jgross/personal-website/papers/academic-papers-local/main.pdf},
  owner      = {Jason},
  pages-old  = {327-342},
  series-old = {Lecture Notes in Computer Science},
  timestamp  = {2014.04.10},
  volume-old = {5674},
}

@InProceedings{gonthier2011make,
  author           = {Gonthier, Georges and Ziliani, Beta and Nanevski, Aleksandar and Dreyer, Derek},
  booktitle        = {ACM SIGPLAN Notices},
  date             = {2011},
  title            = {How to Make Ad Hoc Proof Automation Less Ad Hoc},
  doi              = {10.1145/2034574.2034798},
  organization     = {ACM},
  pages            = {163--175},
  url              = {http://www.mpi-sws.org/~beta/lessadhoc/lessadhoc.pdf},
  volume           = {46},
  local-url        = {http://people.csail.mit.edu/jgross/personal-website/papers/academic-papers-local/lessadhoc.pdf},
  number-duplicate = {9},
  owner            = {Jason},
  timestamp        = {2014.01.08},
}

@Article{Harper1991107,
  author       = {Robert Harper and Robert Pollack},
  date         = {1991},
  journaltitle = {Theoretical Computer Science},
  title        = {Type checking with universes},
  doi          = {10.1016/0304-3975(90)90108-T},
  issn         = {0304-3975},
  number       = {1},
  pages        = {107--136},
  url          = {http://www.sciencedirect.com/science/article/pii/030439759090108T},
  volume       = {89},
  abstract     = {Various formulations of constructive type theories have been proposed
	to serve as the basis for machine-assisted proof and as a theoretical
	basis for studying programming languages. Many of these calculi include
	a cumulative hierarchy of ``universes'', each a type of types closed
	under a collection of type-forming operations. Universes are of interest
	for a variety of reasons, some philosophical (predicative vs. impredicative
	type theories), some theoretical (limitations on the closure properties
	of type theories) and some practical (to achieve some of the advantages
	of a type of all types without sacrificing consistency.) The Generalized
	Calculus of Constructions (CC$^\omega$) is a formal theory of types
	that includes such a hierarchy of universes. Although essential to
	the formalization of constructive mathematics, universes are tedious
	to use in practice, for one is required to make specific choices
	of universe levels and to ensure that all choices are consistent.
	In this paper we study several problems associated with type checking
	in the presence of universes in the context of CC$^\omega$. First,
	we consider the basic type checking and well-typedness problems for
	this calculus. Second, we consider a formulation of Russell and Whitehead's
	``typical ambiguity'' convention whereby universe levels may be elided,
	provided that some consistent assignment of levels leads to a correct
	derivation. Third, we consider the introduction of definitions to
	both the basic calculus and the calculus with typical ambiguity.
	This extension leads to a notion of ``universe polymorphism'' analogous
	to the type polymorphism of ML. Although our study is conducted for
	CC$^\omega$, we expect that our methods will apply to other variants
	of the Calculus of Constructions and to type theories such as Constable's
	V3.},
  local-url    = {http://people.csail.mit.edu/jgross/personal-website/papers/academic-papers-local/1-s2.0-030439759090108T-main.pdf},
  owner        = {Jason},
  timestamp    = {2013.12.24},
}

@Book{harrison1996formalized,
  author      = {Harrison, John},
  date        = {1996},
  title       = {Formalized mathematics},
  isbn        = {9789516508132},
  publisher   = {Turku Centre for Computer Science},
  series      = {TUCS technical report},
  url         = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.47.8842&rep=rep1&type=pdf},
  institution = {Turku Centre for Computer Science},
  local-url   = {http://people.csail.mit.edu/jgross/personal-website/papers/academic-papers-local/download-doi=10.1.1.47.8842.pdf},
  owner       = {Jason},
  timestamp   = {2013.12.24},
}

@Article{hofmann1998groupoid,
  author       = {Hofmann, Martin and Streicher, Thomas},
  date         = {1998-08},
  journaltitle = {Twenty-five years of constructive type theory (Venice, 1995)},
  title        = {The groupoid interpretation of type theory},
  pages        = {83--111},
  url          = {http://www.tcs.ifi.lmu.de/mitarbeiter/martin-hofmann/pdfs/agroupoidinterpretationoftypetheroy.pdf},
  volume       = {36},
  local-url    = {http://people.csail.mit.edu/jgross/personal-website/papers/academic-papers-local/agroupoidinterpretationoftypetheroy.pdf},
  owner        = {Jason},
  timestamp    = {2014.04.15},
}

@InProceedings{huet2000constructive,
  author       = {Huet, G{\'e}rard and Sa{\"i}bi, Amokrane},
  booktitle    = {Proof, language, and interaction},
  date         = {2000},
  title        = {Constructive category theory},
  organization = {MIT Press},
  pages        = {239--275},
  url          = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.39.4193},
  local-url    = {http://people.csail.mit.edu/jgross/personal-website/papers/academic-papers-local/download-doi=10.1.1.39.4193.pdf},
  owner        = {Jason},
  timestamp    = {2013.12.24},
}

@Electronic{konn/category-agda,
  author    = {Hiromi Ishii},
  title     = {{konn/category-agda}},
  url       = {https://github.com/konn/category-agda},
  owner     = {Jason},
  timestamp = {2013.12.12},
}

@Article{Category2-AFP,
  author       = {Alexander Katovsky},
  date         = {2010-06},
  journaltitle = {Archive of Formal Proofs},
  title        = {Category Theory},
  issn         = {2150-914x},
  note         = {\url{http://afp.sf.net/entries/Category2.shtml}, Formal proof development},
  abstract     = {This article presents a development of Category Theory in Isabelle/HOL.
	A Category is defined using records and locales. Functors and Natural
	Transformations are also defined. The main result that has been formalized
	is that the Yoneda functor is a full and faithful embedding. We also
	formalize the completeness of many sorted monadic equational logic.
	Extensive use is made of the HOLZF theory in both cases.},
  local-url    = {http://people.csail.mit.edu/jgross/personal-website/papers/academic-papers-local/Cat.pdf},
  owner        = {Jason},
  pdf          = {http://apk32.user.srcf.net/Isabelle/Category/Cat.pdf},
  timestamp    = {2014.01.19},
}

@Electronic{Komendantsky,
  author       = {Vladimir Komendantsky and Alexander Konovalov and Steve Linton},
  title        = {Connecting {C}oq theorem prover to {GAP}},
  url          = {http://www.symcomp.org/sciencehome-view/images/e/e9/CICM_2010_Komendantsky.pdf},
  organization = {SCIEnce/CICM'10; University of St Andrews, UK},
  local-url    = {http://people.csail.mit.edu/jgross/personal-website/papers/academic-papers-local/CICM_2010_Komendantsky.pdf},
  owner        = {Jason},
  timestamp    = {2014.04.10},
}

@InCollection{kozen2006automating,
  author    = {Kozen, Dexter and Kreitz, Christoph and Richter, Eva},
  booktitle = {Automated Reasoning},
  date      = {2006},
  title     = {Automating Proofs in Category Theory},
  doi       = {10.1007/11814771_34},
  pages     = {392--407},
  publisher = {Springer},
  url       = {http://www.cs.uni-potsdam.de/ti/kreitz/PDF/06ijcar-categories.pdf},
  file      = {Automating Proofs in Category Theory:http\://www.cs.uni-potsdam.de/ti/kreitz/PDF/06ijcar-categories.pdf:URL},
  local-url = {http://people.csail.mit.edu/jgross/personal-website/papers/academic-papers-local/06ijcar-categories.pdf},
  owner     = {Jason Gross},
  timestamp = {2013.06.19},
}

@Electronic{MathClasses,
  author       = {Robbert Krebbers and Bas Spitters and Eelis van der Weegen},
  title        = {Math Classes},
  howpublished = {\url{http://coq.inria.fr/pylons/pylons/contribs/view/MathClasses/v8.4}},
  owner        = {Jason},
  timestamp    = {2013.12.12},
}

@Book{Leinster2007,
  author         = {Tom Leinster},
  title          = {Higher Operads, Higher Categories},
  doi            = {10.1017/cbo9780511525896},
  eprint         = {math/0305049},
  eprinttype     = {arxiv},
  publisher      = {Cambridge Univ.~Press},
  abstract       = {Higher-dimensional category theory is the study of n-categories, operads,
	braided monoidal categories, and other such exotic structures. It
	draws its inspiration from areas as diverse as topology, quantum
	algebra, mathematical physics, logic, and theoretical computer science.
	This is the first book on the subject and lays its foundations. Many
	examples are given throughout. There is also an introductory chapter
	motivating the subject for topologists.},
  adsnote        = {Provided by the SAO/NASA Astrophysics Data System},
  adsurl         = {http://adsabs.harvard.edu/abs/2004hohc.book.....L},
  comments       = {Book, 410 pages},
  isbn-bak       = {0521532159},
  month-bak      = {8},
  oai2identifier = {math/0305049},
  owner          = {Jason},
  publisher-bak  = {Cambridge University Press},
  timestamp      = {2014.01.19},
  year-bak       = {2007},
  year-old       = {2007},
}

@Book{mac1998categories,
  author        = {Mac Lane, Saunders},
  title         = {Categories for the working mathematician},
  doi           = {10.1007/978-1-4612-9839-7},
  url           = {http://books.google.com/books?id=MXboNPdTv7QC},
  owner         = {Jason},
  publisher-old = {Springer verlag},
  timestamp     = {2013.12.23},
  volume-old    = {5},
  year-old      = {1998},
}

@Book{martin1984intuitionistic,
  author    = {Martin-L\"of, Per and Sambin, Giovanni},
  date      = {1984},
  title     = {Intuitionistic Type Theory},
  publisher = {Bibliopolis},
  url       = {http://www.cs.cmu.edu/afs/cs/Web/People/crary/819-f09/Martin-Lof80.pdf},
  volume    = {17},
  local-url = {http://people.csail.mit.edu/jgross/personal-website/papers/academic-papers-local/Martin-Lof80.pdf},
  owner     = {Jason},
  timestamp = {2014.01.17},
}

@Electronic{megacz-coq-categories,
  author    = {Adam Megacz},
  title     = {Category Theory Library for {C}oq},
  url       = {http://www.cs.berkeley.edu/~megacz/coq-categories/},
  language  = {Coq},
  owner     = {Jason},
  timestamp = {2013.12.12},
}

@MastersThesis{mohri1995formalization,
  author       = {Mohri, Takahisa},
  date         = {1995},
  institution  = {University of Tokyo},
  title        = {On formalization of category theory},
  doi          = {10.1007/bfb0028395},
  url          = {http://aleteya.cs.buap.mx/~jlavalle/papers/categorias/ST.ps},
  journaltitle = {A senior thesis},
  local-url    = {http://people.csail.mit.edu/jgross/personal-website/papers/academic-papers-local/ST.pdf},
  owner        = {Jason},
  pdf          = {http://people.csail.mit.edu/jgross/personal-website/papers/academic-papers-local/ST.pdf},
  timestamp    = {2013.12.24},
}

@Electronic{Coalgebras,
  author    = {Milad Niqui},
  date      = {2010-01},
  title     = {Coalgebras, bisimulation and lambda-coiteration},
  url       = {http://coq.inria.fr/pylons/pylons/contribs/view/Coalgebras/v8.4},
  owner     = {Jason},
  timestamp = {2013.12.12},
}

@Electronic{Norell,
  author    = {Ulf Norell},
  date      = {2011-08},
  title     = {{A}gda performance improvements},
  url       = {https://lists.chalmers.se/pipermail/agda/2011/003266.html},
  owner     = {Jason},
  timestamp = {2014.05.10},
}

@Misc{nuo2013second,
  author    = {Nuo, Li},
  date      = {2013-07},
  title     = {Second-Year Annual Report},
  url       = {http://www.cs.nott.ac.uk/~nzl/Home_Page/Homepage_files/AR2-8Jul2013.pdf},
  local-url = {http://people.csail.mit.edu/jgross/personal-website/papers/academic-papers-local/AR2-8Jul2013.pdf},
  owner     = {Jason},
  timestamp = {2014.01.01},
}

@Article{o2004towards,
  author       = {Greg O'Keefe},
  date         = {2004},
  journaltitle = {Electronic Notes in Theoretical Computer Science},
  title        = {Towards a readable formalisation of category theory},
  doi          = {10.1016/j.entcs.2003.12.014},
  pages        = {212--228},
  url          = {http://users.cecs.anu.edu.au/~okeefe/work/fcat4cats04.pdf},
  volume       = {91},
  comment      = {Has survey of existing formalizations},
  local-url    = {http://people.csail.mit.edu/jgross/personal-website/papers/academic-papers-local/fcat4cats04.pdf},
  owner        = {Jason},
  publisher    = {Elsevier},
  timestamp    = {2013.12.12},
}

@Electronic{copumpkin/categories,
  author    = {Daniel Peebles and James Deikun and Andrea Vezzosi and James Cook},
  title     = {{copumpkin/categories}},
  url       = {https://github.com/copumpkin/categories},
  owner     = {Jason},
  timestamp = {2013.12.12},
}

@TechReport{pierce1988taste,
  author          = {Pierce, B.},
  title           = {A taste of category theory for computer scientists},
  url             = {http://repository.cmu.edu/cgi/viewcontent.cgi?article=2846&context=compsci},
  institution-old = {Carnegie Mellon University},
  journal-old     = {Computer Science Department},
  local-url       = {http://people.csail.mit.edu/jgross/personal-website/papers/academic-papers-local/repository.cmu.edu__cgi__viewcontent.cgi_article=2846_context=compsci.pdf},
  owner           = {Jason},
  timestamp       = {2014.01.17},
  year-old        = {1988},
}

@Electronic{Algebra,
  author    = {Lo\"ic Pottier},
  title     = {Algebra},
  url       = {http://coq.inria.fr/pylons/pylons/contribs/view/Algebra/v8.4},
  owner     = {Jason},
  timestamp = {2014.01.01},
}

@Electronic{crypto-agda/crypto-agda,
  author    = {Nicolas Pouillard},
  title     = {{crypto-agda/crypto-agda}},
  url       = {https://github.com/crypto-agda/crypto-agda/tree/master/FunUniverse},
  owner     = {Jason},
  timestamp = {2013.12.12},
}

@Electronic{ConCaT,
  author    = {Amokrane Sa{\"i}bi},
  title     = {Constructive Category Theory},
  url       = {http://coq.inria.fr/pylons/pylons/contribs/view/ConCaT/v8.4},
  owner     = {Jason},
  timestamp = {2013.12.12},
}

@Electronic{interval-implies-funext,
  author    = {Michael Shulman},
  title     = {An Interval Type Implies Function Extensionality},
  url       = {http://homotopytypetheory.org/2011/04/04},
  month-old = {4},
  owner     = {Jason},
  timestamp = {2014.01.01},
  year-old  = {2011},
}

@Electronic{CatsInZFC,
  author    = {Carlos Simpson},
  title     = {{C}ats{I}n{ZFC}},
  url       = {http://coq.inria.fr/pylons/pylons/contribs/view/CatsInZFC/v8.4},
  owner     = {Jason},
  timestamp = {2013.12.12},
}

@Electronic{mattam82/coq-polyproj,
  author    = {Matthieu Sozeau},
  title     = {{mattam82/coq polyproj}},
  url       = {https://github.com/mattam82/coq/tree/polyproj},
  owner     = {Jason},
  timestamp = {2014.01.03},
}

@Electronic{mattam82-cat,
  author    = {Matthieu Sozeau},
  title     = {Cat},
  url       = {http://mattam.org/repos/coq/cat/},
  owner     = {Jason},
  timestamp = {2013.12.12},
}

@Electronic{HoTT/coq,
  author    = {Matthieu Sozeau and Hugo Herbelin and Pierre Letouzey and Jean-Christophe Filli\^{a}tre and Matthieu Sozeau and anonymous and Pierre-Marie Pédrot and Bruno Barras and Jean-Marc Notin and Pierre Boutillier and Enrico Tassi and St\'ephane Glondu and Arnaud Spiwack and Claudio Sacerdoti Coen and Christine Paulin and Olivier Desmettre and Yves Bertot and Julien Forest and David Delahaye and Pierre Corbineau and Julien Narboux and Matthias Puech and Benjamin Monate and Elie Soubiran and Pierre Courtieu and Vincent Gross and Judica\"el Courant and Lionel Elie Mamane and Cl\'ement Renard and Evgeny Makarov and Claude March\'e and Guillaume Melquiond and Micaela Mayero and Yann R\'egis-Gianas and Benjamin Gr\'egoire and Vincent Siles and Fr\'ed\'eric Besson and Laurent Th\'ery and Florent Kirchner and Maxime D\'en\`es and Xavier Clerc and Lo\"ic Pottier and Russel O'Connor and Assia Mahboubi and Benjamin Werner and xclerc and Huang Guan-Shieng and Jason Gross and Tom Hutchinson and Cezary Kaliszyk and Pierre and Daniel De Rauglaudre and Alexandre Miquel and Damien Doligez and Gregory Malecha and Stephane Glondu and Andrej Bauer},
  title     = {{HoTT/coq}},
  url       = {https://github.com/HoTT/coq},
  owner     = {Jason},
  timestamp = {2014.01.16},
}

@InCollection{spitters2010developing,
  author    = {Spitters, Bas and van der Weegen, Eelis},
  booktitle = {Interactive Theorem Proving},
  date      = {2010},
  title     = {Developing the algebraic hierarchy with type classes in {C}oq},
  doi       = {10.1007/978-3-642-14052-5_35},
  publisher = {Springer},
  url       = {http://www.eelis.net/research/math-classes/mathclasses-diamond.pdf},
  local-url = {http://people.csail.mit.edu/jgross/personal-website/papers/academic-papers-local/mathclasses-diamond.pdf},
  owner     = {Jason},
  pages-old = {490--493},
  timestamp = {2013.12.24},
}

@MastersThesis{spiwackverified,
  author      = {Spiwack, Arnaud},
  date        = {2011},
  institution = {\'Ecole Polytechnique},
  title       = {Verified Computing in Homological Algebra},
  type        = {PhD thesis},
  url         = {http://assert-false.net/arnaud/papers/thesis.spiwack.pdf},
  local-url   = {http://people.csail.mit.edu/jgross/personal-website/papers/academic-papers-local/thesis.spiwack.pdf},
  owner       = {Jason},
  timestamp   = {2013.12.20},
}

@MastersThesis{weber02program,
  author      = {Tjark Weber},
  date        = {2002-08},
  institution = {University of Wyoming},
  title       = {Program Transformations in {Nuprl}},
  location    = {Laramie, WY},
  url         = {http://user.it.uu.se/~tjawe125/publications/weber02program.html},
  local-url   = {http://people.csail.mit.edu/jgross/personal-website/papers/academic-papers-local/weber02program.pdf},
  owner       = {Jason},
  pdf         = {http://user.it.uu.se/~tjawe125/publications/weber02program.pdf},
  timestamp   = {2013.12.24},
}

@Article{wilander2012constructing,
  author       = {Wilander, Olov},
  date         = {2012},
  journaltitle = {Mathematical Structures in Computer Science},
  title        = {Constructing a small category of setoids},
  number       = {1},
  pages        = {103--121},
  url          = {http://www.diva-portal.org/smash/get/diva2:399799/FULLTEXT01.pdf},
  volume       = {22},
  local-url    = {http://people.csail.mit.edu/jgross/personal-website/papers/academic-papers-local/FULLTEXT01.pdf},
  owner        = {Jason},
  publisher    = {Cambridge Univ Press},
  timestamp    = {2014.01.01},
}

@TechReport{wilander2005bicategory,
  author      = {Wilander, Olov},
  date        = {2005},
  institution = {Technical report, University of Uppsala},
  title       = {An {E}-bicategory of {E}-categories exemplifying a type-theoretic approach to bicategories},
  local-url   = {http://people.csail.mit.edu/jgross/personal-website/papers/academic-papers-local/download_doi=10.1.1.63.5498.pdf},
  owner       = {Jason},
  pdf         = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.63.5498&rep=rep1&type=pdf},
  timestamp   = {2013.12.24},
}

@Electronic{HoTT/HoTT-categories,
  title      = {{HoTT/HoTT} Categories},
  url        = {https://github.com/HoTT/HoTT/tree/V8.12/theories/Categories},
  author-old = {Jason Gross},
  owner      = {Jason},
  timestamp  = {2014.01.01},
}

@Electronic{wiki:adjoint-functors:universal-morphisms,
  date         = {2020-09-24},
  title        = {Adjoint functors: Formal definitions: Definition via universal morphisms},
  url          = {https://en.wikipedia.org/w/index.php?title=Adjoint_functors&oldid=980061872#Definition_via_universal_morphisms},
  organization = {Wikipedia, the free encyclopedia},
  author-old   = {Wikipedia},
  owner        = {Jason},
  timestamp    = {2014.01.07},
}

@Electronic{ncatlab:adjoint+functor:UniversalArrows,
  date         = {2012-11},
  title        = {adjoint functor: in terms of universal arrows / universal factorization through unit and counit},
  url          = {http://ncatlab.org/nlab/show/adjoint+functor#UniversalArrows},
  organization = {nCatLab},
  author-old   = {nCatLab},
  owner        = {Jason},
  timestamp    = {2014.01.07},
}

@Electronic{ncatlab:subobject+classifier,
  date         = {2012-09},
  title        = {subobject classifier},
  url          = {http://ncatlab.org/nlab/show/subobject+classifier},
  organization = {nLab},
  author-old   = {nCatLab},
  owner        = {Jason},
  timestamp    = {2013.12.22},
}

@Electronic{math-overflow-formalizations,
  title        = {Formalizations of category theory in proof assistants},
  url          = {http://mathoverflow.net/questions/152497/formalizations-of-category-theory-in-proof-assistants},
  organization = {MathOverflow},
  key-old      = {MathOverflow},
  owner        = {Jason},
  timestamp    = {2014.03.28},
}

@InProceedings{adt-synthesis,
  author            = {Ben Delaware and Clément Pit-Claudel and Jason Gross and Adam Chlipala},
  booktitle         = {Proceedings of the \href{http://popl.mpi-sws.org/2015/}{42nd ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages (POPL'15)}},
  date              = {2015-01},
  title             = {Fiat: Deductive Synthesis of Abstract Data Types in a Proof Assistant},
  doi               = {10.1145/2676726.2677006},
  url               = {https://people.csail.mit.edu/jgross/personal-website/papers/2015-adt-synthesis.pdf},
  abstract          = {We present Fiat, a library for the Coq proof assistant supporting refinement of declarative specifications into efficient functional programs with a high degree of automation. Each refinement process leaves a proof trail, checkable by the normal Coq kernel, justifying its soundness. We focus on the synthesis of abstract data types that package methods with private data. We demonstrate the utility of our framework by applying it to the synthesis of \textit{query structures} -- abstract data types with SQL-like query and insert operations. Fiat includes a library for writing specifications of query structures in SQL-inspired notation, expressing operations over relations (tables) in terms of mathematical sets. This library includes a set of tactics for automating the refinement of these specifications into efficient, correct-by-construction OCaml code. Using these tactics, a programmer can generate such an implementation completely automatically by only specifying the equivalent of SQL indexes, data structures capturing useful views of the abstract data. We conclude by speculating on the new programming modularity possibilities enabled by an automated refinement system with proved-correct rules.},
  acm-authorize-url = {https://dl.acm.org/authorize?N20774},
  artifact-tar-gz   = {https://people.csail.mit.edu/jgross/personal-website/media/2015-popl/fiat-20141031.tar.gz},
  owner             = {Jason},
  project-homepage  = {http://plv.csail.mit.edu/fiat/},
  timestamp         = {2014.10.07},
}

@Misc{coqpl-15-coq-bug-minimizer,
  author    = {Jason Gross},
  date      = {2015-01},
  title     = {Coq Bug Minimizer},
  note      = {Presented at \href{https://coqpl.cs.washington.edu/2014/07/31/}{The First International Workshop on Coq for PL (CoqPL'15)}},
  url       = {https://people.csail.mit.edu/jgross/personal-website/papers/2015-coq-bug-minimizer.pdf},
  abstract  = {Are bugs the bane of your existence? Do you dread Coq upgrades, because they mean you'll have to spend days tracking down subtle failures deep in your developments? Have you ever hit an anomaly that just wouldn't go away, and wished you understood what triggered it? Have you ever been tormented by two blocks of code that looked identical, but behaved differently? Do you wish you submit more helpful error reports, but don't want to put in the time to construct minimal examples? If you answered ``yes'' to any of these questions, then the Coq Bug Minimizer is for you! Clone your own copy at \url{https://github.com/JasonGross/coq-bug-finder}.},
  owner     = {Jason},
  reviews   = {https://people.csail.mit.edu/jgross/personal-website/papers/2015-coq-bug-minimizer-reviews.txt},
  timestamp = {2014.10.07},
}

@MastersThesis{jgross-masters-thesis,
  author      = {Jason Gross},
  date        = {2015-09},
  institution = {Massachusetts Institute of Technology},
  title       = {An Extensible Framework for Synthesizing Efficient, Verified Parsers},
  url         = {https://people.csail.mit.edu/jgross/personal-website/papers/2015-jgross-thesis.pdf},
  abstract    = {Parsers have a long history in computer science. This thesis proposes a novel approach to synthesizing efficient, verified parsers by refinement, and presents a demonstration of this approach in the Fiat framework by synthesizing a parser for arithmetic expressions. The benefits of this framework may include more flexibility in the parsers that can be described, more control over the low-level details when necessary for performance, and automatic or mostly automatic correctness proofs.},
}

@InProceedings{category-coq-experience,
  author                      = {Jason Gross and Adam Chlipala and David I. Spivak},
  booktitle                   = {Proceedings of the \href{http://www.cs.uwyo.edu/~ruben/itp-2014}{5th International Conference on Interactive Theorem Proving (ITP'14)}},
  date                        = {2014-07},
  title                       = {Experience Implementing a Performant Category-Theory Library in {C}oq},
  doi                         = {10.1007/978-3-319-08970-6_18},
  eprint                      = {1401.7694},
  url                         = {https://people.csail.mit.edu/jgross/personal-website/papers/category-coq-experience-itp-submission-final.pdf},
  abstract                    = {We describe our experience implementing a broad category-theory library in Coq. Category theory and computational performance are not usually mentioned in the same breath, but we have needed substantial engineering effort to teach Coq to cope with large categorical constructions without slowing proof script processing unacceptably. In this paper, we share the lessons we have learned about how to represent very abstract mathematical objects and arguments in Coq and how future proof assistants might be designed to better support such reasoning. One particular encoding trick to which we draw attention allows category-theoretic arguments involving \emph{duality} to be internalized in Coq's logic with definitional equality. Ours may be the largest Coq development to date that uses the relatively new Coq version developed by homotopy type theorists, and we reflect on which new features were especially helpful.},
  full-bibliography           = {https://people.csail.mit.edu/jgross/personal-website/papers/category-coq-experience.html},
  original-url                = {https://people.csail.mit.edu/jgross/personal-website/papers/category-coq-experience-itp-submission.pdf},
  owner                       = {Jason},
  presentation-annotated-pptx = {https://people.csail.mit.edu/jgross/personal-website/presentations/itp-2014/category-coq-experience.pptx},
  presentation-pdf            = {https://people.csail.mit.edu/jgross/personal-website/presentations/itp-2014/category-coq-experience.pdf},
  published-url-springer      = {http://link.springer.com/chapter/10.1007/978-3-319-08970-6_18},
  reviews                     = {https://people.csail.mit.edu/jgross/personal-website/papers/category-coq-experience-itp-2014-reviews.txt},
  timestamp                   = {2014.01.19},
}

@Misc{coqpl-15-ltac-profiler,
  author    = {Tobias Tebbi and Jason Gross},
  date      = {2015-01},
  title     = {A Profiler for {L}tac},
  note      = {Presented at \href{https://coqpl.cs.washington.edu/2014/07/31/}{The First International Workshop on Coq for PL (CoqPL'15)}},
  url       = {https://people.csail.mit.edu/jgross/personal-website/papers/2015-ltac-profiler.pdf},
  abstract  = {We present a simple profiler for the Ltac tactic language of the Coq Proof Assistent. It measures the time spent in invocations of primitive tactics as well as tactics defined in Ltac and their inner invocations. The profiler is controlled using Vernacular commands and prints an aggregated view that differentiates between tactic invocations depending on their call tree location.},
  owner     = {Jason},
  timestamp = {2014.10.17},
}

@InProceedings{FiatCryptoSP19,
  author      = {Andres Erbsen and Jade Philipoom and Jason Gross and Robert Sloan and Adam Chlipala},
  booktitle   = {IEEE Security \& Privacy},
  date        = {2019-05},
  title       = {Simple High-Level Code For Cryptographic Arithmetic -- With Proofs, Without Compromises},
  doi         = {10.1109/sp.2019.00005},
  location    = {San Francisco, CA, USA},
  url         = {http://adam.chlipala.net/papers/FiatCryptoSP19/},
  abstract    = {We introduce a new approach for implementing cryptographic arithmetic in short high-level code with machine-checked proofs of functional correctness.
We further demonstrate that simple partial evaluation is sufficient to transform into the fastest-known C code, breaking the decades-old pattern that the only fast implementations are those whose instruction-level steps were written out by hand.

These techniques were used to build an elliptic-curve library that achieves competitive performance for 80 prime fields and multiple CPU architectures, showing that implementation and proof effort scales with the number and complexity of conceptually different algorithms, not their use cases.
As one outcome, we present the first verified high-performance implementation of P-256, the most widely used elliptic curve.
Implementations from our library were included in BoringSSL to replace existing specialized code, for inclusion in several large deployments for Chrome, Android, and CloudFlare.},
  code-github = {https://github.com/mit-plv/fiat-crypto},
  owner       = {jgross},
  timestamp   = {2018.06.01},
}

@Article{ringer2020qed,
  author       = {Talia Ringer and Karl Palmskog and Ilya Sergey and Milos Gligoric and Zachary Tatlock},
  date         = {2020-03-13},
  journaltitle = {Foundations and Trends in Programming Languages, Vol. 5, No. 2-3 (Sept. 2019), pp. 102-281},
  title        = {{QED} at Large: A Survey of Engineering of Formally Verified Software},
  doi          = {10.1561/2500000045},
  eprint       = {2003.06458},
  eprintclass  = {cs.LO},
  eprinttype   = {arxiv},
  abstract     = {Development of formal proofs of correctness of programs can increase actual and perceived reliability and facilitate better understanding of program specifications and their underlying assumptions. Tools supporting such development have been available for over 40 years, but have only recently seen wide practical use. Projects based on construction of machine-checked formal proofs are now reaching an unprecedented scale, comparable to large software projects, which leads to new challenges in proof development and maintenance. Despite its increasing importance, the field of proof engineering is seldom considered in its own right; related theories, techniques, and tools span many fields and venues. This survey of the literature presents a holistic understanding of proof engineering for program correctness, covering impact in practice, foundations, proof automation, proof organization, and practical proof development.},
  file         = {:http\://arxiv.org/pdf/2003.06458v1:PDF},
  keywords     = {cs.LO, cs.PL, F.3.1; D.2.4; I.2.3},
}

@Article{georges2007statistically,
  author       = {Georges, Andy and Buytaert, Dries and Eeckhout, Lieven},
  date         = {2007},
  journaltitle = {ACM SIGPLAN Notices},
  title        = {Statistically Rigorous Java Performance Evaluation},
  doi          = {10.1145/1297027.1297033},
  number       = {10},
  pages        = {57--76},
  volume       = {42},
  publisher    = {ACM New York, NY, USA},
}

@Article{mytkowicz-wrong-data,
  author       = {Mytkowicz, Todd and Diwan, Amer and Hauswirth, Matthias and Sweeney, Peter F.},
  date         = {2009},
  journaltitle = {ACM Sigplan Notices},
  title        = {Producing Wrong Data Without Doing Anything Obviously Wrong!},
  doi          = {10.1145/1508284.1508275},
  number       = {3},
  pages        = {265--276},
  url          = {https://users.cs.northwestern.edu/~robby/courses/322-2013-spring/mytkowicz-wrong-data.pdf},
  volume       = {44},
  abstract     = {This paper presents a surprising result: changing a seemingly
innocuous aspect of an experimental setup can cause a systems researcher to draw wrong conclusions from an experiment. What appears to be an innocuous aspect in the experimental setup may in fact introduce a significant bias in an
evaluation. This phenomenon is called \emph{measurement bias} in
the natural and social sciences.
Our results demonstrate that measurement bias is significant and commonplace in computer system evaluation. By
\emph{significant} we mean that measurement bias can lead to a performance analysis that either over-states an effect or even
yields an incorrect conclusion. By \emph{commonplace} we mean
that measurement bias occurs in all architectures that we
tried (Pentium 4, Core 2, and m5 O3CPU), both compilers
that we tried (gcc and Intel’s C compiler), and most of the
SPEC CPU2006 C programs. Thus, we cannot ignore measurement bias. Nevertheless, in a literature survey of 133 recent papers from ASPLOS, PACT, PLDI, and CGO, we determined that none of the papers with experimental results
adequately consider measurement bias.
Inspired by similar problems and their solutions in other
sciences, we describe and demonstrate two methods, one
for detecting (causal analysis) and one for avoiding (setup
randomization) measurement bias.},
  publisher    = {ACM New York, NY, USA},
}

@InProceedings{CelikETAL17iCoq,
  author       = {Celik, Ahmet and Palmskog, Karl and Gligoric, Milos},
  booktitle    = {2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)},
  date         = {2017},
  title        = {{ɪCᴏǫ}: Regression Proof Selection for Large-Scale Verification Projects},
  doi          = {10.1109/ase.2017.8115630},
  organization = {IEEE},
  pages        = {171--182},
  url          = {https://users.ece.utexas.edu/~gligoric/papers/CelikETAL17iCoq.pdf},
  abstract     = {Proof assistants such as Coq are used to construct
and check formal proofs in many large-scale verification projects.
As proofs grow in number and size, the need for tool support
to quickly find failing proofs after revising a project increases.
We present a technique for large-scale regression proof selection,
suitable for use in continuous integration services, e.g., Travis CI.
We instantiate the technique in a tool dubbed \textsc{iCoq}. \textsc{iCoq} tracks
fine-grained dependencies between Coq definitions, propositions,
and proofs, and only checks those proofs affected by changes
between two revisions. \textsc{iCoq} additionally saves time by ignoring
changes with no impact on semantics. We applied \textsc{iCoq} to track
dependencies across many revisions in several large Coq projects
and measured the time savings compared to proof checking from
scratch and when using Coq’s timestamp-based toolchain for
incremental checking. Our results show that proof checking with
\textsc{iCoq} is up to 10 times faster than the former and up to 3 times
faster than the latter.},
}

@InProceedings{PalmskogETAL18piCoq,
  author    = {Palmskog, Karl and Celik, Ahmet and Gligoric, Milos},
  booktitle = {Proceedings of the 27th ACM SIGSOFT International Symposium on Software Testing and Analysis},
  date      = {2018},
  title     = {{ᴘɪCᴏǫ}: Parallel regression proving for large-scale verification projects},
  doi       = {10.1145/3213846.3213877},
  pages     = {344--355},
  url       = {http://users.ece.utexas.edu/~gligoric/papers/PalmskogETAL18piCoq.pdf},
  abstract  = {Large-scale verification projects using proof assistants typically
contain many proofs that must be checked at each new project
revision. While proof checking can sometimes be parallelized at
the coarse-grained file level to save time, recent changes in some
proof assistant in the LCF family, such as Coq, enable fine-grained
parallelism at the level of proofs. However, these parallel techniques
are not currently integrated with regression proof selection, a technique that checks only the subset of proofs affected by a change. We
present techniques that blend the power of parallel proof checking
and selection to speed up regression proving in verification projects,
suitable for use both on users’ own machines and in workflows
involving continuous integration services. We implemented the
techniques in a tool, \textsc{piCoq}, which supports Coq projects. \textsc{piCoq}
can track dependencies between files, definitions, and lemmas and
perform parallel checking of only those files or proofs affected
by changes between two project revisions. We applied \textsc{piCoq} to
perform regression proving over many revisions of several large
open source projects and measured the proof checking time. While
gains from using proof-level parallelism and file selection can be
considerable, our results indicate that proof-level parallelism and
proof selection is consistently much faster than both sequential
checking from scratch and sequential checking with proof selection.
In particular, 4-way parallelization is up to 28.6 times faster than
the former, and up to 2.8 times faster than the latter.},
}

@Article{lean-tactic-language,
  author       = {Ebner, Gabriel and Ullrich, Sebastian and Roesch, Jared and Avigad, Jeremy and de Moura, Leonardo},
  date         = {2017},
  journaltitle = {Proceedings of the ACM on Programming Languages},
  title        = {A Metaprogramming Framework for Formal Verification},
  doi          = {10.1145/3110278},
  number       = {ICFP},
  pages        = {1--29},
  url          = {https://leanprover.github.io/papers/tactic.pdf},
  volume       = {1},
  publisher    = {ACM New York, NY, USA},
}

@Article{Implementing1998Shao,
  author       = {Shao, Zhong and League, Christopher and Monnier, Stefan},
  date         = {1998},
  journaltitle = {ACM SIGPLAN Notices},
  title        = {Implementing Typed Intermediate Languages},
  doi          = {10.1145/291251.289460},
  number       = {1},
  pages        = {313--323},
  volume       = {34},
  publisher    = {ACM New York, NY, USA},
}

@InProceedings{Inductive2003Brady,
  author       = {Brady, Edwin and McBride, Conor and McKinna, James},
  booktitle    = {International Workshop on Types for Proofs and Programs},
  date         = {2003},
  title        = {Inductive Families Need Not Store Their Indices},
  doi          = {10.1007/978-3-540-24849-1_8},
  organization = {Springer},
  pages        = {115--129},
  url          = {https://eb.host.cs.st-andrews.ac.uk/writings/types2003.pdf},
}

@Book{thesis-nogin,
  author    = {Nogin, Aleksey Yuryevich},
  date      = {2002},
  title     = {Theory and Implementation of an Efficient Tactic-Based Logical Framework},
  publisher = {Cornell University},
  url       = {http://www.nuprl.org/documents/Nogin/thesis-nogin.pdf},
  abstract  = {Formal methods are successfully used in a wide range of applications — from hardware and software verification to formalizing mathematics and education. However their impact is limited and is very far from realizing the full potential of formal methods. Our investigation of these limitations shows that they can not be avoided by simply fine-tuning existing tools and methods. We demonstrate the need to concentrate on improving and extending the underlying theory and methodology of computer-aided formal reasoning.

This thesis explores both practical and theoretical aspects of achieving these improvements; we present solutions for some of the outstanding problems and substantial improvements for others. In particular, we improve axiomatizations of the extant logics to make them more accessible to both users of the system and proof automating procedures. We also present methods for very significant speedup of the proof search process. Such additional speed means not only that the theorem prover will work faster, but also users can now take advantage of more advanced proof automation procedures that would have been prohibitively slow otherwise.

This thesis also demonstrates how these wide ranging practical and theoretical results can be brought together in a more efficient and more generic tactic-based formal system. In particular, we present a generic derived rules mechanism and explain how such a mechanism can facilitate practical modularization of a formal system. We also present several approaches to establishing a generic layer of proof automation procedures (tactics) that apply to a wide variety of logical theories. Most of the ideas presented in this thesis were implemented in the MetaPRL logical framework taking advantage of an existing modular flexible design and making it even more modular and more flexible.

After implementing these ideas in the MetaPRL logical framework, we use that system to improve a formalization of NuPRL intuitionistic type theory. In particular, we show how to modularize an axiomatization of a quotient type thus creating a formalization capable of expressing important concepts that were impossible to express in the original monolithic axiomatization. We also show how to add a limited form of classical reasoning to an intuitionistic type theory in a way that preserves many constructive aspects of the theory. Several theorems in this thesis were formally proven in the MetaPRL system.},
}

@InProceedings{vmcompute,
  author       = {Benjamin Gr{\'e}goire and Xavier Leroy},
  booktitle    = {ICFP 2002: International Conference on Functional Programming},
  date         = {2002},
  title        = {A compiled implementation of strong reduction},
  doi          = {10.1145/581478.581501},
  pages        = {235--246},
  publisher    = {ACM},
  abstract     = {Motivated by applications to proof assistants based on dependent
types, we develop and prove correct a strong reducer and
$\beta$-equivalence checker for the $\lambda$-calculus with products,
sums, and guarded fixpoints.  Our approach is based on compilation to
the bytecode of an abstract machine performing weak reductions on
non-closed terms, derived with minimal modifications from the ZAM
machine used in the Objective Caml bytecode interpreter, and
complemented by a recursive ``read back'' procedure.  An
implementation in the Coq proof assistant demonstrates important
speed-ups compared with the original interpreter-based implementation
of strong reduction in Coq.},
  urllocal     = {http://xavierleroy.org/publi/strong-reduction.pdf},
  urlpublisher = {http://dx.doi.org/10.1145/581478.581501},
  xranking     = {top},
  xtopic       = {caml},
}

@PhdThesis{Strongly2011Kleeblatt,
  author      = {Kleeblatt, Dirk},
  date        = {2011},
  institution = {Technischen Universität Berlin},
  title       = {On a Strongly Normalizing {STG} Machine},
  subtitle    = {With an Application to Dependent Type Checking},
  type        = {phdthesis},
  url         = {https://depositonce.tu-berlin.de/bitstream/11303/3095/1/Dokument_9.pdf},
}

@Software{smallttKovacs,
  author = {András Kovács},
  title  = {smalltt: Demo for high-performance type theory elaboration},
  url    = {https://github.com/AndrasKovacs/smalltt},
}

@Misc{FastKovacs,
  author   = {András Kovács},
  date     = {2019-02-24},
  title    = {Fast Elaboration for Dependent Type Theories},
  location = {EUTypes WG Meeting, Krakow},
  url      = {https://github.com/AndrasKovacs/smalltt/blob/fb56723b098cb1a95e8a5f3f9f5fce30bbcc67da/krakow-pres.pdf},
}

@Software{NormalizationKovacs,
  author = {András Kovács},
  title  = {Normalization Bench},
  url    = {https://github.com/AndrasKovacs/normalization-bench},
}

@Article{GluedEvalKovacs,
  author = {András Kovács},
  title  = {Non-deterministic normalization-by-evaluation in Olle Fredriksson's flavor},
  url    = {https://gist.github.com/AndrasKovacs/a0e0938113b193d6b9c1c0620d853784},
}

@Article{Tabled2020Selsam,
  author      = {Daniel Selsam and Sebastian Ullrich and Leonardo de Moura},
  date        = {2020-01-13},
  title       = {Tabled Typeclass Resolution},
  eprint      = {2001.04301v2},
  eprintclass = {cs.PL},
  eprinttype  = {arXiv},
  abstract    = {Typeclasses provide an elegant and effective way of managing ad-hoc polymorphism in both programming languages and interactive proof assistants. However, the increasingly sophisticated uses of typeclasses within proof assistants, especially within Lean's burgeoning mathematics library, mathlib, have elevated once-theoretical limitations of existing typeclass resolution procedures into major impediments to ongoing progress. The two most devastating limitations of existing procedures are exponential running times in the presence of diamonds and divergence in the presence of cycles. We present a new procedure, tabled typeclass resolution, that solves both problems by tabling, which is a generalization of memoizing originally introduced to address similar limitations of early logic programming systems. We have implemented our procedure for the upcoming version (v4) of Lean, and have confirmed empirically that our implementation is exponentially faster than existing systems in the presence of diamonds. Although tabling is notoriously difficult to implement, our procedure is notably lightweight and could easily be implemented in other systems. We hope our new procedure facilitates even more sophisticated uses of typeclasses in both software development and interactive theorem proving.},
  file        = {:http\://arxiv.org/pdf/2001.04301v2:PDF},
  keywords    = {cs.PL, cs.LO},
}

@Article{Interaction1994Asperti,
  author       = {Asperti, Andrea and Laneve, Cosimo},
  date         = {1994},
  journaltitle = {Mathematical Structures in Computer Science},
  title        = {Interaction Systems {I}: The theory of optimal reductions},
  doi          = {10.1017/s0960129500000566},
  number       = {4},
  pages        = {457--504},
  url          = {https://hal.inria.fr/docs/00/07/69/88/PDF/RR-1748.pdf},
  volume       = {4},
  publisher    = {Cambridge University Press},
}

@InProceedings{asperti1995deltao,
  author       = {Asperti, Andrea},
  booktitle    = {International Conference on Rewriting Techniques and Applications},
  date         = {1995},
  title        = {$\delta$$\omicron$!$\epsilon$=1 Optimizing optimal $\lambda$-calculus implementations},
  editor       = {Hsiang, Jieh},
  isbn         = {978-3-540-49223-8},
  location     = {Berlin, Heidelberg},
  organization = {Springer},
  pages        = {102--116},
  publisher    = {Springer Berlin Heidelberg},
  abstract     = {In [As94], a correspondence between Lamping-Gonthier's operators for Optimal Reduction of the $\lambda$-calculus [Lam90, GAL92a] and the operations associated with the comonad ``!'' of Linear Logic was established. In this paper, we put this analogy at work, adding new rewriting rules directly suggested by the categorical equations of the comonad. These rules produce an impressive improvement of the performance of the reduction system, and provide a first step towards the solution of the well known and crucial problem of accumulation of control operators.},
}

@TechReport{Bologna1995Asperti,
  author      = {Asperti, Andrea and Giovannetti, Cecilia and Naletto, Andrea},
  date        = {1995-03},
  institution = {University of Bologna},
  title       = {The {B}ologna Optimal Higher-order Machine},
  doi         = {10.1017/s0956796800001994},
  url         = {https://pdfs.semanticscholar.org/3517/03af066fd2e65ad64c63108672d960b9d8fb.pdf},
}

@InProceedings{algorithm1989Lamping,
  author    = {Lamping, John},
  booktitle = {Proceedings of the 17th ACM SIGPLAN-SIGACT symposium on Principles of programming languages},
  date      = {1989},
  title     = {An algorithm for optimal lambda calculus reduction},
  doi       = {10.1145/96709.96711},
  pages     = {16--30},
}

@Misc{geometry1992Gonthier,
  author = {Georges Gonthier and Martín Abadi and Jean-Jacques Lévy},
  date   = {1992},
  title  = {The geometry of optimal lambda reduction},
  doi    = {10.1145/143165.143172},
}

@InCollection{Optimal1980Levy,
  author    = {Jean-Jacques Lévy},
  booktitle = {To {H}.~{B}.~{C}urry: Essays on Combinatory Logic, Lambda Calculus and Formalism},
  date      = {1980},
  title     = {Optimal reductions in the lambda-calculus},
  editor    = {J. P. Seldin and J. R. Hindley},
  publisher = {Academic Press},
  url       = {http://pauillac.inria.fr/~levy/pubs/80curry.pdf},
}

@Electronic{SOOnlineTTReferenceKovacs,
  author = {András Kovács},
  date   = {2019-12-10},
  title  = {Online reference book for *implementing* concepts in type theory.},
  url    = {https://math.stackexchange.com/a/3468022/22982},
}

@Misc{SharingKovacs,
  author   = {András Kovács},
  date     = {2018-01},
  title    = {Sharing-Preserving Elaboration with Precisely Scoped Metavariables},
  location = {Agda Implementors’ Meeting XXVI},
  url      = {https://github.com/AndrasKovacs/elaboration-zoo/blob/0c7f8a676c0964cc05c247879393e97729f59e5b/AIMprez/AIMprez.pdf},
}

@InProceedings{Programming2000Barras,
  author    = {Barras, Bruno},
  booktitle = {Theorem Proving in Higher Order Logics},
  date      = {2000},
  title     = {Programming and Computing in {HOL}},
  doi       = {10.1007/3-540-44659-1_2},
  editor    = {Aagaard, Mark and Harrison, John},
  isbn      = {978-3-540-44659-0},
  location  = {Berlin, Heidelberg},
  pages     = {17--37},
  publisher = {Springer Berlin Heidelberg},
  abstract  = {This article describes a set of derived inference rules and an abstract reduction machine using them that allow the inplementation of an interpreter for HOL terms, with the same complexity as with ML code. The latter fact allows us to use HOL as a computer algebra system in which the user can implement algorithms, provided he proved them correct.},
}

@Book{Efficiency1994Boulton,
  author    = {Boulton, Richard},
  date      = {1994-11},
  title     = {Efficiency in a Fully-Expansive Theorem Prover},
  publisher = {University of Cambridge, Computer Laboratory},
  series    = {Computer Laboratory Cambridge: Technical report},
  url       = {https://books.google.com/books?id=7DAkAQAAIAAJ},
}

@Article{LCF2019Paulson,
  author      = {Lawrence C. Paulson and Tobias Nipkow and Makarius Wenzel},
  date        = {2019-07-05},
  title       = {From {LCF} to {I}sabelle/{HOL}},
  doi         = {10.1007/s00165-019-00492-1},
  eprint      = {1907.02836v2},
  eprintclass = {cs.LO},
  eprinttype  = {arXiv},
  abstract    = {Interactive theorem provers have developed dramatically over the past four decades, from primitive beginnings to today's powerful systems. Here, we focus on Isabelle/HOL and its distinctive strengths. They include automatic proof search, borrowing techniques from the world of first order theorem proving, but also the automatic search for counterexamples. They include a highly readable structured language of proofs and a unique interactive development environment for editing live proof documents. Everything rests on the foundation conceived by Robin Milner for Edinburgh LCF: a proof kernel, using abstract types to ensure soundness and eliminate the need to store proofs. Compared with the research prototypes of the 1970s, Isabelle is a practical and versatile tool. It is used by system designers, mathematicians and many others.},
  file        = {:http\://arxiv.org/pdf/1907.02836v2:PDF},
  keywords    = {cs.LO},
}

@Misc{TrustedSlind,
  author   = {Konrad Slind},
  date     = {2010-08},
  title    = {Trusted Extensions of Interactive Theorem Provers: Workshop Summary},
  location = {Cambridge, England},
  url      = {http://www.cs.utexas.edu/users/kaufmann/itp-trusted-extensions-aug-2010/summary/summary.pdf},
  xurl     = {http://www.cs.utexas.edu/users/kaufmann/itp-trusted-extensions-aug-2010/summary/summary.pdf},
}

@Article{Should1999Lamport,
  author       = {Lamport, Leslie and Paulson, Lawrence C.},
  date         = {1999-05},
  journaltitle = {ACM Transactions on Programming Languages and Systems},
  title        = {Should Your Specification Language Be Typed?},
  doi          = {10.1145/319301.319317},
  issn         = {0164-0925},
  number       = {3},
  pages        = {502--526},
  url          = {https://lamport.azurewebsites.net/pubs/lamport-types.pdf},
  volume       = {21},
  issue_date   = {May 1999},
  keywords     = {specification, types, set theory},
  location     = {New York, NY, USA},
  numpages     = {25},
  publisher    = {Association for Computing Machinery},
}

@Article{Formalising2018Paulson,
  author      = {Lawrence C. Paulson},
  date        = {2018-04-20},
  title       = {Formalising Mathematics In Simple Type Theory},
  doi         = {10.1007/978-3-030-15655-8_20},
  eprint      = {1804.07860v1},
  eprintclass = {cs.LO},
  eprinttype  = {arXiv},
  abstract    = {Despite the considerable interest in new dependent type theories, simple type theory (which dates from 1940) is sufficient to formalise serious topics in mathematics. This point is seen by examining formal proofs of a theorem about stereographic projections. A formalisation using the HOL Light proof assistant is contrasted with one using Isabelle/HOL. Harrison's technique for formalising Euclidean spaces is contrasted with an approach using Isabelle/HOL's axiomatic type classes. However, every formal system can be outgrown, and mathematics should be formalised with a view that it will eventually migrate to a new formalism.},
  file        = {:http\://arxiv.org/pdf/1804.07860v1:PDF},
  keywords    = {cs.LO, 03A05},
}

@Article{Sealing2020Selsam,
  author      = {Daniel Selsam and Simon Hudon and Leonardo de Moura},
  date        = {2020-03-03},
  title       = {Sealing Pointer-Based Optimizations Behind Pure Functions},
  eprint      = {2003.01685v1},
  eprintclass = {cs.PL},
  eprinttype  = {arXiv},
  abstract    = {Functional programming languages are particularly well-suited for building automated reasoning systems, since (among other reasons) a logical term is well modeled by an inductive type, traversing a term can be implemented generically as a higher-order combinator, and backtracking is dramatically simplified by persistent datastructures. However, existing pure functional programming languages all suffer a major limitation in these domains: traversing a term requires time proportional to the tree size of the term as opposed to its graph size. This limitation would be particularly devastating when building automation for interactive theorem provers such as Lean and Coq, for which the exponential blowup of term-tree sizes has proved to be both common and difficult to prevent. All that is needed to recover the optimal scaling is the ability to perform simple operations on the memory addresses of terms, and yet allowing these operations to be used freely would clearly violate the basic premise of referential transparency. We show how to use dependent types to seal the necessary pointer-address manipulations behind pure functional interfaces while requiring only a negligible amount of additional trust. We have implemented our approach for the upcoming version (v4) of Lean, and our approach could be adopted by other languages based on dependent type theory as well.},
  file        = {:http\://arxiv.org/pdf/2003.01685v1:PDF},
  keywords    = {cs.PL},
}

@Electronic{CC++Performance2017,
  author       = {Vishal Kasliwal and Andrey Vladimirov},
  date         = {2017-11-19},
  title        = {A Performance-Based Comparison of C/C++ Compilers},
  url          = {https://colfaxresearch.com/compiler-comparison/},
  organization = {Colfax International},
}

@InProceedings{Coqoon2016Faithfull,
  author    = {Faithfull, Alexander and Bengtson, Jesper and Tassi, Enrico and Tankink, Carst},
  booktitle = {Tools and Algorithms for the Construction and Analysis of Systems},
  date      = {2016},
  title     = {Coqoon},
  doi       = {10.1007/s10009-017-0457-2},
  editor    = {Chechik, Marsha and Raskin, Jean-Fran{\c{c}}ois},
  isbn      = {978-3-662-49674-9},
  location  = {Berlin, Heidelberg},
  pages     = {316--331},
  publisher = {Springer Berlin Heidelberg},
  subtitle  = {An {IDE} for Interactive Proof Development in {C}oq},
  url       = {https://hal.inria.fr/hal-01242295/document},
  abstract  = {User interfaces for interactive proof assistants have always lagged behind those for mainstream programming languages. Whereas integrated development environments---IDEs---have support for features like project management, version control, dependency analysis and incremental project compilation, ``IDE''s for proof assistants typically only operate on files in isolation, relying on external tools to integrate those files into larger projects. In this paper we present Coqoon, an IDE for Coq developments integrated into Eclipse. Coqoon manages proofs as projects rather than isolated source files, and compiles these projects using the Eclipse common build system. Coqoon takes advantage of the latest features of Coq, including asynchronous and parallel processing of proofs, and---when used together with a third-party OCaml extension for Eclipse---can even be used to work on large developments containing Coq plugins.},
}

@Electronic{TypedUntyped2018Malecha,
  author = {Gregory Malecha},
  date   = {2018-02-20},
  title  = {To Be Typed and Untyped},
  url    = {https://gmalecha.github.io/reflections/2018/to-be-typed-or-untyped},
}

@Electronic{Speeding2017Malecha,
  author = {Gregory Malecha},
  date   = {2017-06-05},
  title  = {Speeding Up Proofs with Computational Reflection},
  url    = {https://gmalecha.github.io/reflections/2017/speeding-up-proofs-with-computational-reflection},
}

@Article{malecha2013mirror-shard,
  author       = {Gregory Malecha and Adam Chlipala and Thomas Braibant and Patrick Hulin and Edward Z. Yang},
  date         = {2013},
  journaltitle = {CoRR},
  title        = {MirrorShard: Proof by Computational Reflection with Verified Hints},
  eprint       = {1305.6543},
  eprinttype   = {arxiv},
  volume       = {abs/1305.6543},
  bibsource    = {dblp computer science bibliography, http://dblp.org},
  biburl       = {http://dblp.uni-trier.de/rec/bib/journals/corr/abs-1305-6543},
  timestamp    = {Sun, 02 Jun 2013 20:48:21 +0200},
}

@InBook{LCF2000Gordon,
  author    = {Michael John Caldwell Gordon},
  booktitle = {Proof, Language, and Interaction: Essays in Honour of Robin Milner},
  date      = {2000},
  title     = {From {LCF} to {HOL}: A Short History},
  isbn      = {0262161885},
  location  = {Cambridge, MA, USA},
  pages     = {169--185},
  publisher = {MIT Press},
  url       = {https://www.cl.cam.ac.uk/archive/mjcg/papers/HolHistory.pdf},
  numpages  = {17},
}

@Article{Tactics2015Gordon,
  author       = {Michael John Caldwell Gordon},
  date         = {2015-04-13},
  journaltitle = {Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences},
  title        = {Tactics for mechanized reasoning: a commentary on Milner (1984) `The use of machines to assist in rigorous proof'},
  doi          = {10.1098/rsta.2014.0234},
  issn         = {1471-2962},
  issue        = {2039},
  volume       = {373},
  publisher    = {The Royal Society Publishing},
}

@InProceedings{Role2005Barras,
  author    = {Barras, Bruno and Gr{\'e}goire, Benjamin},
  booktitle = {Computer Science Logic},
  date      = {2005},
  title     = {On the Role of Type Decorations in the Calculus of Inductive Constructions},
  doi       = {10.1007/11538363_12},
  editor    = {Ong, Luke},
  isbn      = {978-3-540-31897-2},
  location  = {Berlin, Heidelberg},
  pages     = {151--166},
  publisher = {Springer Berlin Heidelberg},
  abstract  = {In proof systems like Coq [16], proof-checking involves comparing types modulo $\beta$-conversion, which is potentially a time-consuming task. Significant speed-ups are achieved by compiling proof terms, see [9]. Since compilation erases some type information, we have to show that convertibility is preserved by type erasure. This article shows the equivalence of the Calculus of Inductive Constructions (formalism of Coq) and its domain-free version where parameters of inductive types are also erased. It generalizes and strengthens significantly a similar result by Barthe and S{\o}rensen [5] on the class of functional Domain-free Pure Type Systems.},
}

@Electronic{Idris2Faster2020Brady,
  author = {Edwin Brady},
  date   = {2020-05-20},
  title  = {Why is {I}dris 2 so much faster than {I}dris 1?},
  url    = {https://www.type-driven.org.uk/edwinb/why-is-idris-2-so-much-faster-than-idris-1.html},
}

@Electronic{NewCoqTactics2016Pedrot,
  author = {Pierre-Marie Pédrot},
  date   = {2016-02-14},
  title  = {{C}oq{HoTT}-minute: Ticking like a Clockwork: the New {C}oq Tactics},
  url    = {http://coqhott.gforge.inria.fr/blog/coq-tactic-engine/},
}

@Article{Nominal2003Pitts,
  author       = {Andrew M. Pitts},
  date         = {2003},
  journaltitle = {Information and Computation},
  title        = {Nominal logic, a first order theory of names and binding},
  doi          = {10.1016/S0890-5401(03)00138-X},
  issn         = {0890-5401},
  note         = {Theoretical Aspects of Computer Software (TACS 2001)},
  number       = {2},
  pages        = {165--193},
  url          = {https://www.sciencedirect.com/science/article/pii/S089054010300138X},
  volume       = {186},
  abstract     = {This paper formalises within first-order logic some common practices in computer science to do with representing and reasoning about syntactical structures involving lexically scoped binding constructs. It introduces Nominal Logic, a version of first-order many-sorted logic with equality containing primitives for renaming via name-swapping, for freshness of names, and for name-binding. Its axioms express properties of these constructs satisfied by the FM-sets model of syntax involving binding, which was recently introduced by the author and M.J. Gabbay and makes use of the Fraenkel–Mostowski permutation model of set theory. Nominal Logic serves as a vehicle for making two general points. First, name-swapping has much nicer logical properties than more general, non-bijective forms of renaming while at the same time providing a sufficient foundation for a theory of structural induction/recursion for syntax modulo α-equivalence. Secondly, it is useful for the practice of operational semantics to make explicit the equivariance property of assertions about syntax – namely that their validity is invariant under name-swapping.},
  keywords     = {Abstract syntax, Variable binding, Permutation, Fresh names},
}

@Article{Locally2012Chargueraud,
  author       = {Arthur Charguéraud},
  date         = {2012-10},
  journaltitle = {Journal of Automated Reasoning},
  title        = {The Locally Nameless Representation},
  doi          = {10.1007/s10817-011-9225-2},
  language     = {English},
  number       = {3},
  pages        = {363--408},
  url          = {https://www.chargueraud.org/research/2009/ln/main.pdf},
  volume       = {49},
  abstract     = {This paper provides an introduction to the locally nameless approach to the representation of syntax with variable binding, focusing in particular on the use of this technique in formal proofs. First, we explain the benefits of representing bound variables with de Bruijn indices while retaining names for free variables. Then, we explain how to describe and manipulate syntax in that form, and show how to define and reason about judgments on locally nameless terms.},
  keywords     = {Computers--Automation},
}

@TechReport{locally2007Leroy,
  author      = {Xavier Leroy},
  date        = {2007},
  institution = {{INRIA}},
  title       = {A locally nameless solution to the {POPL}mark challenge},
  number      = {RR-6098},
  pages       = {54},
  type        = {Research Report},
  url         = {https://hal.inria.fr/inria-00123945},
  abstract    = {The POPLmark challenge is a collective experiment intended to assess the usability of theorem provers and proof assistants in the context of fundamental research on programming languages. In this report, we present a solution to the challenge, developed with the Coq proof assistant, and using the "locally nameless" presentation of terms with binders introduced by McKinna, Pollack, Gordon, and McBride.},
  hal_id      = {inria-00123945},
  hal_version = {v2},
  keywords    = {POPLmark ; Coq ; locally nameless ; alpha-conversion ; binders ; type systems ; metatheory ; system F-sub},
  pdf         = {https://hal.inria.fr/inria-00123945/file/RR-6098.pdf},
}

@InProceedings{POPLMark,
  author    = {Aydemir, Brian E. and Bohannon, Aaron and Fairbairn, Matthew and Foster, J. Nathan and Pierce, Benjamin C. and Sewell, Peter and Vytiniotis, Dimitrios and Washburn, Geoffrey and Weirich, Stephanie and Zdancewic, Steve},
  booktitle = {Theorem Proving in Higher Order Logics},
  date      = {2005},
  title     = {Mechanized Metatheory for the Masses: The {POPL}Mark Challenge},
  doi       = {10.1007/11541868_4},
  editor    = {Hurd, Joe and Melham, Tom},
  isbn      = {978-3-540-31820-0},
  location  = {Berlin, Heidelberg},
  pages     = {50--65},
  publisher = {Springer Berlin Heidelberg},
  abstract  = {How close are we to a world where every paper on programming languages is accompanied by an electronic appendix with machine-checked proofs?},
}

@Article{weak2013Ciaffaglione,
  author       = {Alberto Ciaffaglione and Ivan Scagnetto},
  date         = {2013-03-29},
  journaltitle = {EPTCS 113, 2013, pp. 109-124},
  title        = {A weak {HOAS} approach to the {POPL}mark Challenge},
  doi          = {10.4204/EPTCS.113.11},
  eprint       = {1303.7332v1},
  eprintclass  = {cs.LO},
  eprinttype   = {arXiv},
  abstract     = {Capitalizing on previous encodings and formal developments about nominal calculi and type systems, we propose a weak Higher-Order Abstract Syntax formalization of the type language of pure System F<: within Coq, a proof assistant based on the Calculus of Inductive Constructions. Our encoding allows us to accomplish the proof of the transitivity property of algorithmic subtyping, which is in fact the first of the three tasks stated by the POPLmark Challenge, a set of problems that capture the most critical issues in formalizing programming language metatheory.},
  file         = {:http\://arxiv.org/pdf/1303.7332v1:PDF},
  keywords     = {cs.LO, cs.PL},
}

@Article{Nested2012Hirschowitz,
  author       = {André Hirschowitz and Marco Maggesi},
  date         = {2012-10-01},
  journaltitle = {Journal of Automated Reasoning},
  title        = {Nested Abstract Syntax in {C}oq},
  doi          = {10.1007/s10817-010-9207-9},
  issn         = {1573-0670},
  number       = {3},
  pages        = {409--426},
  url          = {https://math.unice.fr/~ah/div/fsubwf.pdf},
  volume       = {49},
  abstract     = {We illustrate Nested Abstract Syntax as a high-level alternative representation of languages with binding constructs, based on nested datatypes. Our running example is a partial solution in the Coq proof assistant to the POPLmark Challenge. The resulting formalization is very compact and does not require any extra library or special logical apparatus. Along the way, we propose an original, high-level perspective on environments.},
  day          = {01},
}

@Article{deBruijn1999Bird,
  author       = {Richard S. Bird and Ross Paterson},
  date         = {1999},
  journaltitle = {Journal of Functional Programming},
  title        = {de {B}ruijn notation as a nested datatype},
  doi          = {10.1017/S0956796899003366},
  number       = {1},
  pages        = {77--91},
  url          = {http://www.cs.ox.ac.uk/people/richard.bird/online/BirdPaterson99DeBruijn.pdf},
  volume       = {9},
  abstract     = {“I have no data yet. It is a capital mistake to theorise before one has data.” Sir Arthur Conan Doyle The Adventures of Sherlock Holmes

de Bruijn notation is a coding of lambda terms in which each occurrence of a bound variable x is replaced by a natural number, indicating the ‘distance’ from the occurrence to the abstraction that introduced x. One might suppose that in any datatype for representing de Bruijn terms, the distance restriction on numbers would have to be maintained as an explicit datatype invariant. However, by using a nested (or non-regular) datatype, we can define a representation in which all terms are well-formed, so that the invariant is enforced automatically by the type system.

Programming with nested types is only a little more difficult than programming with regular types, provided we stick to well-established structuring techniques. These involve expressing inductively defined functions in terms of an appropriate fold function for the type, and using fusion laws to establish their properties. In particular, the definition of lambda abstraction and beta reduction is particularly simple, and the proof of their associated properties is entirely mechanical.},
  publisher    = {Cambridge University Press},
}

@Article{POPLmark2005Stumpa,
  author   = {Aaron Stump},
  date     = {2005-12-30},
  title    = {{POPL}mark 1a with Named Bound Variables},
  url      = {https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.521.5740&rep=rep1&type=pdf},
  abstract = {A solution to the POPLmark challenge part 1a in Coq version 8.0 is described, where names are used for bound variables. The technical complexities associated with using names for bound variables are tamed using two main technical ideas: de Bruijn levels for free variables, and the Barendregt variable convention. The resulting solution stands at around 1250 lines of Coq (as written by a novice Coq user).},
}

@InProceedings{Engineering2008Aydemir,
  author    = {Aydemir, Brian and Chargu\'{e}raud, Arthur and Pierce, Benjamin C. and Pollack, Randy and Weirich, Stephanie},
  booktitle = {Proceedings of the 35th Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
  date      = {2008},
  title     = {Engineering Formal Metatheory},
  doi       = {10.1145/1328438.1328443},
  isbn      = {9781595936899},
  location  = {San Francisco, California, USA},
  pages     = {3--15},
  publisher = {Association for Computing Machinery},
  series    = {POPL ’08},
  url       = {https://www.cis.upenn.edu/~sweirich/papers/popl08-binders.pdf},
  address   = {New York, NY, USA},
  keywords  = {locally nameless, binding, coq},
  numpages  = {13},
}

@Article{sprop,
  author       = {Gilbert, Ga\"{e}tan and Cockx, Jesper and Sozeau, Matthieu and Tabareau, Nicolas},
  date         = {2019-01},
  journaltitle = {Proceedings of the ACM on Programming Languages},
  title        = {Definitional Proof-Irrelevance without {K}},
  doi          = {10.1145/3290316},
  number       = {POPL},
  volume       = {3},
  abstract     = {Definitional equality—or conversion—for a type theory with a decidable type checking is the simplest tool to prove that two objects are the same, letting the system decide just using computation. Therefore, the more things are equal by conversion, the simpler it is to use a language based on type theory. Proof-irrelevance, stating that any two proofs of the same proposition are equal, is a possible way to extend conversion to make a type theory more powerful. However, this new power comes at a price if we integrate it naively, either by making type checking undecidable or by realizing new axioms—such as uniqueness of identity proofs (UIP)—that are incompatible with other extensions, such as univalence. In this paper, taking inspiration from homotopy type theory, we propose a general way to extend a type theory with definitional proof irrelevance, in a way that keeps type checking decidable and is compatible with univalence. We provide a new criterion to decide whether a proposition can be eliminated over a type (correcting and improving the so-called singleton elimination of Coq) by using techniques coming from recent development on dependent pattern matching without UIP. We show the generality of our approach by providing implementations for both Coq and Agda, both of which are planned to be integrated in future versions of those proof assistants.},
  articleno    = {3},
  issue_date   = {January 2019},
  keywords     = {proof assistants, type theory, proof irrelevance},
  location     = {New York, NY, USA},
  numpages     = {28},
  publisher    = {Association for Computing Machinery},
}

@Article{Strongly2012Benton,
  author       = {Benton, Nick and Hur, Chung-Kil and Kennedy, Andrew J. and McBride, Conor},
  date         = {2012},
  journaltitle = {Journal of Automated Reasoning},
  title        = {Strongly Typed Term Representations in {C}oq},
  doi          = {10.1007/s10817-011-9219-0},
  issn         = {1573-0670},
  number       = {2},
  pages        = {141--159},
  url          = {https://sf.snu.ac.kr/publications/typedsyntaxfull.pdf},
  volume       = {49},
  abstract     = {There are two approaches to formalizing the syntax of typed object languages in a proof assistant or programming language. The extrinsic approach is to first define a type that encodes untyped object expressions and then make a separate definition of typing judgements over the untyped terms. The intrinsic approach is to make a single definition that captures well-typed object expressions, so ill-typed expressions cannot even be expressed. Intrinsic encodings are attractive and naturally enforce the requirement that metalanguage operations on object expressions, such as substitution, respect object types. The price is that the metalanguage types of intrinsic encodings and operations involve non-trivial dependency, adding significant complexity. This paper describes intrinsic-style formalizations of both simply-typed and polymorphic languages, and basic syntactic operations thereon, in the Coq proof assistant. The Coq types encoding object-level variables (de Bruijn indices) and terms are indexed by both type and typing environment. One key construction is the boot-strapping of definitions and lemmas about the action of substitutions in terms of similar ones for a simpler notion of renamings. In the simply-typed case, this yields definitions that are free of any use of type equality coercions. In the polymorphic case, some substitution operations do still require type coercions, which we at least partially tame by uniform use of heterogeneous equality.},
  refid        = {Benton2012},
}

@Article{Mtac2,
  author       = {Kaiser, Jan-Oliver and Ziliani, Beta and Krebbers, Robbert and R\'{e}gis-Gianas, Yann and Dreyer, Derek},
  date         = {2018-07},
  journaltitle = {Proc. ACM Program. Lang.},
  title        = {Mtac2: Typed Tactics for Backward Reasoning in {C}oq},
  doi          = {10.1145/3236773},
  number       = {ICFP},
  volume       = {2},
  articleno    = {78},
  issue_date   = {September 2018},
  keywords     = {Dependent Types, Metaprogramming, Coq, Theorem Proving, Tactic Languages},
  location     = {New York, NY, USA},
  numpages     = {31},
  publisher    = {Association for Computing Machinery},
}

@InProceedings{Outrageous2010McBride,
  author    = {McBride, Conor},
  booktitle = {Proceedings of the 6th ACM SIGPLAN Workshop on Generic Programming},
  date      = {2010},
  title     = {Outrageous but Meaningful Coincidences: Dependent Type-Safe Syntax and Evaluation},
  doi       = {10.1145/1863495.1863497},
  isbn      = {9781450302517},
  location  = {Baltimore, Maryland, USA},
  pages     = {1--12},
  publisher = {Association for Computing Machinery},
  series    = {WGP ’10},
  url       = {https://personal.cis.strath.ac.uk/conor.mcbride/pub/DepRep/DepRep.pdf},
  address   = {New York, NY, USA},
  keywords  = {dependent types, generic programming},
  numpages  = {12},
}

@Online{coq-pr-econstr,
  author = {Pierre-Marie Pédrot},
  date   = {2017-04-10},
  title  = {Introducing evar-insensitive constrs by ppedrot · Pull Request \#379 · coq/coq},
  url    = {https://github.com/coq/coq/pull/379},
}

@Online{coq-pr-floats,
  author = {Erik Martin-Dorel and Guillaume Bertholon and Pierre Roux},
  date   = {2019-03-29},
  title  = {Add primitive floats (binary64 floating-point numbers) by erikmd · Pull Request \#9867 · coq/coq},
  url    = {https://github.com/coq/coq/pull/9867},
}

@Online{coq-commit-delayed-externalization,
  author   = {Pierre-Marie Pédrot},
  date     = {2016-06-07},
  title    = {Fix bug \#4777: Printing time is impacted by large terms that don't print · coq/coq@87f9a31},
  url      = {https://github.com/coq/coq/commit/87f9a317b020554abef358aec614dad1fdc0bd98},
  abstract = {We delay the externalization of application arguments in Constrextern, so that they only get computed when they are actually explicitly displayed.},
}

@Online{Constrintern,
  title = {Constrintern (coq.Constrintern)},
  url   = {https://coq.github.io/doc/V8.12.0/api/coq/Constrintern/index.html},
}

@Online{Pretyping,
  title = {Pretyping (coq.Pretyping)},
  url   = {https://coq.github.io/doc/V8.12.0/api/coq/Pretyping/index.html},
}

@Online{Constrextern,
  title = {Constrextern (coq.Constrextern)},
  url   = {https://coq.github.io/doc/V8.12.0/api/coq/Constrextern/index.html},
}

@Online{Ppconstr,
  title = {Ppconstr (coq.Ppconstr)},
  url   = {https://coq.github.io/doc/V8.12.0/api/coq/Ppconstr/index.html},
}

@Online{Detyping,
  title = {Detyping (coq.Detyping)},
  url   = {https://coq.github.io/doc/V8.12.0/api/coq/Detyping/index.html},
}

@Online{coq-commit-native-compiler,
  author = {Maxime Dénès},
  date   = {2013-01-22},
  title  = {New implementation of the conversion test, using normalization by evaluation to native OCaml code · coq/coq@6b908b5},
  url    = {https://github.com/coq/coq/commit/6b908b5185a55a27a82c2b0fce4713812adde156},
}

@InProceedings{Extending2010Armand,
  author    = {Armand, Micha{\"e}l and Gr{\'e}goire, Benjamin and Spiwack, Arnaud and Th{\'e}ry, Laurent},
  booktitle = {Interactive Theorem Proving},
  date      = {2010},
  title     = {Extending {C}oq with Imperative Features and Its Application to {SAT} Verification},
  doi       = {10.1007/978-3-642-14052-5_8},
  editor    = {Kaufmann, Matt and Paulson, Lawrence C.},
  isbn      = {978-3-642-14052-5},
  location  = {Berlin, Heidelberg},
  pages     = {83--98},
  publisher = {Springer Berlin Heidelberg},
  url       = {https://hal.inria.fr/inria-00502496v2/document},
  abstract  = {Coq has within its logic a programming language that can be used to replace many deduction steps into a single computation, this is the so-called reflection. In this paper, we present two extensions of the evaluation mechanism that preserve its correctness and make it possible to deal with cpu-intensive tasks such as proof checking of SAT traces.},
}

@Online{coq-pr-int63,
  author    = {Maxime Dénès and Benjamin Grégoire},
  date      = {2018-03-05},
  title     = {Primitive integers by maximedenes · Pull Request \#6914 · coq/coq},
  url       = {https://github.com/coq/coq/pull/6914},
  mergedate = {2019-02-04},
}

@Online{coq-pr-parray,
  author    = {Maxime Dénès},
  date      = {2020-02-14},
  title     = {Primitive persistent arrays by maximedenes · Pull Request \#11604 · coq/coq},
  url       = {https://github.com/coq/coq/pull/11604},
  mergedate = {2020-07-06},
}

@Online{coq-commit-int31,
  author = {Arnaud Spiwack},
  date   = {2007-05-11},
  title  = {Processor integers + Print assumption (see coqdev mailing list for the details). · coq/coq@2dbe106},
  url    = {https://github.com/coq/coq/commit/2dbe106c09b60690b87e31e58d505b1f4e05b57f},
}

@InProceedings{Persistent2007Conchon,
  author    = {Conchon, Sylvain and Filli\^{a}tre, Jean-Christophe},
  booktitle = {Proceedings of the 2007 Workshop on Workshop on ML},
  date      = {2007},
  title     = {A Persistent Union-Find Data Structure},
  doi       = {10.1145/1292535.1292541},
  isbn      = {9781595936769},
  location  = {Freiburg, Germany},
  pages     = {37--46},
  publisher = {Association for Computing Machinery},
  series    = {ML ’07},
  url       = {https://www.lri.fr/~filliatr/puf/},
  address   = {New York, NY, USA},
  keywords  = {formal verification, union-find, persistence},
  numpages  = {10},
}

@Online{coq-pr-parray-prim-recursion,
  author = {Maxime Dénès},
  date   = {2020-06-05},
  title  = {Comment by maximedenes on Primitive integers by maximedenes · Pull Request \#6914 · coq/coq},
  url    = {https://github.com/coq/coq/pull/11604\#issuecomment-639566223},
}

@InProceedings{logical2001implicit,
  author       = {Alexandre Miquel},
  booktitle    = {Proceedings of the 5th International Conference on Typed Lambda Calculi and Applications},
  date         = {2001},
  title        = {The Implicit Calculus of Constructions},
  isbn         = {3540419608},
  location     = {Krak\'{o}w, Poland},
  organization = {Springer},
  pages        = {344--359},
  publisher    = {Springer-Verlag},
  series       = {TLCA’01},
  subtitle     = {Extending Pure Type Systems with an Intersection Type Binder and Subtyping},
  url          = {http://www.pps.univ-paris-diderot.fr/~miquel/publis/tlca01.pdf},
  volume       = {2044},
  address      = {Berlin, Heidelberg},
  local-url    = {http://people.csail.mit.edu/jgross/personal-website/papers/academic-papers-local/tlca01.pdf},
  numpages     = {16},
  owner        = {Jason},
  timestamp    = {2014.01.08},
}

@Online{coq-pr-fast-application-typing,
  author = {Pierre-Marie Pédrot},
  date   = {2018-08-15},
  title  = {Fast typing of application nodes by ppedrot · Pull Request \#8255 · coq/coq},
  url    = {https://github.com/coq/coq/pull/8255},
}

@Online{coq-commit-polyproj,
  author = {Matthieu Sozeau},
  date   = {2014-05-06},
  title  = {This commit adds full universe polymorphism and fast projections to Coq. · coq/coq@a404360},
  url    = {https://github.com/coq/coq/commit/a4043608f704f026de7eb5167a109ca48e00c221},
}

@InCollection{sep-russell-paradox,
  author    = {Irvine, Andrew David and Deutsch, Harry},
  booktitle = {The {S}tanford Encyclopedia of Philosophy},
  date      = {2016},
  title     = {{R}ussell's Paradox},
  edition   = {Winter 2016},
  editor    = {Edward N. Zalta},
  publisher = {Metaphysics Research Lab, Stanford University},
  url       = {https://plato.stanford.edu/archives/win2016/entries/russell-paradox/},
}

@Book{nuprl,
  author       = {R. L. Constable and S. F. Allen and H. M. Bromley and W. R. Cleaveland and J. F. Cremer and R. W. Harper and D. J. Howe and T. B. Knoblock and N. P. Mendler and P. Panangaden and J. T. Sasaki and S. F. Smith},
  date         = {1986-12},
  title        = {Implementing Mathematics with the {N}uprl Proof Development System},
  isbn         = {9780134518329},
  publisher    = {Prentice Hall},
  url          = {http://www.nuprl.org/book/},
  journaltitle = {Computer Science Department, Cornell University},
}

@InCollection{Typical1966Specker,
  author    = {Ernst Specker},
  booktitle = {Logic, Methodology and Philosophy of Science},
  date      = {1966},
  title     = {Typical Ambiguity},
  doi       = {10.1007/978-3-0348-9259-9_17},
  editor    = {Ernest Nagel and Patrick Suppes and Alfred Tarski},
  pages     = {116--124},
  publisher = {Elsevier},
  series    = {Studies in Logic and the Foundations of Mathematics},
  url       = {http://www.sciencedirect.com/science/article/pii/S0049237X09705762},
  volume    = {44},
  abstract  = {Publisher Summary
This chapter describes the simple theory of types and some of its extensions. The simple theory of types is certainly one of the most natural systems of set theory; the reason for this is that it is defined rather by a family of structures than by a system of axioms. The axioms of extensionality and of comprehension are in a certain sense the same for all types. The chapter consistently adds to the ideal type theory. “Ideal type theory” could now be defined as the set of sentences (formulas without free variables) holding in every structure (T0, T1,…; =, Є), where Tk+l is the power set of Tk and where “=,” “ Є,” and the variables are interpreted in the obvious way. One group of axioms of type theory is the axioms of extensionality. There is one such axiom for every type (except type 0), and it says that two sets are equal if they have the same elements.},
  issn      = {0049-237X},
}

@Online{Universe2012Shulman,
  author   = {Mike Shulman},
  date     = {2012-12-09},
  title    = {Universe Polymorphism and Typical Ambiguity},
  url      = {https://golem.ph.utexas.edu/category/2012/12/universe_polymorphism_and_typi.html},
  location = {The n-Category Café},
}

@Online{coq-pr-sprop,
  author = {Gaëtan Gilbert},
  date   = {2018-10-25},
  title  = {{SP}rop: the definitionally proof irrelevant universe by {S}ky{S}kimmer · Pull Request \#8817 · coq/coq},
  url    = {https://github.com/coq/coq/pull/8817},
}

@Article{Equivalences2018Tabareau,
  author       = {Tabareau, Nicolas and Tanter, \'{E}ric and Sozeau, Matthieu},
  date         = {2018-07},
  journaltitle = {Proc. ACM Program. Lang.},
  title        = {Equivalences for Free: Univalent Parametricity for Effective Transport},
  doi          = {10.1145/3236787},
  volume       = {2},
  articleno    = {92},
  conference   = {{ICFP}},
  issue_date   = {September 2018},
  keywords     = {Coq, Type Equivalence, Parametricity, Homotopy Type Theory},
  location     = {New York, NY, USA},
  numpages     = {29},
  publisher    = {Association for Computing Machinery},
}

@Article{Tabareau2019TheMO,
  author       = {Nicolas Tabareau and {\'E}ric Tanter and Matthieu Sozeau},
  date         = {2019},
  journaltitle = {ArXiv},
  title        = {The Marriage of Univalence and Parametricity},
  eprint       = {1909.05027},
  eprintclass  = {cs.PL},
  eprinttype   = {arxiv},
}

@InProceedings{reynolds1983types,
  author    = {Reynolds, John C.},
  booktitle = {Information Processing 83, Proceedings of the IFIP 9th World Computer Congres},
  date      = {1983},
  title     = {Types, Abstraction and Parametric Polymorphism},
  pages     = {513--523},
}

@InProceedings{wadler1989theorems,
  author    = {Wadler, Philip},
  booktitle = {Proceedings of the fourth international conference on Functional programming languages and computer architecture},
  date      = {1989-06},
  title     = {Theorems for free!},
  pages     = {347--359},
}

@Article{Cubical2016Cohen,
  author      = {Cyril Cohen and Thierry Coquand and Simon Huber and Anders Mörtberg},
  date        = {2016-11-07},
  title       = {Cubical Type Theory: a constructive interpretation of the univalence axiom},
  eprint      = {1611.02108v1},
  eprintclass = {cs.LO},
  eprinttype  = {arXiv},
  abstract    = {This paper presents a type theory in which it is possible to directly manipulate $n$-dimensional cubes (points, lines, squares, cubes, etc.) based on an interpretation of dependent type theory in a cubical set model. This enables new ways to reason about identity types, for instance, function extensionality is directly provable in the system. Further, Voevodsky's univalence axiom is provable in this system. We also explain an extension with some higher inductive types like the circle and propositional truncation. Finally we provide semantics for this cubical type theory in a constructive meta-theory.},
  file        = {:http\://arxiv.org/pdf/1611.02108v1:PDF},
  keywords    = {cs.LO, math.LO, F.3.2; F.4.1},
}

@Online{Running2011Licata,
  author = {Dan Licata},
  date   = {2011-04-23},
  title  = {Running Circles Around (In) Your Proof Assistant; or, Quotients that Compute},
  url    = {https://homotopytypetheory.org/2011/04/23/running-circles-around-in-your-proof-assistant/},
}

@Article{Cubical2019Vezzosi,
  author       = {Vezzosi, Andrea and M\"{o}rtberg, Anders and Abel, Andreas},
  date         = {2019-07},
  journaltitle = {Proc. ACM Program. Lang.},
  title        = {Cubical {A}gda: A Dependently Typed Programming Language with Univalence and Higher Inductive Types},
  doi          = {10.1145/3341691},
  volume       = {3},
  articleno    = {87},
  conference   = {ICFP},
  issue_date   = {August 2019},
  keywords     = {Higher Inductive Types, Dependent Pattern Matching, Cubical Type Theory, Univalence},
  location     = {New York, NY, USA},
  numpages     = {29},
  publisher    = {Association for Computing Machinery},
}

@Online{DAO2018Guecluetuerk,
  author       = {Osman Gazi Güçlütürk},
  date         = {2018-08-01},
  title        = {The {DAO} Hack Explained: Unfortunate Take-off of Smart Contracts},
  url          = {https://medium.com/@ogucluturk/the-dao-hack-explained-unfortunate-take-off-of-smart-contracts-2bd8c8db3562},
  organization = {Medium},
}

@Online{Therac,
  title        = {Therac-25},
  url          = {https://en.wikipedia.org/wiki/Therac-25},
  journaltitle = {Wikipedia, the free encyclopedia},
}

@Online{curve25519-donna-commit-correct-bounds,
  author   = {Adam Langley},
  date     = {2014-06-15},
  title    = {Correct bounds in 32-bit code. · agl/curve25519-donna@2647eeb},
  url      = {https://github.com/agl/curve25519-donna/commit/2647eeba59fb628914c79ce691df794a8edc799f},
  abstract = {The 32-bit code was illustrative of the tricks used in the original
curve25519 paper rather than rigorous. However, it has proven quite
popular.

This change fixes an issue that Robert Ransom found where outputs between
$2^{255}-19$ and $2^{255}-1$ weren't correctly reduced in fcontract. This
appears to leak a small fraction of a bit of security of private keys.

Additionally, the code has been cleaned up to reflect the real-world
needs. The ref10 code also exists for 32-bit, generic C but is somewhat
slower and objections around the lack of qhasm availibility have been
raised.},
}

@Report{naur1969software,
  date      = {1970-04},
  title     = {Software Engineering Techniques},
  location  = {Rome, Italy},
  subtitle  = {Report of a conference sponsored by the {NATO} Science Committee, Garmisch, Germany, 7th--11th October 1968},
  url       = {http://homepages.cs.ncl.ac.uk/brian.randell/NATO/nato1969.PDF},
  editor    = {J. N. Buxton and B. Randell},
  publisher = {{NATO} Science Committee},
}

@Article{Reflections1984Thompson,
  author       = {Thompson, Ken},
  date         = {1984-08},
  journaltitle = {Communications of the ACM},
  title        = {Reflections on Trusting Trust},
  doi          = {10.1145/358198.358210},
  issn         = {0001-0782},
  number       = {8},
  pages        = {761--763},
  volume       = {27},
  abstract     = {To what extent should one trust a statement that a program is free of Trojan horses? Perhaps it is more important to trust the people who wrote the software.},
  issue_date   = {Aug 1984},
  location     = {New York, NY, USA},
  numpages     = {3},
  publisher    = {Association for Computing Machinery},
}

@InCollection{sep-goedel-incompleteness,
  author    = {Raatikainen, Panu},
  booktitle = {The {S}tanford Encyclopedia of Philosophy},
  date      = {2020},
  title     = {Gödel's Incompleteness Theorems},
  edition   = {Fall 2020},
  editor    = {Edward N. Zalta},
  publisher = {Metaphysics Research Lab, Stanford University},
  url       = {https://plato.stanford.edu/archives/fall2020/entries/goedel-incompleteness/},
}

@InProceedings{Network2015Chlipala,
  author    = {Chlipala, Adam},
  booktitle = {Proceedings of the 42nd Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
  date      = {2015},
  title     = {From Network Interface to Multithreaded Web Applications: A Case Study in Modular Program Verification},
  doi       = {10.1145/2676726.2677003},
  isbn      = {9781450333009},
  location  = {Mumbai, India},
  pages     = {609--622},
  publisher = {Association for Computing Machinery},
  series    = {POPL '15},
  url       = {http://adam.chlipala.net/papers/BedrockPOPL15/},
  abstract  = {Many verifications of realistic software systems are monolithic, in the sense that they define single global invariants over complete system state. More modular proof techniques promise to support reuse of component proofs and even reduce the effort required to verify one concrete system, just as modularity simplifies standard software development. This paper reports on one case study applying modular proof techniques in the Coq proof assistant. To our knowledge, it is the first modular verification certifying a system that combines infrastructure with an application of interest to end users. We assume a nonblocking API for managing TCP networking streams, and on top of that we work our way up to certifying multithreaded, database-backed Web applications. Key verified components include a cooperative threading library and an implementation of a domain-specific language for XML processing. We have deployed our case-study system on mobile robots, where it interfaces with off-the-shelf components for sensing, actuation, and control.},
  address   = {New York, NY, USA},
  keywords  = {thread libraries, proof assistants, modular program verification, internet servers, domain-specific languages},
  numpages  = {14},
}

@Article{gonthier2008formal,
  author       = {Gonthier, Georges},
  date         = {2008},
  journaltitle = {Notices of the AMS},
  title        = {Formal Proof--The Four-Color Theorem},
  number       = {11},
  pages        = {1382--1393},
  url          = {https://www.ams.org/notices/200811/tx081101382p.pdf},
  volume       = {55},
}

@InProceedings{gonthier2013machine,
  author       = {Gonthier, Georges and Asperti, Andrea and Avigad, Jeremy and Bertot, Yves and Cohen, Cyril and Garillot, Fran{\c{c}}ois and Le Roux, St{\'e}phane and Mahboubi, Assia and O’Connor, Russell and Biha, Sidi Ould and others},
  booktitle    = {International Conference on Interactive Theorem Proving},
  date         = {2013},
  title        = {A Machine-Checked Proof of the Odd Order Theorem},
  doi          = {10.1007/978-3-642-39634-2_14},
  eprint       = {hal-00816699},
  organization = {Springer},
  pages        = {163--179},
  url          = {https://hal.inria.fr/file/index/docid/816699/filename/main.pdf},
}

@InProceedings{Proving2005Benjamin,
  author       = {Benjamin Grégoire and Assia Mahboubi},
  booktitle    = {Theorem Proving in Higher Order Logics},
  date         = {2005},
  title        = {Proving Equalities in a Commutative Ring Done Right in {C}oq},
  doi          = {10.1007/11541868_7},
  editor       = {Hurd, Joe and Melham, Tom},
  isbn         = {978-3-540-31820-0},
  location     = {Berlin, Heidelberg},
  pages        = {98--113},
  publisher    = {Springer Berlin Heidelberg},
  abstract     = {We present a new implementation of a reflexive tactic which solves equalities in a ring structure inside the Coq system. The efficiency is improved to a point that we can now prove equalities that were previously beyond reach. A special care has been taken to implement efficient algorithms while keeping the complexity of the correctness proofs low. This leads to a single tool, with a single implementation, which can be addressed for a ring or for a semi-ring, abstract or not, using the Leibniz equality or a setoid equality. This example shows that such reflective methods can be effectively used in symbolic computation.},
  journaltitle = {Theorem Proving in Higher Order Logics},
}

@InProceedings{Recognizing1989Benanav,
  author    = {Benanav, Dan},
  booktitle = {Proceedings of the 11th International Joint Conference on Artificial Intelligence - Volume 1},
  date      = {1989},
  title     = {Recognizing Unnecessary Inference},
  location  = {Detroit, Michigan},
  pages     = {366--371},
  publisher = {Morgan Kaufmann Publishers Inc.},
  series    = {IJCAI'89},
  abstract  = {Intelligent reasoners sometimes draw conclusions that lack new or relevant information. Similarly, automated reasoning systems can produce formulas that are not necessary for the problem at hand. We concentrate on the problem of unnecessary inference in the context of resolution based systems. In such systems several strategies have been developed that allow for the deletion of clauses without sacrificing completeness. Unfortunately these strategies fail to recognize other frequently generated unnecessary formulas. We will present a generalized subsumption theorem that can be used to recognize such formulas and to develop new deletion methods which retain completeness.},
  address   = {San Francisco, CA, USA},
  numpages  = {6},
}

@InProceedings{mechanical1990Pierce,
  author    = {Pierce, William},
  booktitle = {10th International Conference on Automated Deduction},
  date      = {1990},
  title     = {Toward Mechanical Methods for Streamlining Proofs},
  editor    = {Stickel, Mark E.},
  isbn      = {978-3-540-47171-4},
  location  = {Berlin, Heidelberg},
  pages     = {351--365},
  publisher = {Springer Berlin Heidelberg},
  abstract  = {We present preliminary work on the problem of mechanical proof simplification. Our approach is to take advantage of the correspondence between proofs and programs. Techniques from the field of program transformation may be used to transform the computational content of a proof. Using examples from elementary number theory, we illustrate how such transformations can lead to simpler proofs.},
}

@InProceedings{Lean2015Moura,
  author       = {de Moura, Leonardo and Kong, Soonho and Avigad, Jeremy and Van Doorn, Floris and von Raumer, Jakob},
  booktitle    = {International Conference on Automated Deduction},
  date         = {2015},
  title        = {The {L}ean Theorem Prover (System Description)},
  doi          = {10.1007/978-3-319-21401-6_26},
  editor       = {Amy P. Felty and Aart Middeldorp},
  organization = {Springer},
  pages        = {378--388},
  publisher    = {Springer},
  url          = {https://leanprover.github.io/papers/system.pdf},
  volumes      = {9195},
}

@InProceedings{Matita2011Asperti,
  author    = {Asperti, Andrea and Ricciotti, Wilmer and Sacerdoti Coen, Claudio and Tassi, Enrico},
  booktitle = {Automated Deduction -- CADE-23},
  date      = {2011},
  title     = {The {M}atita Interactive Theorem Prover},
  doi       = {10.1007/978-3-642-22438-6_7},
  editor    = {Bj{\o}rner, Nikolaj and Sofronie-Stokkermans, Viorica},
  isbn      = {978-3-642-22438-6},
  location  = {Berlin, Heidelberg},
  pages     = {64--69},
  publisher = {Springer Berlin Heidelberg},
  abstract  = {Matita is an interactive theorem prover being developed by the Helm team at the University of Bologna. Its stable version 0.5.x may be downloaded at http://matita.cs.unibo.it. The tool originated in the European project MoWGLI as a set of XML-based tools aimed to provide a mathematician-friendly web-interface to repositories of formal mathematical knoweldge, supporting advanced content-based functionalities for querying, searching and browsing the library. It has since then evolved into a fully fledged ITP, specifically designed as a light-weight, but competitive system, particularly suited for the assessment of innovative ideas, both at foundational and logical level. In this paper, we give an account of the whole system, its peculiarities and its main applications.},
}

@Article{calculus1988Coquand,
  author = {Thierry Coquand and Gérard Huet},
  date   = {1988},
  title  = {The Calculus of Constructions},
  doi    = {10.1016/0890-5401(88)90005-3},
  issn   = {0890-5401},
  pages  = {95--120},
  url    = {https://hal.inria.fr/inria-00076024/document},
  volume = {76},
}

@InProceedings{Inductively1988Coquand,
  author       = {Coquand, Thierry and Paulin, Christine},
  booktitle    = {International Conference on Computer Logic},
  date         = {1988},
  title        = {Inductively Defined Types},
  doi          = {10.1007/3-540-52335-9_47},
  organization = {Springer},
  pages        = {50--66},
}

@InBook{Dependently2009Norell,
  author    = {Norell, Ulf},
  booktitle = {Advanced Functional Programming: 6th International School, AFP 2008, Heijen, The Netherlands, May 2008, Revised Lectures},
  date      = {2009},
  title     = {Dependently Typed Programming in {A}gda},
  doi       = {10.1007/978-3-642-04652-0_5},
  editor    = {Koopman, Pieter and Plasmeijer, Rinus and Swierstra, Doaitse},
  isbn      = {978-3-642-04652-0},
  location  = {Berlin, Heidelberg},
  pages     = {230--266},
  publisher = {Springer Berlin Heidelberg},
  abstract  = {In Hindley-Milner style languages, such as Haskell and ML, there is a clear separation between types and values. In a dependently typed language the line is more blurry - types can contain (depend on) arbitrary values and appear as arguments and results of ordinary functions.},
}

@InProceedings{PVS1992Owre,
  author    = {Owre, Sam and Rushby, John M. and Shankar, Natarajan},
  booktitle = {Proceedings of the 11th International Conference on Automated Deduction: Automated Deduction},
  date      = {1992},
  title     = {{PVS}: A Prototype Verification System},
  doi       = {10.1007/3-540-55602-8_217},
  isbn      = {3540556028},
  location  = {Berlin, Heidelberg},
  pages     = {748--752},
  publisher = {Springer-Verlag},
  series    = {CADE-11},
  numpages  = {5},
}

@InProceedings{Rudnicki92anoverview,
  author    = {Piotr Rudnicki},
  booktitle = {University of Technology, Bastad},
  date      = {1992-06-30},
  title     = {An Overview of the {MIZAR} Project},
  pages     = {311--332},
  url       = {http://mizar.org/project/MizarOverview.pdf},
}

@Book{HoTTBook,
  author        = {The {Univalent Foundations Program}},
  date          = {2013-08-03},
  title         = {Homotopy Type Theory: {U}nivalent Foundations of Mathematics},
  eprint        = {1308.0729v1},
  eprintclass   = {math.LO},
  eprinttype    = {arXiv},
  url           = {http://homotopytypetheory.org/book/},
  abstract      = {Homotopy type theory is a new branch of mathematics, based on a recently discovered connection between homotopy theory and type theory, which brings new ideas into the very foundation of mathematics. On the one hand, Voevodsky's subtle and beautiful "univalence axiom" implies that isomorphic structures can be identified. On the other hand, "higher inductive types" provide direct, logical descriptions of some of the basic spaces and constructions of homotopy theory. Both are impossible to capture directly in classical set-theoretic foundations, but when combined in homotopy type theory, they permit an entirely new kind of "logic of homotopy types". This suggests a new conception of foundations of mathematics, with intrinsic homotopical content, an "invariant" conception of the objects of mathematics -- and convenient machine implementations, which can serve as a practical aid to the working mathematician. This book is intended as a first systematic exposition of the basics of the resulting "Univalent Foundations" program, and a collection of examples of this new style of reasoning -- but without requiring the reader to know or learn any formal logic, or to use any computer proof assistant.},
  file          = {:http\://arxiv.org/pdf/1308.0729v1:PDF},
  institute     = {Institute for Advanced Study},
  keywords      = {math.LO, cs.PL, math.AT, math.CT},
  publisher-old = {{L}ulu {M}arketplace},
}

@PhdThesis{Isabelle/Isar2002Wenzel,
  author      = {Wenzel, Markus M.},
  date        = {2002},
  institution = {Technische Universität München},
  title       = {{I}sabelle/{I}sar --- a versatile environment for human-readable formal proof documents},
  location    = {München},
  type        = {Dissertation},
  url         = {https://mediatum.ub.tum.de/601724},
}

@Article{KnuthPrematureOptimization,
  author       = {Knuth, Donald E.},
  date         = {1974-12},
  journaltitle = {Communications of the ACM},
  title        = {Computer Programming as an Art},
  doi          = {10.1145/361604.361612},
  issn         = {0001-0782},
  number       = {12},
  pages        = {667--673},
  url          = {http://www.paulgraham.com/knuth.html},
  volume       = {17},
  abstract     = {When Communications of the ACM began publication in 1959, the members of ACM's Editorial Board made the following remark as they described the purposes of ACM's periodicals [2]: “If computer programming is to become an important part of computer research and development, a transition of programming from an art to a disciplined science must be effected.” Such a goal has been a continually recurring theme during the ensuing years; for example, we read in 1970 of the “first steps toward transforming the art of programming into a science” [26]. Meanwhile we have actually succeeded in making our discipline a science, and in a remarkably simple way: merely by deciding to call it “computer science.”},
  issue_date   = {Dec 1974},
  location     = {New York, NY, USA},
  numpages     = {7},
  publisher    = {Association for Computing Machinery},
}

@InCollection{davis2001early,
  author    = {Davis, Martin},
  booktitle = {Handbook of Automated Reasoning},
  date      = {2001},
  title     = {The Early History of Automated Deduction},
  pages     = {3--15},
  publisher = {Elsevier},
  subtitle  = {Dedicated to the memory of {H}ao {W}ang},
  url       = {http://cs.nyu.edu/cs/faculty/davism/early.ps},
}

@Online{Brief2019Darbari,
  author       = {Ashish Darbari},
  date         = {2019-03-08},
  title        = {A Brief History of Formal Verification},
  url          = {https://www.eeweb.com/profile/adarbari/articles/a-brief-history-of-formal-verification},
  organization = {EEWeb},
  abstract     = {As conventional simulation-based testing has increasingly struggled to cope with design complexity, strategies centered around formal verification have quietly evolved},
}

@TechReport{luckham1979stanford,
  author      = {Luckham, David C. and German, Steven M. and Henke, F. W. V. and Karp, Richard A. and Milne, P. W.},
  date        = {1979},
  institution = {Stanford University of California Department of Computer Science},
  title       = {{S}tanford {P}ascal Verifier User Manual},
  url         = {http://i.stanford.edu/pub/cstr/reports/cs/tr/79/731/CS-TR-79-731.pdf},
}

@InProceedings{CakeML,
  author    = {Kumar, Ramana and Myreen, Magnus O. and Norrish, Michael and Owens, Scott},
  booktitle = {Proceedings of the 41st ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
  date      = {2014},
  title     = {{CakeML}: A Verified Implementation of {ML}},
  doi       = {10.1145/2535838.2535841},
  isbn      = {9781450325448},
  location  = {San Diego, California, USA},
  pages     = {179--191},
  publisher = {Association for Computing Machinery},
  series    = {POPL ’14},
  address   = {New York, NY, USA},
  keywords  = {verified garbage collection., read-eval-print loop, compiler bootstrapping, verified parsing, compiler verification, verified type checking, machine code verification, ML},
  numpages  = {13},
}

@Online{Nqthm,
  title = {{N}qthm, the {B}oyer-{M}oore prover},
  url   = {https://www.cs.utexas.edu/users/boyer/ftp/nqthm/},
}

@Online{wiki:Nqthm,
  author       = {{Wikipedia contributors}},
  date         = {2020-08-25},
  title        = {Nqthm --- {W}ikipedia{,} The Free Encyclopedia},
  url          = {https://en.wikipedia.org/w/index.php?title=Nqthm&oldid=956139282},
  note         = {[Online; accessed 2020-08-25]},
  organization = {Wikipedia, the free encyclopedia},
}

@Online{ACL2Applications,
  title = {{ACL}2 User's Manual — Interesting-applications},
  url   = {https://www.cs.utexas.edu/users/moore/acl2/v8-3/combined-manual/index.html?topic=ACL2____INTERESTING-APPLICATIONS},
}

@Online{ACL2,
  author = {Matt Kaufmann and J. Strother Moore},
  date   = {2020-04-14},
  title  = {{ACL}2 Version 8.3},
  url    = {https://www.cs.utexas.edu/users/moore/acl2/},
}

@InProceedings{flyspeck,
  author     = {Thomas C. Hales},
  booktitle  = {Mathematics, Algorithms, Proofs},
  date       = {2006},
  title      = {Introduction to the {F}lyspeck Project},
  editor     = {Thierry Coquand and Henri Lombardi and Marie-Fran{\c{c}}oise Roy},
  location   = {Dagstuhl, Germany},
  number     = {05021},
  publisher  = {Internationales Begegnungs- und Forschungszentrum f{\"u}r Informatik (IBFI), Schloss Dagstuhl, Germany},
  series     = {Dagstuhl Seminar Proceedings},
  url        = {http://drops.dagstuhl.de/opus/volltexte/2006/432},
  abstract   = {This article gives an introduction to a long-term project called Flyspeck, whose purpose is to give a formal verification of the Kepler Conjecture. The Kepler Conjecture asserts that the density of a packing of equal radius balls in three dimensions cannot exceed $pi/sqrt{18}$. The original proof of the Kepler Conjecture, from 1998, relies extensively on computer calculations. Because the proof relies on relatively few external results, it is a natural choice for a formalization effort.},
  annotation = {Keywords: Certified proofs, Kepler conjecture},
  issn       = {1862-4405},
}

@Online{flyspeck2014Hales,
  author = {Thomas Hales and Alexey Solovyevand Hoang Le Truong and {the Flyspeck Team}},
  date   = {2014-08-10},
  title  = {flyspeck - AnnouncingCompletion.wiki},
  url    = {https://code.google.com/archive/p/flyspeck/wikis/AnnouncingCompletion.wiki},
}

@Book{Isabelle,
  author    = {Tobias Nipkow and Lawrence C. Paulson and Markus Wenzel},
  date      = {2002},
  title     = {Isabelle/HOL --- A Proof Assistant for Higher-Order Logic},
  publisher = {Springer-Verlag},
  series    = {LNCS},
  volume    = {2283},
}

@Book{paulson1994isabelle,
  author    = {Paulson, L. C.},
  date      = {1994},
  title     = {Isabelle: A Generic Theorem Prover},
  publisher = {Springer},
  volume    = {828},
}

@Article{gordon1979edinburgh,
  author       = {Gordon, M. J. and Milner, R. and Wadsworth, C. P.},
  date         = {1979},
  journaltitle = {Springer-Verlag Berlin},
  title        = {Edinburgh {LCF}: A Mechanized Logic of Computation},
  pages        = {11--25},
  volume       = {10},
}

@InProceedings{gordon1978metalanguage,
  author       = {Gordon, M. and Milner, R. and Morris, L. and Newey, M. and Wadsworth, C.},
  booktitle    = {Proceedings of the 5th ACM SIGACT-SIGPLAN symposium on Principles of programming languages},
  date         = {1978},
  title        = {A Metalanguage for Interactive Proof in {LCF}},
  organization = {ACM},
  pages        = {119--130},
}

@Article{pfenning1991logic,
  author       = {Pfenning, F.},
  date         = {1991},
  journaltitle = {Logical Frameworks},
  title        = {Logic Programming in the {LF} Logical Framework},
}

@InProceedings{slind2008brief,
  author    = {Konrad Slind and Michael Norrish},
  booktitle = {Theorem Proving in Higher Order Logics},
  date      = {2008},
  title     = {A Brief Overview of {HOL4}},
  editor    = {Mohamed, Otmane Ait and Muñoz, C{\'e}sar and Tahar, Sofi{\`e}ne},
  isbn      = {978-3-540-71067-7},
  location  = {Berlin, Heidelberg},
  pages     = {28--32},
  publisher = {Springer Berlin Heidelberg},
  abstract  = {The HOL4 proof assistant supports specification and proof in classical higher order logic. It is the latest in a long line of similar systems. In this short overview, we give an outline of the HOL4 system and how it may be applied in formal verification.},
}

@InProceedings{harrison-mizar,
  author    = {John Harrison},
  booktitle = {Theorem Proving in Higher Order Logics: 9th International Conference, TPHOLs'96},
  date      = {1996-08},
  title     = {A Mizar Mode for {HOL}},
  editor    = {Joakim von Wright and Jim Grundy and John Harrison},
  location  = {Turku, Finland},
  pages     = {203--220},
  publisher = {Springer-Verlag},
  series    = {Lecture Notes in Computer Science},
  url       = {https://www.cl.cam.ac.uk/~jrh13/papers/mizar.html},
  volume    = {1125},
}

@InProceedings{owre1996pvs,
  author    = {Shankar, N.},
  booktitle = {Formal Methods in Computer-Aided Design},
  date      = {1996},
  title     = {{PVS}: Combining Specification, Proof Checking, and Model Checking},
  editor    = {Srivas, Mandayam and Camilleri, Albert},
  isbn      = {978-3-540-49567-3},
  location  = {Berlin, Heidelberg},
  pages     = {257--264},
  publisher = {Springer Berlin Heidelberg},
  abstract  = {We claim that no single technique such as rewriting, BDDs, or model checking is effective for all aspects of hardware verification. Many examples need the careful integration of these techniques. We have shown some simple examples to illustrate the integration available in PVS. This combination of techniques has been applied to some larger examples such as an SRT divider and Rockwell-Collins AAMP series of processors. The automation available in PVS on these examples can be further improved through the use of more decision procedures (e.g., bit vectors) and better verification methodologies (e.g., abstraction, induction).},
}

@Article{harrison1996hol,
  author       = {John Harrison},
  date         = {1996},
  journaltitle = {Lecture Notes in Computer Science},
  title        = {{HOL} {L}ight: A Tutorial Introduction},
  pages        = {265--269},
  publisher    = {Springer},
}

@Article{harper93,
  author       = {Robert Harper and Furio Honsell and Gordon Plotkin},
  date         = {1993},
  journaltitle = {JACM},
  title        = {A Framework for Defining Logics},
}

@Article{pfenning1999system,
  author       = {Frank Pfenning and Carsten Schürmann},
  date         = {1999},
  journaltitle = {LNCS},
  title        = {System Description: {Twelf} -- A Meta-Logical Framework for Deductive Systems},
}

@Article{asperti2007user,
  author       = {Asperti, A. and Sacerdoti Coen, C. and Tassi, E. and Zacchiroli, S.},
  date         = {2007},
  journaltitle = {Journal of Automated Reasoning},
  title        = {User Interaction with the {M}atita Proof Assistant},
  number       = {2},
  pages        = {109--139},
  volume       = {39},
  publisher    = {Springer},
}

@Article{zhivich2009real,
  author       = {Zhivich, M. and Cunningham, R. K.},
  date         = {2009},
  journaltitle = {IEEE Security \& Privacy Magazine},
  title        = {The Real Cost of Software Errors},
  doi          = {10.1109/msp.2009.56},
  editor       = {Sean W. Smith},
  number       = {2},
  pages        = {87--90},
  url          = {http://hdl.handle.net/1721.1/74607},
  volume       = {7},
  publisher    = {IEEE},
}

@InBook{barendregt2001proof,
  author    = {Henk P. Barendregt and Herman Geuvers},
  booktitle = {Handbook of Automated Reasoning},
  date      = {2001},
  title     = {Proof-Assistants using Dependent Type Systems},
  doi       = {10.1016/b978-044450813-3/50020-5},
  editor    = {Alan Robinson and Andrei Voronkov},
  isbn      = {0444508120},
  location  = {NLD},
  pages     = {1149--1238},
  publisher = {Elsevier Science Publishers B. V.},
  numpages  = {90},
}

@PhdThesis{stampoulis2013veriml,
  author      = {Antonios Michael Stampoulis},
  date        = {2013},
  institution = {Yale University},
  title       = {Veri{ML}: A dependently-typed, user-extensible and language-centric approach to proof assistants},
  url         = {https://astampoulis.github.io/veriml/dissertation.pdf},
}

@Article{Idris2013Brady,
  author       = {Edwin Brady},
  date         = {2013},
  journaltitle = {Journal of Functional Programming},
  title        = {Idris, a General Purpose Dependently Typed Programming Language: Design and Implementation},
  doi          = {10.1017/S095679681300018X},
  number       = {5},
  pages        = {552--593},
  url          = {https://eb.host.cs.st-andrews.ac.uk/drafts/impldtp.pdf},
  volume       = {23},
  abstract     = {Many components of a dependently typed programming language are by now well understood, for example, the underlying type theory, type checking, unification and evaluation. How to combine these components into a realistic and usable high-level language is, however, folklore, discovered anew by successive language implementors. In this paper, I describe the implementation of \textsc{Idris}, a new dependently typed functional programming language. Idris is intended to be a \emph{general-purpose} programming language and as such provides high-level concepts such as implicit syntax, type classes and do notation. I describe the high-level language and the underlying type theory, and present a tactic-based method for \emph{elaborating} concrete high-level syntax with implicit arguments and type classes into a fully explicit type theory. Furthermore, I show how this method facilitates the implementation of new high-level language constructs.},
  publisher    = {Cambridge University Press},
}

@Article{challenge2005Barendregt,
  author       = {Barendregt, Henk and Wiedijk, Freek},
  date         = {2005-10-12},
  journaltitle = {Philosophical transactions. Series A, Mathematical, physical, and engineering sciences},
  title        = {The challenge of computer mathematics},
  doi          = {10.1098/rsta.2005.1650},
  issn         = {1364-503X},
  number       = {1835},
  pages        = {2351--2375},
  volume       = {363},
}

@Online{harrison2001lcf,
  author       = {Harrison, John},
  date         = {2001-09-12},
  title        = {The {LCF} Approach to Theorem Proving},
  url          = {https://www.cl.cam.ac.uk/~jrh13/slides/manchester-12sep01/slides.pdf},
  organization = {Intel Corporation},
  location     = {University of Manchester},
  year         = {2001},
}

@InCollection{Survey1994deBruijn,
  author    = {N. G. de Bruijn},
  booktitle = {Selected Papers on Automath},
  date      = {1994},
  title     = {A Survey of the Project {A}utomath},
  doi       = {10.1016/S0049-237X(08)70203-9},
  editor    = {R.P. Nederpelt and J.H. Geuvers and R.C. {de Vrijer}},
  pages     = {141--161},
  publisher = {Elsevier},
  series    = {Studies in Logic and the Foundations of Mathematics},
  url       = {http://www.sciencedirect.com/science/article/pii/S0049237X08702039},
  volume    = {133},
  abstract  = {Publisher Summary
This chapter presents a short survey about the work that has been done on the Automath, is going on, and planned for the future. It also explains the concept of types and the matter of propositions as types and the survey is used to ventilate opinions and views in mathematics which are not easily set down in more technical reports. The project Automath develops a system of writing entire mathematical theories that verification of the correctness can be carried out by formal operations on the text. The motivations for the project: checking; understanding; and processing are discussed. These motives favor the choice of a system of a very general nature of formalizing mathematics of classical logic and set theory. One of the most important things in the project is that it expects machines to check the correctness of what humans have written. The machine has to find out whether there is a sequence of applications of the language rules that motivates the correctness of a line of the book.},
  issn      = {0049-237X},
}

@InProceedings{mathematical1970Bruijn,
  author    = {de Bruijn, N. G.},
  booktitle = {Symposium on Automatic Demonstration},
  date      = {1970},
  title     = {The mathematical language {AUTOMATH}, its usage, and some of its extensions},
  doi       = {10.1007/bfb0060623},
  editor    = {Laudet, M. and Lacombe, D. and Nolin, L. and Sch{\"u}tzenberger, M.},
  isbn      = {978-3-540-36262-3},
  location  = {Berlin, Heidelberg},
  pages     = {29--61},
  publisher = {Springer Berlin Heidelberg},
}

@Online{wiki:AutoMath,
  author = {{Wikipedia contributors}},
  date   = {2020},
  title  = {Automath --- {Wikipedia}{,} The Free Encyclopedia},
  url    = {https://en.wikipedia.org/w/index.php?title=Automath&oldid=968530682},
  note   = {[Online; accessed 26-August-2020]},
}

@Article{KnuthPrematureOptimizationExtended,
  author       = {Knuth, Donald E.},
  date         = {1974-12},
  journaltitle = {ACM Computing Surveys},
  title        = {Structured Programming with \emph{go to} Statements},
  doi          = {10.1145/356635.356640},
  issn         = {0360-0300},
  number       = {4},
  pages        = {261--301},
  volume       = {6},
  abstract     = {A consideration of several different examples sheds new light on the problem of creating reliable, well-structured programs that behave efficiently. This study focuses largely on two issues: (a) improved syntax for iterations and error exits, making it possible to write a larger class of programs clearly and efficiently without \textbf{go to} statements; (b) a methodology of program design, beginning with readable and correct, but possibly inefficient programs that are systematically transformed if necessary into efficient and correct, but possibly less readable code. The discussion brings out opposing points of view about whether or not \textbf{go to} statements should be abolished; some merit is found on both sides of this question. Finally, an attempt is made to define the true nature of structured programming, and to recommend fruitful directions for further study.},
  issue_date   = {Dec. 1974},
  keywords     = {structured programming, \emph{go to} statements, language design, event indicators, recursion, Boolean variables, iteration, optimization of programs, program transformations, program manipulation systems searching, Quieksort, efficiency},
  location     = {New York, NY, USA},
  numpages     = {41},
  publisher    = {Association for Computing Machinery},
}

@Misc{Profiling2020Leiserson,
  author       = {Leiserson, Charles E.},
  date         = {2020-08-28},
  title        = {Re: Quoting you in my {P}h{D} Thesis?},
  howpublished = {personal correspondence},
}

@Article{Uber1929Presburger,
  author       = {Mojżesz Presburger},
  date         = {1929},
  journaltitle = {Comptes Rendus du I congrès de Mathématiciens des Pays Slaves},
  title        = {Über die {V}ollständigkeit eines gewissen {S}ystems der {A}rithmetik ganzer {Z}ahlen},
  language     = {German},
  note         = {see \textcite{Stansifer:1884:PAIA} for an English translation},
  pages        = {92--101},
}

@TechReport{Stansifer:1884:PAIA,
  author      = {Ryan Stansifer},
  date        = {1984-09},
  institution = {Cornell University, Computer Science Department},
  title       = {Presburger's Article on Integer Airthmetic: Remarks and Translation},
  number      = {TR84-639},
  url         = {https://cs.fit.edu/~ryan/papers/presburger.pdf},
}

@Article{Automation2013Moore,
  author       = {J. Strother Moore and Claus-Peter Wirth},
  date         = {2013-09-24},
  journaltitle = {IfCoLog Journal of Logics and their Applications, Vol. 4, number 5, pp. 1505-1634 (2017)},
  title        = {Automation of Mathematical Induction as part of the History of Logic},
  eprint       = {1309.6226v5},
  eprintclass  = {cs.AI},
  eprinttype   = {arXiv},
  abstract     = {We review the history of the automation of mathematical induction},
  file         = {:http\://arxiv.org/pdf/1309.6226v5:PDF},
  keywords     = {cs.AI},
}

@Article{Machine1965Robinson,
  author       = {Robinson, J. A.},
  date         = {1965-01},
  journaltitle = {Journal of the ACM},
  title        = {A Machine-Oriented Logic Based on the Resolution Principle},
  doi          = {10.1145/321250.321253},
  issn         = {0004-5411},
  number       = {1},
  pages        = {23--41},
  volume       = {12},
  issue_date   = {Jan. 1965},
  location     = {New York, NY, USA},
  numpages     = {19},
  publisher    = {Association for Computing Machinery},
}

@Online{Are2011Makholm,
  author       = {Henning Makholm},
  date         = {2011-09-17},
  title        = {Are there statements that are undecidable but not provably undecidable},
  url          = {https://math.stackexchange.com/q/65302},
  urldate      = {2020-06-12},
  abstract     = {First assume that ZFC is indeed consistent. If every statement were either provably true or provably false or provably independent, then there would be a decision procedure that sorted all statements into these three groups -- just enumerate all valid proofs until one whose conclusion is one of the three forms were found.

We could use this to decide the halting problem. For any $n$ consider the statement ``Turing machine $T_n$ halts''. There are then three cases.

\begin{enumerate}
\item
$ ZFC \vdash Con(ZFC) \Rightarrow T_n\text{ halts}$
\\
   In this case, it must be true that $T_n$ halts.
\item
 $ ZFC \vdash Con(ZFC) \Rightarrow \neg(T_n\text{ halts})$
\\
   In this case it must be false that $T_n$ halts.
\item
 $ ZFC \vdash Con(ZFC) \Rightarrow{}$ ``$T_n$ halts'' is independent of ZFC.
\\
   In this case there must be a model of ZFC in which $T_n$ does not halt and so has an infinitely long computation. However, in every model of ZFC, the model's $\omega$ must contain a surjective image of the meta-$\omega$. (And similarly for whatever objects we use to represent Turing tapes). Therefore the infinite computation \emph{in the model} corresponds to an infinite computation \emph{at the meta-level}. Therefore $T_n$ really does not halt.
\end{enumerate}

In conclusion, if ZFC is consistent, then your hypothesis leads to a solution to the halting problem, which we know is impossible. Thus by contradiction your hypothesis must be false if ZFC is consistent. On the other hand if ZFC is \emph{not} consistent, then your hypothesis is still false, because then there are no unprovable statements at all.},
  author_url   = {https://math.stackexchange.com/users/14366/hmakholm-left-over-monica},
  eprint       = {https://math.stackexchange.com/q/65302},
  howpublished = {Mathematics Stack Exchange},
}

@Article{Computing1960Davis,
  author       = {Davis, Martin and Putnam, Hilary},
  date         = {1960-07},
  journaltitle = {Journal of the ACM},
  title        = {A Computing Procedure for Quantification Theory},
  doi          = {10.1145/321033.321034},
  issn         = {0004-5411},
  number       = {3},
  pages        = {201--215},
  volume       = {7},
  abstract     = {The hope that mathematical methods employed in the investigation of formal logic would lead to purely computational methods for obtaining mathematical theorems goes back to Leibniz and has been revived by Peano around the turn of the century and by Hilbert's school in the 1920's. Hilbert, noting that all of classical mathematics could be formalized within quantification theory, declared that the problem of finding an algorithm for determining whether or not a given formula of quantification theory is valid was the central problem of mathematical logic. And indeed, at one time it seemed as if investigations of this ``decision'' problem were on the verge of success. However, it was shown by Church and by Turing that such an algorithm can not exist. This result led to considerable pessimism regarding the possibility of using modern digital computers in deciding significant mathematical questions. However, recently there has been a revival of interest in the whole question. Specifically, it has been realized that while no decision procedure exists for quantification theory there are many proof procedures available—that is, uniform procedures which will ultimately locate a proof for any formula of quantification theory which is valid but which will usually involve seeking ``forever'' in the case of a formula which is not valid—and that some of these proof procedures could well turn out to be feasible for use with modern computing machinery.Hao Wang [9] and P. C. Gilmore [3] have each produced working programs which employ proof procedures in quantification theory. Gilmore's program employs a form of a basic theorem of mathematical logic due to Herbrand, and Wang's makes use of a formulation of quantification theory related to those studied by Gentzen. However, both programs encounter decisive difficulties with any but the simplest formulas of quantification theory, in connection with methods of doing propositional calculus. Wang's program, because of its use of Gentzen-like methods, involves exponentiation on the total number of truth-functional connectives, whereas Gilmore's program, using normal forms, involves exponentiation on the number of clauses present. Both methods are superior in many cases to truth table methods which involve exponentiation on the total number of variables present, and represent important initial contributions, but both run into difficulty with some fairly simple examples.In the present paper, a uniform proof procedure for quantification theory is given which is feasible for use with some rather complicated formulas and which does not ordinarily lead to exponentiation. The superiority of the present procedure over those previously available is indicated in part by the fact that a formula on which Gilmore's routine for the IBM 704 causes the machine to computer for 21 minutes without obtaining a result was worked successfully by hand computation using the present method in 30 minutes. Cf. §6, below.It should be mentioned that, before it can be hoped to employ proof procedures for quantification theory in obtaining proofs of theorems belonging to ``genuine'' mathematics, finite axiomatizations, which are ``short,'' must be obtained for various branches of mathematics. This last question will not be pursued further here; cf., however, Davis and Putnam [2], where one solution to this problem is given for ele},
  issue_date   = {July 1960},
  location     = {New York, NY, USA},
  numpages     = {15},
  publisher    = {Association for Computing Machinery},
}

@Book{Metamathematics1994Shankar,
  author     = {Shankar, N.},
  date       = {1994},
  title      = {Metamathematics, Machines and {G}ödel's Proof},
  doi        = {10.1017/CBO9780511569883},
  isbn       = {9780511569883},
  publisher  = {Cambridge University Press},
  series     = {Cambridge Tracts in Theoretical Computer Science},
  collection = {Cambridge Tracts in Theoretical Computer Science},
  place      = {Cambridge},
}

@Book{moore2007piton,
  author    = {Moore, J. S.},
  date      = {2007},
  title     = {Piton: A Mechanically Verified Assembly-Level Language},
  isbn      = {9780585336541},
  publisher = {Springer Netherlands},
  series    = {Automated Reasoning Series},
  url       = {https://books.google.com/books?id=Y09c047gV10C},
}

@Article{Milestones2019Moore,
  author       = {Moore, J. Strother},
  date         = {2019},
  journaltitle = {Formal Aspects of Computing},
  title        = {Milestones from The {P}ure {L}isp Theorem Prover to {ACL}2},
  doi          = {10.1007/s00165-019-00490-3},
  issn         = {1433-299X},
  number       = {6},
  pages        = {699--732},
  volume       = {31},
  abstract     = {We discuss the evolutionary path from the Edinburgh Pure Lisp Theorem Prover of the early 1970s to its modern counterpart, AComputational Logic for Applicative Common Lisp, aka ACL2, which is in regular industrial use. Among the milestones in this evolution are the adoption of a first-order subset of a programming language as a logic; the analysis of recursive definitions to guess appropriate mathematical induction schemes; the use of simplification in inductive proofs; the incorporation of rewrite rules derived from user-suggested lemmas; the generalization of that idea to allow the user to affect other proof techniques soundly; the recognition that evaluation efficiency is paramount so that formal models can serve as prototypes and the logic can be used to reprogram the system; use of the system to prove extensions correct; the incorporation of decision procedures; the provision of hierarchically structured libraries of previously certified results to configure the prover; the provision of system programming features to allow verification tools to be built and verified within the system; the release of many verified collections of lemmas supporting floating point, programming languages, and hardware platforms; a verified “bit-bashing” tool exploiting verified BDD and checked external SAT procedures; and the provisionof certain higher-order features within the first-order setting. As will become apparent, some of these milestones were suggested or even prototyped by users. Some additional non-technical aspects of the project are also critical. Among these are a devotion to soundness, good documentation, freely available source code, production of a system usable by industry, responsiveness to user needs, and a dedicated, passionate, and brilliant user community.},
  refid        = {Moore2019},
}

@Online{Automath2002Kamareddine,
  author   = {Fairouz Kamareddine},
  date     = {2002-04},
  title    = {Thirty Five years of {A}utomath},
  url      = {http://www.cedar-forest.org/forest/events/automath2002/},
  abstract = {Automath started in 1967 by N.G. de Bruijn. Automath (automating mathematics) was the first system to use computer technology to check the correctness of whole books of mathematics. During his work on Automath, de Bruijn discovered many concepts that still remain of great relevance to the theory and practice of computation. For example, de Bruijn indices still play an important role in the implementation of programming languages and theorem provers, de Bruijn's new type systems were influential in the discovery of new powerful type systems, and de Bruijn re-invented the Curry-Howard isomorphism (which should be referred to as the Curry-Howard-de Bruijn isomorphism). The Landau book on the foundations of analysis remains the only fully encoded and checked mathematical book in any theorem prover. The Landau book was encoded by Bert van Benthem-Jutting in Automath in the early seventies.

Automath was written in Algol 60 and implemented on the primitive PCs of the sixties. Thirty five years on, both technology and theory have evolved very much and this led to impressive new directions in theorem proving and in using the computers for manipulating and checking mathematics. This workshop is to celebrate the 35th year of Automath and some of the impressive directions in using computers for mathematics. This area is so huge now, that it cannot be covered in one workshop. Hence, this workshop makes no claim that it covers all the important directions in the field.},
  location = {Heriot-Watt University, Edinburgh},
}

@Article{Matuszewski05mizar:the,
  author       = {Roman Matuszewski and Piotr Rudnicki},
  date         = {2005-03},
  journaltitle = {Mechanized Mathematics and Its Applications},
  title        = {M\textsc{izar}: the first 30 years},
  number       = {1},
  url          = {http://mizar.org/people/romat/MatRud2005.pdf},
  volume       = {4},
}

@Article{Proof2009Geuvers,
  author       = {Geuvers, Herman},
  date         = {2009},
  journaltitle = {Sādhanā},
  title        = {Proof assistants: History, ideas and future},
  doi          = {10.1007/s12046-009-0001-5},
  issn         = {0973-7677},
  number       = {1},
  pages        = {3--25},
  url          = {https://www.ias.ac.in/article/fulltext/sadh/034/01/0003-0025},
  volume       = {34},
  abstract     = {In this paper I will discuss the fundamental ideas behind proof assistants: What are they and what is a proof anyway? I give a short history of the main ideas, emphasizing the way they ensure the correctness of the mathematics formalized. I will also briefly discuss the places where proof assistants are used and how we envision their extended use in the future. While being an introduction into the world of proof assistants and the main issues behind them, this paper is also a position paper that pushes the further use of proof assistants. We believe that these systems will become the future of mathematics, where definitions, statements, computations and proofs are all available in a computerized form. An important application is and will be in computer supported modelling and verification of systems. But there is still a long road ahead and I will indicate what we believe is needed for the further proliferation of proof assistants.},
  refid        = {Geuvers2009},
}

@InProceedings{History2014Harrison,
  author    = {John Harrison and Josef Urban and Freek Wiedijk},
  booktitle = {Computational Logic},
  date      = {2014},
  title     = {History of Interactive Theorem Proving},
  doi       = {10.1016/b978-0-444-51624-4.50004-6},
  pages     = {135--214},
  url       = {https://www.cl.cam.ac.uk/~jrh13/papers/joerg.pdf},
  issn      = {1874-5857},
}

@Online{Rigour2013Bauer,
  author       = {Andrej Bauer},
  date         = {2013-05-08},
  title        = {Is rigour just a ritual that most mathematicians wish to get rid of if they could?},
  url          = {https://mathoverflow.net/q/130125},
  version      = {2013-05-08},
  abstract     = {I was not going to write anything, as I am a latecomer to this masterful troll question and not many are likely going to scroll all the way down, but Paul Taylor's call for Proof mining and Realizability (or Realisability as the Queen would write it) was irresistible.

Nobody asks whether numbers are just a ritual, or at least not very many mathematicians do. Even the most anti-scientific philosopher can be silenced with ease by a suitable application of rituals and theories of social truth to the number that is written on his paycheck. At that point the hard reality of numbers kicks in with all its might, may it be Platonic, Realistic, or just Mathematical.

So what makes numbers so different from proofs that mathematicians will fight a meta-war just for the right to attack the heretical idea that mathematics could exist without rigor, but they would have long abandoned this question as irrelevant if it asked instead ``are numbers just a ritual that most mathematicians wish to get rid of''? We may search for an answer in the fields of sociology and philosophy, and by doing so we shall learn important and sad facts about the way mathematical community operates in a world driven by profit, but as mathematicians we shall never find a truly satisfactory answer there. Isn't philosophy the art of never finding the answers?

Instead, as mathematicians we can and should turn *inwards*. How are numbers different from proofs? The answer is this: \textbf{proofs are irrelevant but numbers are not}. This is at the same time a joke and a very serious observation about mathematics. I tell my students that proofs serve two purposes:

\begin{enumerate}
\item They convince people (including ourselves) that statements are true.
\item They convey intuitions, ideas and techniques.
\end{enumerate}

Both are important, and we have had some very nice quotes about this fact in other answers. Now ask the same question about numbers. What role do numbers play in mathematics? You might hear something like ``they are what mathematics is (also) about'' or ``That's what mathematicians study'', etc. Notice the difference? Proofs are for people but numbers are for mathematics. We admit numbers into mathematical universe as first-class citizen but we do not take seriously the idea that proofs themselves are also mathematical objects. We ignore proofs as mathematical objects. Proofs are irrelevant.

Of course you will say that logic takes proofs very seriously indeed. Yes, it does, but in a very limited way:

\begin{itemize}
\item It mostly ignores the fact that we use proofs to convey ideas and focuses just on how proofs convey truth. Such practice not only hinders progress in logic, but is also actively harmful because it discourages mathematization of about 50\% of mathematical activity. If you do not believe me try getting funding on research in ``mathematical beauty''.
\item It considers proofs as syntactic objects. This puts logic where analysis used to be when mathematicians thought of functions as symbolic expressions, probably sometime before the 19th century.
\item It is largely practiced in isolation from ``normal'' mathematics, by which it is doubly handicapped, once for passing over the rest of mathematics and once for passing over the rest of mathematicians.
\item Consequently even very basic questions, such as ``when are two proofs equal'' puzzle many logicians. This is a ridiculous state of affairs.
\end{itemize}

But these are rather minor technical deficiencies. The real problem is that \emph{mainstream} mathematicians are mostly unaware of the fact that proofs can and should be first-class mathematical objects. I can anticipate the response: proofs are in the domain of logic, they should be studied by logicians, but normal mathematicians cannot gain much by doing proof theory. I agree, normal mathematicians cannot gain much by doing \emph{traditional} proof theory. But did you know that proofs and computation are intimately connected, and that every time you prove something you have also written a program, and vice versa? That proofs have a homotopy-theoretic interpretation that has been discovered only recently? That proofs can be ``mined'' for additional, hidden mathematical gems? This is the stuff of \emph{new} proof theory, which also goes under names such as Realizability, Type theory, and Proof mining.

Imagine what will happen with mathematics if logic gets boosted by the machinery of algebra and homotopy theory, if the full potential of ``proofs as computations'' is used in practice on modern computers, if completely new and fresh ways of looking at the nature of proof are explored by the brightest mathematicians who have vast experience outside the field of logic? This will necessarily represent a major shift in how mathematics is done and what it can accomplish.

Because mathematicians have not reached the level of reflection which would allow them to accept \textbf{proof relevant mathematics} they seek security in the mathematically and socially inadequate dogma that a proof can only be a finite syntactic entity. This makes us feeble and weak and unable to argue intelligently with a well-versed sociologist who can wield the weapons of social theories, anthropology and experimental psychology.
So the best answer to the question ``is rigor just a ritual'' is to study rigor as a \emph{mathematical concept}, to quantify it, to abstract it, and to turn it into something new, flexible and beautiful. Then we will laugh at our old fears, wonder how we ever could have thought that rigor is absolute, and we will become the teachers of our critics.},
  author_url   = {https://mathoverflow.net/users/1176/andrej-bauer},
  eprint       = {https://mathoverflow.net/q/130125},
  howpublished = {MathOverflow},
}

@InBook{CoqArtForward2013Huet,
  author       = {Gérard Huet and Christine Paulin-Mohring},
  booktitle    = {Interactive Theorem Proving and Program Development},
  date         = {2003-11},
  title        = {Forward},
  bookauthor   = {Yves Bertot and Pierre Castéran},
  booksubtitle = {Coq'Art: The Calculus of Inductive Constructions},
  isbn         = {9783662079645},
  pages        = {IX--XVI},
  publisher    = {Springer Berlin Heidelberg},
  series       = {Texts in Theoretical Computer Science. An EATCS Series},
  url          = {https://books.google.com/books?id=FeklBQAAQBAJ},
}

@Article{Coq2019Sozeau,
  author       = {Sozeau, Matthieu and Boulier, Simon and Forster, Yannick and Tabareau, Nicolas and Winterhalter, Théo},
  date         = {2019-12},
  journaltitle = {Proceedings of the ACM on Programming Languages},
  title        = {Coq {C}oq Correct! Verification of Type Checking and Erasure for {C}oq, in {C}oq},
  doi          = {10.1145/3371076},
  issue        = {POPL},
  volume       = {4},
  abstract     = {Coq is built around a well-delimited kernel that perfoms typechecking for definitions in a variant of the Calculus of Inductive Constructions (CIC). Although the metatheory of CIC is very stable and reliable, the correctness of its implementation in Coq is less clear. Indeed, implementing an efficient type checker for CIC is a rather complex task, and many parts of the code rely on implicit invariants which can easily be broken by further evolution of the code. Therefore, on average, one critical bug has been found every year in Coq.  This paper presents the first implementation of a type checker for the kernel of Coq (without the module system and template polymorphism), which is proven correct in Coq with respect to its formal specification and axiomatisation of part of its metatheory. Note that because of G\"{o}del's incompleteness theorem, there is no hope to prove completely the correctness of the specification of Coq inside Coq (in particular strong normalisation or canonicity), but it is possible to prove the correctness of the implementation assuming the correctness of the specification, thus moving from a trusted code base (TCB) to a trusted theory base (TTB) paradigm.  Our work is based on the MetaCoq project which provides metaprogramming facilities to work with terms and declarations at the level of this kernel. Our type checker is based on the specification of the typing relation of the Polymorphic, Cumulative Calculus of Inductive Constructions (PCUIC) at the basis of Coq and the verification of a relatively efficient and sound type-checker for it. In addition to the kernel implementation, an essential feature of Coq is the so-called extraction: the production of executable code in functional languages from Coq definitions. We present a verified version of this subtle type-and-proof erasure step, therefore enabling the verified extraction of a safe type-checker for Coq.},
  articleno    = {8},
  issue_date   = {January 2020},
  keywords     = {certification, type checker, proof assistants},
  location     = {New York, NY, USA},
  numpages     = {28},
  publisher    = {Association for Computing Machinery},
}

@InBook{Logical2002Pfenning,
  author    = {Pfenning, Frank},
  booktitle = {Proof and System-Reliability},
  date      = {2002},
  title     = {Logical Frameworks---A Brief Introduction},
  doi       = {10.1007/978-94-010-0413-8_5},
  editor    = {Schwichtenberg, Helmut and Steinbr{\"u}ggen, Ralf},
  isbn      = {978-94-010-0413-8},
  location  = {Dordrecht},
  pages     = {137--166},
  publisher = {Springer Netherlands},
  url       = {https://www.cs.cmu.edu/~fp/papers/mdorf01.pdf},
  abstract  = {A logical framework is a meta-language for the formalization of deductive systems. We provide a brief introduction to logical frameworks and their methodology, concentrating on LF. We use first-order logic as the running example to illustrate the representations of syntax, natural deductions, and proof transformations.},
}

@Article{Formalizing2009Wiedijk,
  author       = {Wiedijk, Freek},
  date         = {2009},
  journaltitle = {Sādhanā},
  title        = {Formalizing {A}rrow’s theorem},
  doi          = {10.1007/s12046-009-0005-1},
  issn         = {0973-7677},
  number       = {1},
  pages        = {193--220},
  url          = {http://www.cs.ru.nl/~freek/pubs/arrow.pdf},
  volume       = {34},
  abstract     = {A small project in which I encoded a proof of Arrow’s theorem--probably the most famous results in the economics field of social choice theory--in the computer using the Mizar system is presented here. The details of this specific project, as well as the process of formalization (encoding proofs in the computer) in general are discussed.},
  refid        = {Wiedijk2009},
}

@PhdThesis{LEGO1994Pollack,
  author      = {Robert Pollack},
  date        = {1994},
  institution = {University of Edinburgh},
  title       = {The Theory of {LEGO}},
  subtitle    = {A Proof Checker for the Extended Calculus of Constructions},
}

@Electronic{Coq,
  author       = {{C}oq Development Team, The},
  date         = {2020-07},
  title        = {The {C}oq Proof Assistant},
  url          = {https://coq.inria.fr/},
  organization = {{INRIA}},
  version      = {{8.12.0}},
  abstractnote = {Coq is a formal proof management system. It provides a formal language to write mathematical definitions, executable algorithms and theorems together with an environment for semi-interactive development of machine-checked proofs. Typical applications include the certification of properties of programming languages (e.g. the CompCert compiler certification project, or the Bedrock verified low-level programming library), the formalization of mathematics (e.g. the full formalization of the Feit-Thompson theorem or homotopy type theory) and teaching. The main changes brought by Coq version 8.11 are: Ltac2, a new tactic language for writing more robust larger scale tactics, with built-in support for datatypes and the multi-goal tactic monad. Primitive floats are integrated in terms and follow the binary64 format of the IEEE 754 standard, as specified in the Coq.Float.Floats library. Cleanups of the section mechanism, delayed proofs and further restrictions of template polymorphism to fix soundness issues related to universes. New unsafe flags to disable locally guard, positivity and universe checking. Reliance on these flags is always printed by Print Assumptions. Fixed bugs of Export and Import that can have a significant impact on user developments (common source of incompatibility!). New interactive development method based on vos interface files, allowing to work on a file without recompiling the proof parts of their dependencies. New Arguments annotation for bidirectional type inference configuration for reference (e.g. constants, inductive) applications. New refine attribute for Instance can be used instead of the removed Refine Instance Mode. Generalization of the under and over tactics of SSReflect to arbitrary relations. Revision of the Coq.Reals library, its axiomatisation and instances of the constructive and classical real numbers. Additionally, while the omega tactic is not yet deprecated in this version of Coq, it should soon be the case and we already recommend users to switch to lia in new proof scripts (see also the warning message in the corresponding chapter). The dev/doc/critical-bugs file documents the known critical bugs of Coq and affected releases. See the Changes in 8.11+beta1 section and following sections for the detailed list of changes, including potentially breaking changes marked with Changed. Coq's documentation is available at https://coq.github.io/doc/v8.11/api (documentation of the ML API), https://coq.github.io/doc/v8.11/refman (reference manual), and https://coq.github.io/doc/v8.11/stdlib (documentation of the standard library). Maxime D{\'{e}}n{\`{e}}s, Emilio Jes{\'{u}}s Gallego Arias, Ga{\"{e}}tan Gilbert, Michael Soegtrop and Th{\'{e}}o Zimmermann worked on maintaining and improving the continuous integration system and package building infrastructure. The OPAM repository for Coq packages has been maintained by Guillaume Claret, Karl Palmskog, Matthieu Sozeau and Enrico Tassi with contributions from many users. A list of packages is available at https://coq.inria.fr/opam/www/. The 61 contributors to this version are Michael D. Adams, Guillaume Allais, Helge Bahmann, Langston Barrett, Guillaume Bertholon, Fr{\'{e}}d{\'{e}}ric Besson, Simon Boulier, Michele Caci, Tej Chajed, Arthur Chargu{\'{e}}raud, Cyril Cohen, Fr{\'{e}}d{\'{e}}ric Dabrowski, Arthur Azevedo de Amorim, Maxime D{\'{e}}n{\`{e}}s, Nikita Eshkeev, Jim Fehrle, Emilio Jes{\'{u}}s Gallego Arias, Paolo G. Giarrusso, Ga{\"{e}}tan Gilbert, Georges Gonthier, Jason Gross, Samuel Gruetter, Arma{\"{e}}l Gu{\'{e}}neau, Hugo Herbelin, Florent Hivert, Jasper Hugunin, Shachar Itzhaky, Jan-Oliver Kaiser, Robbert Krebbers, Vincent Laporte, Olivier Laurent, Samuel Leli{\`{e}}vre, Nicholas Lewycky, Yishuai Li, Jose Fernando Lopez Fernandez, Andreas Lynge, Kenji Maillard, Erik Martin-Dorel, Guillaume Melquiond, Alexandre Moine, Oliver Nash, Wojciech Nawrocki, Antonio Nikishaev, Pierre-Marie P{\'{e}}drot, Cl{\'{e}}ment Pit-Claudel, Lars Rasmusson, Robert Rand, Talia Ringer, JP Rodi, Pierre Roux, Kazuhiko Sakaguchi, Vincent Semeria, Michael Soegtrop, Matthieu Sozeau, spanjel, Claude Stolze, Enrico Tassi, Laurent Th{\'{e}}ry, James R. Wilcox, Xia Li-yao, Th{\'{e}}o Zimmermann Many power users helped to improve the design of the new features via the issue and pull request system, the Coq development mailing list, the coq-club@inria.fr mailing list or the Discourse forum. It would be impossible to mention exhaustively the names of everybody who to some extent influenced the development. Version 8.11 is the sixth release of Coq developed on a time-based development cycle. Its development spanned 3 months from the release of Coq 8.10. Pierre-Marie P{\'{e}}drot is the release manager and maintainer of this release, assisted by Matthieu Sozeau. This release is the result of 2000+ commits and 300+ PRs merged, closing 75+ issues.},
  doi          = {10.5281/zenodo.1003420},
  publisher    = {Zenodo},
}

@Article{Ben-AmramG92,
  author       = {Amir M. Ben-Amram and Zvi Galil},
  date         = {1992-07},
  journaltitle = {Journal of the ACM},
  title        = {On Pointers versus Addresses},
  doi          = {10.1145/146637.146666},
  number       = {3},
  pages        = {617--648},
  url          = {https://www2.mta.ac.il/~amirben/downloadable/jacm.ps.gz},
  volume       = {39},
  area         = {Theory of Computation},
}

@Unpublished{Ben-amram96noteson,
  author   = {Amir M. Ben-Amram},
  date     = {1996},
  title    = {Notes on {P}ippenger's Comparison of Pure and Impure {LISP}},
  location = {DIKU, University of Copenhagen, Denmark},
  url      = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.55.3024},
}

@Article{More1997Bird,
  author       = {Bird, Richard and Jones, Geraint and De Moor, Oege},
  date         = {1997-09},
  journaltitle = {Journal of Functional Programming},
  title        = {More Haste, Less Speed: Lazy versus Eager Evaluation},
  doi          = {10.1017/S0956796897002827},
  issn         = {0956-7968},
  number       = {5},
  pages        = {541--547},
  volume       = {7},
  abstract     = {Nicholas Pippenger has recently given a problem that, under two simple restrictions, can be solved in linear time by an impure Lisp program, but requires Ω(n log n) steps to be solved by any eager pure Lisp program. By showing how to solve the problem in linear time with a lazy functional program, we demonstrate that – for some problems at least – lazy evaluators are strictly more powerful than eager ones.},
  issue_date   = {September 1997},
  location     = {USA},
  numpages     = {7},
  publisher    = {Cambridge University Press},
}

@PhdThesis{okasaki1996purely,
  author      = {Okasaki, Chris},
  date        = {1996-09},
  institution = {Carnegie Mellon University},
  title       = {Purely Functional Data Structures},
  url         = {https://www.cs.cmu.edu/~rwh/theses/okasaki.pdf},
}

@Book{okasaki1998purely,
  author    = {Okasaki, Chris},
  date      = {1998},
  title     = {Purely Functional Data Structures},
  doi       = {10.1017/cbo9780511530104},
  isbn      = {9781139811019},
  publisher = {Cambridge University Press},
  url       = {https://books.google.com/books?id=IV8hAwAAQBAJ},
}

@Article{Pure1997Pippenger,
  author       = {Pippenger, Nicholas},
  date         = {1997-03},
  journaltitle = {ACM Transactions on Programming Languages and Systems},
  title        = {Pure versus Impure {L}isp},
  doi          = {10.1145/244795.244798},
  issn         = {0164-0925},
  number       = {2},
  pages        = {223--238},
  volume       = {19},
  issue_date   = {March 1997},
  keywords     = {online computation, schematology},
  location     = {New York, NY, USA},
  numpages     = {16},
  publisher    = {Association for Computing Machinery},
}

@Online{Efficiency2010Campbell,
  author       = {Brian Campbell},
  date         = {2010-05-23},
  title        = {Efficiency of purely functional programming},
  url          = {https://stackoverflow.com/a/1990580},
  abstract     = {According to Pippenger [1996], when comparing a Lisp system that is purely functional (and has strict evaluation semantics, not lazy) to one that can mutate data, an algorithm written for the impure Lisp that runs in O(n) can be translated to an algorithm in the pure Lisp that runs in O(n log n) time (based on work by Ben-Amram and Galil [1992] about simulating random access memory using only pointers). Pippenger also establishes that there are algorithms for which that is the best you can do; there are problems which are O(n) in the impure system which are Ω(n log n) in the pure system.

There are a few caveats to be made about this paper. The most significant is that it does not address lazy functional languages, such as Haskell. Bird, Jones and De Moor [1997] demonstrate that the problem constructed by Pippenger can be solved in a lazy functional language in O(n) time, but they do not establish (and as far as I know, no one has) whether or not a lazy functional language can solve all problems in the same asymptotic running time as a language with mutation.

The problem constructed by Pippenger requires Ω(n log n) is specifically constructed to achieve this result, and is not necessarily representative of practical, real-world problems. There are a few restrictions on the problem that are a bit unexpected, but necessary for the proof to work; in particular, the problem requires that results are computed on-line, without being able to access future input, and that the input consists of a sequence of atoms from an unbounded set of possible atoms, rather than a fixed size set. And the paper only establishes (lower bound) results for an impure algorithm of linear running time; for problems that require a greater running time, it is possible that the extra O(log n) factor seen in the linear problem may be able to be "absorbed" in the process of extra operations necessary for algorithms with greater running times. These clarifications and open questions are explored briefly by Ben-Amram [1996].

In practice, many algorithms can be implemented in a pure functional language at the same efficiency as in a language with mutable data structures. For a good reference on techniques to use for implementing purely functional data structures efficiently, see Chris Okasaki's "Purely Functional Data Structures" [Okasaki 1998] (which is an expanded version of his thesis [Okasaki 1996]).

Anyone who needs to implement algorithms on purely-functional data structures should read Okasaki. You can always get at worst an O(log n) slowdown per operation by simulating mutable memory with a balanced binary tree, but in many cases you can do considerably better than that, and Okasaki describes many useful techniques, from amortized techniques to real-time ones that do the amortized work incrementally. Purely functional data structures can be a bit difficult to work with and analyze, but they provide many benefits like referential transparency that are helpful in compiler optimization, in parallel and distributed computing, and in implementation of features like versioning, undo, and rollback.

Note also that all of this discusses only asymptotic running times. Many techniques for implementing purely functional data structures give you a certain amount of constant factor slowdown, due to extra bookkeeping necessary for them to work, and implementation details of the language in question. The benefits of purely functional data structures may outweigh these constant factor slowdowns, so you will generally need to make trade-offs based on the problem in question.
References
\begin{itemize}
\item    Ben-Amram, Amir and Galil, Zvi 1992. "On Pointers versus Addresses" Journal of the ACM, 39(3), pp. 617-648, July 1992
\item    Ben-Amram, Amir 1996. "Notes on Pippenger's Comparison of Pure and Impure Lisp" Unpublished manuscript, DIKU, University of Copenhagen, Denmark
\item    Bird, Richard, Jones, Geraint, and De Moor, Oege 1997. "More haste, less speed: lazy versus eager evaluation" Journal of Functional Programming 7, 5 pp. 541–547, September 1997
\item    Okasaki, Chris 1996. "Purely Functional Data Structures" PhD Thesis, Carnegie Mellon University
\item    Okasaki, Chris 1998. "Purely Functional Data Structures" Cambridge University Press, Cambridge, UK
\item    Pippenger, Nicholas 1996. "Pure Versus Impure Lisp" ACM Symposium on Principles of Programming Languages, pages 104–109, January 1996
\end{itemize}},
  author_url   = {https://stackoverflow.com/users/69755/brian-campbell},
  eprint       = {https://stackoverflow.com/a/1990580},
  howpublished = {Stack Overflow},
}

@Article{Logical2016Garrabrant,
  author      = {Scott Garrabrant and Tsvi Benson-Tilsen and Andrew Critch and Nate Soares and Jessica Taylor},
  date        = {2016-09-12},
  title       = {Logical Induction},
  eprint      = {1609.03543},
  eprintclass = {cs.AI},
  eprinttype  = {arXiv},
  abstract    = {We present a computable algorithm that assigns probabilities to every logical statement in a given formal language, and refines those probabilities over time. For instance, if the language is Peano arithmetic, it assigns probabilities to all arithmetical statements, including claims about the twin prime conjecture, the outputs of long-running computations, and its own probabilities. We show that our algorithm, an instance of what we call a logical inductor, satisfies a number of intuitive desiderata, including: (1) it learns to predict patterns of truth and falsehood in logical statements, often long before having the resources to evaluate the statements, so long as the patterns can be written down in polynomial time; (2) it learns to use appropriate statistical summaries to predict sequences of statements whose truth values appear pseudorandom; and (3) it learns to have accurate beliefs about its own current beliefs, in a manner that avoids the standard paradoxes of self-reference. For example, if a given computer program only ever produces outputs in a certain range, a logical inductor learns this fact in a timely manner; and if late digits in the decimal expansion of $\pi$ are difficult to predict, then a logical inductor learns to assign $\approx 10\%$ probability to "the $n$th digit of $\pi$ is a 7" for large $n$. Logical inductors also learn to trust their future beliefs more than their current beliefs, and their beliefs are coherent in the limit (whenever $\phi \implies \psi$, $\mathbb{P}_\infty(\phi) \le \mathbb{P}_\infty(\psi)$, and so on); and logical inductors strictly dominate the universal semimeasure in the limit. These properties and many others all follow from a single logical induction criterion, which is motivated by a series of stock trading analogies. Roughly speaking, each logical sentence $\phi$ is associated with a stock that is worth \$1 per share if [...]},
  file        = {:http\://arxiv.org/pdf/1609.03543v4:PDF},
  keywords    = {cs.AI, cs.LO, math.LO, math.PR},
}

@InCollection{Constructive1982MartinLoef,
  author    = {Per Martin-Löf},
  booktitle = {Logic, Methodology and Philosophy of Science VI},
  date      = {1982},
  title     = {Constructive Mathematics and Computer Programming},
  doi       = {10.1016/S0049-237X(09)70189-2},
  editor    = {L. Jonathan Cohen and Jerzy Łoś and Helmut Pfeiffer and Klaus-Peter Podewski},
  pages     = {153--175},
  publisher = {Elsevier},
  series    = {Studies in Logic and the Foundations of Mathematics},
  url       = {http://www.sciencedirect.com/science/article/pii/S0049237X09701892},
  volume    = {104},
  abstract  = {Publisher Summary
This chapter discusses that relating constructive mathematics to computer programming seems to be beneficial. Among the benefits to be derived by constructive mathematics from its association with computer programming, one is that you see immediately why you cannot rely upon the law of excluded middle: its uninhibited use would lead to programs that one did not know how to execute. By choosing to program in a formal language for constructive mathematics, like the theory of types, one gets access to the conceptual apparatus of pure mathematics, neglecting those parts that depend critically on the law of excluded middle, whereas even the best high level programming languages so far designed are wholly inadequate as mathematical languages. The virtue of a machine code is that a program written in it can be directly read and executed by the machine. The distinction between low and high level programming languages is of course relative to the available hardware. It may well be possible to turn what is now regarded as a high level programming language into machine code by the invention of new hardware.},
  issn      = {0049-237X},
}

@InCollection{Intuitionistic1975MartinLoef,
  author    = {Per Martin-Löf},
  booktitle = {Logic Colloquium '73},
  date      = {1975},
  title     = {An Intuitionistic Theory of Types: Predicative Part},
  doi       = {10.1016/S0049-237X(08)71945-1},
  editor    = {H.E. Rose and J.C. Shepherdson},
  pages     = {73--118},
  publisher = {Elsevier},
  series    = {Studies in Logic and the Foundations of Mathematics},
  url       = {http://www.sciencedirect.com/science/article/pii/S0049237X08719451},
  volume    = {80},
  abstract  = {Publisher Summary
The theory of types is intended to be a full-scale system for formalizing intuitionistic mathematics as developed. The language of the theory is richer than the languages of traditional intuitionistic systems in permitting proofs to appear as parts of propositions so that the propositions of the theory can express properties of proofs. There are axioms for universes that link the generation of objects and types and play somewhat the same role for the present theory as does the replacement axiom for Zermelo–Fraenkel set theory. The present theory is based on a strongly impredicative axiom that there is a type of all types in symbols. This axiom has to be abandoned, however, after it has been shown to lead to a contraction. This chapter discusses Normalization theorem, which can be strengthened in two ways: it can be made to cover open terms and it can be proved that every reduction sequence starting from an arbitrary term leads to a unique normal term after a finite number of steps. The definition of the notion of convertibility and the proof that an arbitrary term is convertible can no longer be separated because the type symbols and the terms are generated simultaneously.},
  issn      = {0049-237X},
}

@Article{Type1993Scott,
  author       = {Dana S. Scott},
  date         = {1993},
  journaltitle = {Theoretical Computer Science},
  title        = {A Type-Theoretical Alternative to {ISWIM}, {CUCH}, {OWHY}},
  doi          = {10.1016/0304-3975(93)90095-B},
  number       = {1{\&}2},
  pages        = {411--440},
  url          = {https://www.cs.cmu.edu/~kw/scans/scott93tcs.pdf},
  volume       = {121},
  bibsource    = {dblp computer science bibliography, https://dblp.org},
  biburl       = {https://dblp.org/rec/journals/tcs/Scott93.bib},
  timestamp    = {Wed, 14 Nov 2018 10:33:30 +0100},
}

@InProceedings{Sorting2007Gruber,
  author    = {Gruber, Hermann and Holzer, Markus and Ruepp, Oliver},
  booktitle = {Fun with Algorithms},
  date      = {2007},
  title     = {Sorting the Slow Way: An Analysis of Perversely Awful Randomized Sorting Algorithms},
  doi       = {10.1007/978-3-540-72914-3_17},
  editor    = {Crescenzi, Pierluigi and Prencipe, Giuseppe and Pucci, Geppino},
  isbn      = {978-3-540-72914-3},
  location  = {Berlin, Heidelberg},
  pages     = {183--197},
  publisher = {Springer Berlin Heidelberg},
  url       = {http://www.hermann-gruber.com/pdf/fun07-final.pdf},
  abstract  = {This paper is devoted to the ``Discovery of Slowness.'' The archetypical perversely awful algorithm bogo-sort, which is sometimes referred to as Monkey-sort, is analyzed with elementary methods. Moreover, practical experiments are performed.},
}

@InCollection{bogosort-name,
  booktitle = {The Jargon File 4.4.7},
  date      = {2003-12-29},
  title     = {bogo-sort},
  editor    = {Eric Raymond},
  url       = {http://www.catb.org/jargon/html/B/bogo-sort.html},
}

@Book{tapl,
  author    = {Benjamin C. Pierce},
  date      = {2002},
  title     = {Types and Programming Languages},
  isbn      = {9780262162098},
  publisher = {MIT Press},
  series    = {The MIT Press},
  url       = {https://www.cis.upenn.edu/~bcpierce/tapl/},
  abstract  = {A type system is a syntactic method for enforcing levels of abstraction in programs. The study of type systems--and of programming languages from a type-theoretic perspective--has important applications in software engineering, language design, high-performance compilers, and security.

This text provides a comprehensive introduction both to type systems in computer science and to the basic theory of programming languages. The approach is pragmatic and operational; each new concept is motivated by programming examples and the more theoretical sections are driven by the needs of implementations. Each chapter is accompanied by numerous exercises and solutions, as well as a running implementation. Dependencies between chapters are explicitly identified, allowing readers to choose a variety of paths through the material.

The core topics include the untyped lambda-calculus, simple type systems, type reconstruction, universal and existential polymorphism, subtyping, bounded quantification, recursive types, kinds, and type operators. Extended case studies develop a variety of approaches to modeling the features of object-oriented languages.},
  lccn      = {2001044428},
}

@Online{C2017FSF,
  author = {{Free Software Foundation}},
  date   = {2017},
  title  = {The {C} Preprocessor: Implementation limits},
  url    = {https://gcc.gnu.org/onlinedocs/gcc-7.5.0/cpp/Implementation-limits.html},
}

@Article{Infamous2014Gawron,
  author = {Nicole Gawron},
  date   = {2014-08-23},
  title  = {Infamous Software Bugs: {FDIV} Bug},
  url    = {https://www.olenick.com/blog/articles/infamous-software-bugs-fdiv-bug},
}

@Article{Truth1995Halfhill,
  author       = {Tom R. Halfhill},
  date         = {1995-03},
  journaltitle = {BYTE},
  title        = {The Truth Behind the {P}entium Bug},
  url          = {https://web.archive.org/web/20060209005434/http://www.byte.com/art/9503/sec13/art1.htm},
}

@Online{Pentium2011Nicely,
  author = {Thomas R. Nicely},
  date   = {2011-08-19},
  title  = {Pentium {FDIV} flaw {FAQ}},
  url    = {https://web.archive.org/web/20190618044444/http://www.trnicely.net/pentbug/pentbug.html},
}

@Online{Space1996Leech,
  author = {Jonathan P. Leech and Larry Klaes and Matthew Wiener and Yoshiro Yamada},
  date   = {1996-09-17},
  title  = {Space {FAQ} 08/13 - Planetary Probe History},
  url    = {http://www.faqs.org/faqs/space/probe/},
}

@Article{Ariane1997Dowson,
  author       = {Dowson, Mark},
  date         = {1997-03},
  journaltitle = {ACM SIGSOFT Software Engineering Notes},
  title        = {The {A}riane 5 Software Failure},
  doi          = {10.1145/251880.251992},
  issn         = {0163-5948},
  number       = {2},
  pages        = {84},
  volume       = {22},
  issue_date   = {March 1997},
  location     = {New York, NY, USA},
  numpages     = {1},
  publisher    = {Association for Computing Machinery},
}

@Article{Design1997Jazequel,
  author       = {Jean-Marc Jézéquel and Bertrand Meyer},
  date         = {1997-01},
  journaltitle = {Computer},
  title        = {Design by Contract: The Lessons of {A}riane},
  doi          = {10.1109/2.562936},
  editor       = {Bertrand Meyer},
  issn         = {1558-0814},
  number       = {1},
  pages        = {129--130},
  url          = {http://se.ethz.ch/~meyer/publications/computer/ariane.pdf},
  volume       = {30},
  abstract     = {Design by contract is the principle that the interfaces between modules of a software system-especially a mission-critical one-should be governed by precise specifications. The contracts cover mutual obligations (pre-conditions), benefits (post-conditions), and consistency constraints (invariants). Together, these properties are known as assertions, and are directly supported in some design and programming languages. A recent \$500 million software error provides a sobering reminder that this principle is not just a pleasant academic ideal. On June 4, 1996, the maiden flight of the European Ariane 5 launcher crashed, about 40 seconds after takeoff. The rocket was uninsured. The French space agency, CNES (Centre National d'Etudes Spatiales), and the European Space Agency (ESA) immediately appointed an international inquiry board. The board makes several recommendations with respect to software process improvement. There is a simple lesson to be learned from this event: reuse without a precise, rigorous specification mechanism is a risk of potentially disastrous proportions. It is regrettable that this lesson has not been heeded by such recent designs as IDL, Ada 95 or Java. None of these languages has built-in support for design by contract. Effective reuse requires design by contract. Without a precise specification attached to each reusable component, no-one can trust a supposedly reusable component. Without a specification, it is probably safer to redo than to reuse.},
  keywords     = {contracts;rockets;software reusability;formal specification;aerospace computing;special purpose computers;safety-critical software;design by contract;software module interfaces;mission-critical software;precise rigorous specification mechanism;mutual obligations;preconditions;benefits;post-conditions;consistency constraints;invariants;assertions;software error;Ariane 5 launcher;CNES;Centre National d'Etudes Spatiales;European Space Agency;ESA;international inquiry board;software process improvement;software reuse;risk;reusable components;Contracts;Software testing;System testing;Computer errors;Protection;Performance analysis;Delay;Computer crashes;Documentation;Software engineering},
}

@Article{Metric1999Lloyd,
  author       = {Robin Lloyd},
  date         = {1999-09-30},
  journaltitle = {CNN},
  title        = {Metric mishap caused loss of {NASA} orbiter},
  url          = {http://www.cnn.com/TECH/space/9909/30/mars.metric.02/index.html},
}

@Book{Gift2018Baase,
  author    = {Sara Baase and Timothy Henry},
  date      = {2018},
  title     = {A Gift of Fire: Social, Legal, and Ethical Issues for Computing Technology},
  edition   = {5},
  isbn      = {9780134615271},
  publisher = {Pearson},
  url       = {https://books.google.com/books?id=izaqAQAACAAJ},
  lccn      = {2016058670},
}

@Article{Investigation1993Leveson,
  author       = {Nancy G. Leveson and Clark S. Turner},
  date         = {1993-07},
  journaltitle = {Computer},
  title        = {An Investigation of the {T}herac-25 Accidents},
  doi          = {10.1109/MC.1993.274940},
  issn         = {1558-0814},
  number       = {7},
  pages        = {18--41},
  url          = {https://web.archive.org/web/20041128024227/http://www.cs.umd.edu/class/spring2003/cmsc838p/Misc/therac.pdf},
  volume       = {26},
  abstract     = {Between June 1985 and January 1987, the Therac-25 medical electron accelerator was involved in six massive radiation overdoses. As a result, several people died and others were seriously injured. A detailed investigation of the factors involved in the software-related overdoses and attempts by users, manufacturers, and government agencies to deal with the accidents is presented. The authors demonstrate the complex nature of accidents and the need to investigate all aspects of system development and operation in order to prevent future accidents. The authors also present some lessons learned in terms of system engineering, software engineering, and government regulation of safety-critical systems containing software components.<>},
  journal      = {Computer},
  keywords     = {accidents;government policies;linear accelerators;medical computing;radiation therapy;software engineering;systems engineering;system operation;accidents;Therac-25 medical electron accelerator;radiation overdoses;software-related overdoses;system development;system engineering;software engineering;government regulation;safety-critical systems;Accidents;Software safety;Food manufacturing;Computer industry;Food industry;Electron accelerators;Biomedical applications of radiation;Injuries;History;Drugs},
}

@Book{Structure1996Sussman,
  author    = {Sussman, Gerald Jay and Sussman, Julie and Abelson, Harold},
  date      = {1996},
  title     = {Structure and Interpretation of Computer Programs},
  edition   = {2},
  language  = {English},
  publisher = {MIT Press},
  url       = {http://mitpress.mit.edu/sicp/},
  abstract  = {Structure and Interpretation of Computer Programs has had a dramatic impact on computer science curricula over the past decade. This long-awaited revision contains changes throughout the text. There are new implementations of most of the major programming systems in the book, including the interpreters and compilers, and the authors have incorporated many small changes that reflect their experience teaching the course at MIT since the first edition was published. A new theme has been introduced that emphasizes the central role played by different approaches to dealing with time in computational models: objects with state, concurrent programming, functional programming and lazy evaluation, and nondeterministic programming. There are new example sections on higher-order procedures in graphics and on applications of stream processing in numerical programming, and many new exercises. In addition, all the programs have been reworked to run in any Scheme implementation that adheres to the IEEE standard.},
  database  = {/z-wcorg/},
  refid     = {1139863890},
}

@Article{Efficient2000Shao,
  author       = {Shao, Zhong and Appel, Andrew W.},
  date         = {2000-01},
  journaltitle = {ACM Transactions on Programming Languages and Systems},
  title        = {Efficient and Safe-for-Space Closure Conversion},
  doi          = {10.1145/345099.345125},
  issn         = {0164-0925},
  number       = {1},
  pages        = {129--161},
  url          = {https://flint.cs.yale.edu/shao/papers/escc.html},
  volume       = {22},
  abstract     = {Modern compilers often implement function calls (or returns) in two steps: first, a “closure” environment is properly installed to provide access for free variables in the target program fragment; second, the control is transferred to the target by a “jump with arguments (for results).” Closure conversion—which decides where and how to represent closures at runtime—is a crucial step in the compilation of functional languages. This paper presents a new algorithm that exploits the use of compile-time control and data-flow information to optimize funtion calls. By extensive closure sharing and allocation by 36\% and memory fetches for local and global variables by 43\%; and improves the already efficient code generated by an earlier version of the Standard ML of New Jersey  compiler by about 17\% on a DECstation 5000. Moreover, unlike most other approaches, our new closure-allocation scheme the strong safe-for-space-complexity rule, thus achieving good asymptotic space usage.},
  issue_date   = {Jan. 2000},
  keywords     = {closure representation, compiler optimization, space safety, flow analysis, callee-save registers, heap-based compilation, closure conversion},
  location     = {New York, NY, USA},
  numpages     = {33},
  publisher    = {Association for Computing Machinery},
}

@Article{Type2011Spitters,
  author      = {Bas Spitters and Eelis van der Weegen},
  date        = {2011-02-07},
  title       = {Type Classes for Mathematics in Type Theory},
  eprint      = {1102.1323},
  eprintclass = {cs.LO},
  eprinttype  = {arXiv},
  abstract    = {The introduction of first-class type classes in the Coq system calls for re-examination of the basic interfaces used for mathematical formalization in type theory. We present a new set of type classes for mathematics and take full advantage of their unique features to make practical a particularly flexible approach formerly thought infeasible. Thus, we address both traditional proof engineering challenges as well as new ones resulting from our ambition to build upon this development a library of constructive analysis in which abstraction penalties inhibiting efficient computation are reduced to a minimum. The base of our development consists of type classes representing a standard algebraic hierarchy, as well as portions of category theory and universal algebra. On this foundation we build a set of mathematically sound abstract interfaces for different kinds of numbers, succinctly expressed using categorical language and universal algebra constructions. Strategic use of type classes lets us support these high-level theory-friendly definitions while still enabling efficient implementations unhindered by gratuitous indirection, conversion or projection. Algebra thrives on the interplay between syntax and semantics. The Prolog-like abilities of type class instance resolution allow us to conveniently define a quote function, thus facilitating the use of reflective techniques.},
  file        = {:http\://arxiv.org/pdf/1102.1323v1:PDF},
  keywords    = {cs.LO},
}

@Misc{UniMath,
  author       = {Voevodsky, Vladimir and Ahrens, Benedikt and Grayson, Daniel and others},
  date         = {2020},
  title        = {Uni{M}ath --- a computer-checked library of univalent mathematics},
  howpublished = {{available} at \url{https://github.com/UniMath/UniMath}},
  url          = {https://github.com/UniMath/UniMath},
}

@Article{voevodsky_2015,
  author       = {Vladimir Voevodsky},
  date         = {2015},
  journaltitle = {Mathematical Structures in Computer Science},
  title        = {An experimental library of formalized Mathematics based on the univalent foundations},
  doi          = {10.1017/S0960129514000577},
  number       = {5},
  pages        = {1278--1294},
  volume       = {25},
  publisher    = {Cambridge University Press},
}

@Article{introduction2018Grayson,
  author       = {Daniel R. Grayson},
  date         = {2018-03-05},
  journaltitle = {Bulletin of the American Mathematical Society},
  title        = {An introduction to univalent foundations for mathematicians},
  doi          = {10.1090/bull/1616},
  issn         = {1088-9485},
  issue        = {55},
  pages        = {427--450},
  abstract     = {We offer an introduction for mathematicians to the univalent foundations of Vladimir Voevodsky, aiming to explain how he chose to encode mathematics in type theory and how the encoding reveals a potentially viable foundation for all of modern mathematics that can serve as an alternative to set theory.},
}

@InProceedings{Packaging2009Garillot,
  author      = {Garillot, François and Gonthier, Georges and Mahboubi, Assia and Rideau, Laurence},
  booktitle   = {Theorem Proving in Higher Order Logics},
  date        = {2009},
  title       = {Packaging Mathematical Structures},
  doi         = {10.1007/978-3-642-03359-9_23},
  editor      = {Berghofer, Stefan and Nipkow, Tobias and Urban, Christian and Wenzel, Makarius},
  isbn        = {978-3-642-03359-9},
  location    = {Berlin, Heidelberg},
  pages       = {327--342},
  publisher   = {Springer Berlin Heidelberg},
  series      = {Lecture Notes in Computer Science},
  url         = {https://hal.inria.fr/inria-00368403},
  volume      = {5674},
  abstract    = {This paper proposes generic design patterns to define and combine algebraic structures, using dependent records, coercions and type inference, inside the Coq system. This alternative to telescopes in particular supports multiple inheritance, maximal sharing of notations and theories, and automated structure inference. Our methodology is robust enough to handle a hierarchy comprising a broad variety of algebraic structures, from types with a choice operator to algebraically closed fields. Interfaces for the structures enjoy the convenience of a classical setting, without requiring any axiom. Finally, we present two applications of our proof techniques: a key lemma for characterising the discrete logarithm, and a matrix decomposition problem.},
  hal_id      = {inria-00368403},
  hal_version = {v2},
  keywords    = {Formalization of Algebra ; Coercive subtyping ; Type inference ; Coq ; SSReflect},
  pdf         = {https://hal.inria.fr/inria-00368403v2/file/main.pdf},
}

@InProceedings{Efficient1998Necula,
  author    = {George C. Necula and Peter Lee},
  booktitle = {Proceedings of the 13th Annual IEEE Symposium on Logic in Computer Science},
  date      = {1998-6},
  title     = {Efficient Representation and Validation of Proofs},
  doi       = {10.1109/lics.1998.705646},
  isbn      = {0818685069},
  location  = {USA},
  pages     = {93},
  publisher = {IEEE Computer Society},
  series    = {LICS '98},
  url       = {https://people.eecs.berkeley.edu/~necula/Papers/lfi_lics98.ps},
  abstract  = {This paper presents a logical framework derived from the Edinburgh Logical Framework (LF) that can be used to obtain compact representations of proofs and efficient proof checkers. These are essential ingredients of any application that manipulates proofs as first-class objects, such as a Proof-Carrying Code system, in which proofs are used to allow the easy validation of properties of safety-critical or untrusted code.

Our framework, which we call LF$_i$, inherits from LF the capability to encode various logics in a natural way. In addition, the LF$_i$ framework allows proof representations without the high degree of redundancy that is characteristic of LF representations. The missing parts of LF$_i$ proof representations can be reconstructed during proof checking by an efficient reconstruction algorithm. We also describe an algorithm that can be used to strip the unnecessary parts of an LF representation of a proof. The experimental data that we gathered in the context of a Proof-Carrying Code system shows that the savings obtained from using LF$_i$ instead of LF can make the difference between practically useless proofs of several megabytes and manageable proofs of tens of kilobytes.},
}

@Comment{jabref-meta: databaseType:biblatex;}
